# AI PPT Assistant 问题修复计划 - 改进版

**文档版本**: 2.0  
**创建时间**: 2025-09-11  
**负责人**: AWS专家团队  
**系统版本**: ai-ppt-assistant-dev  
**部署区域**: us-east-1  

## 执行摘要

基于G老师的专业建议，本改进版修复计划不仅解决当前的18个技术问题，更重要的是建立**长期稳态**的解决方案，通过配置中心化、单一真相源、IaC管控等措施，彻底避免配置漂移和环境不一致问题。

**关键改进**:
- 🔐 立即轮换已泄露的API密钥
- 🏷️ 使用Agent别名替代硬编码ID
- 🎯 统一到单一API Gateway和Stage
- 💾 实施DynamoDB数据迁移
- 🔧 配置中心化(SSM Parameter Store)
- 🚀 CI/CD自动验证闸

**预计修复时间**: 
- P0级问题(含安全): 1-2小时（立即执行）
- P1级问题: 4-6小时  
- 长期化改造: 1-2天
- 监控优化: 持续迭代

---

## 第零阶段：紧急安全措施（立即执行）

### 0.1 API密钥轮换 🔴 最高优先级

**问题**: 文档中已泄露API Key（9EQHqfmiuA5GrkMnK5PVf8OpbIcsMj1N2z6PFGR3）

**立即执行**:
```bash
# 步骤1: 创建新的API密钥
NEW_API_KEY=$(aws apigateway create-api-key \
  --name ai-ppt-assistant-dev-key-$(date +%Y%m%d) \
  --enabled \
  --query 'value' \
  --output text \
  --region us-east-1)

echo "新API密钥已创建（请立即保存到安全位置）: $NEW_API_KEY"

# 步骤2: 关联到使用计划
USAGE_PLAN_ID=$(aws apigateway get-usage-plans \
  --query 'items[?name==`ai-ppt-assistant-usage-plan`].id' \
  --output text \
  --region us-east-1)

aws apigateway create-usage-plan-key \
  --usage-plan-id $USAGE_PLAN_ID \
  --key-id $(aws apigateway get-api-keys --query "items[?value=='$NEW_API_KEY'].id" --output text) \
  --key-type API_KEY \
  --region us-east-1

# 步骤3: 存储到SSM Parameter Store（加密）
aws ssm put-parameter \
  --name "/ai-ppt-assistant/dev/api-key" \
  --value "$NEW_API_KEY" \
  --type "SecureString" \
  --overwrite \
  --region us-east-1

# 步骤4: 禁用旧密钥
OLD_KEY_ID=$(aws apigateway get-api-keys \
  --query "items[?value=='9EQHqfmiuA5GrkMnK5PVf8OpbIcsMj1N2z6PFGR3'].id" \
  --output text \
  --region us-east-1)

if [ ! -z "$OLD_KEY_ID" ]; then
  aws apigateway update-api-key \
    --api-key $OLD_KEY_ID \
    --patch-operations op=replace,path=/enabled,value=false \
    --region us-east-1
  echo "旧密钥已禁用"
fi
```

### 0.2 清理仓库中的敏感信息

```bash
# 创建安全的配置模板
cat > api_config_info.json << 'EOF'
{
  "project": "ai-ppt-assistant",
  "environment": "dev",
  "region": "us-east-1",
  "api_gateway_url": "{{API_GATEWAY_URL}}",
  "api_key_parameter": "/ai-ppt-assistant/dev/api-key",
  "note": "Actual values are stored in AWS SSM Parameter Store",
  "updated_at": "2025-09-11T19:00:00Z",
  "updated_by": "security_fix"
}
EOF

# 清理Git历史（如果需要）
# git filter-branch --force --index-filter \
#   'git rm --cached --ignore-unmatch api_config_info.json' \
#   --prune-empty --tag-name-filter cat -- --all
```

---

## 第一阶段：核心功能恢复（P0级）

### 1.1 Bedrock Agent配置 - 使用别名替代硬编码ID

**关键改进**: 为所有Agent创建统一别名，避免ID变化带来的连锁修改

```python
#!/usr/bin/env python3
# fix_agent_config.py
import boto3
import json
from datetime import datetime

# 初始化客户端
bedrock = boto3.client('bedrock-agent', region_name='us-east-1')
lambda_client = boto3.client('lambda', region_name='us-east-1')
ssm = boto3.client('ssm', region_name='us-east-1')

def create_or_update_agent_alias(agent_id, alias_name='dev'):
    """为Agent创建或更新别名"""
    try:
        # 检查别名是否存在
        response = bedrock.list_agent_aliases(agentId=agent_id)
        existing_alias = next((a for a in response['agentAliasSummaries'] 
                              if a['aliasName'] == alias_name), None)
        
        if existing_alias:
            print(f"✓ 别名 {alias_name} 已存在于Agent {agent_id}")
            return existing_alias['agentAliasId']
        else:
            # 创建新别名
            response = bedrock.create_agent_alias(
                agentId=agent_id,
                agentAliasName=alias_name,
                description=f"Development alias created at {datetime.now()}"
            )
            print(f"✅ 创建别名 {alias_name} 成功: {response['agentAlias']['agentAliasId']}")
            return response['agentAlias']['agentAliasId']
    except Exception as e:
        print(f"⚠️ 处理Agent {agent_id} 时出错: {e}")
        return None

def store_config_in_ssm():
    """将配置存储到SSM Parameter Store"""
    
    # Agent配置映射（使用别名而非ID）
    agent_configs = {
        'orchestrator': {
            'agent_id': 'Q6RODNGFYR',
            'alias_name': 'dev',
            'functions': ['ai-ppt-assistant-api-generate-presentation']
        },
        'content': {
            'agent_id': 'L0ZQHJSU4X',
            'alias_name': 'dev',
            'functions': ['ai-ppt-assistant-generate-content']
        },
        'visual': {
            'agent_id': 'FO53FNXIRL',
            'alias_name': 'dev',
            'functions': ['ai-ppt-assistant-generate-image']
        },
        'compiler': {
            'agent_id': 'B02XIGCUKI',
            'alias_name': 'dev',
            'functions': ['ai-ppt-assistant-compile-pptx']
        }
    }
    
    # 为每个Agent创建别名并存储配置
    for agent_type, config in agent_configs.items():
        agent_id = config['agent_id']
        alias_name = config['alias_name']
        
        # 创建或获取别名ID
        alias_id = create_or_update_agent_alias(agent_id, alias_name)
        
        if alias_id:
            # 存储到SSM
            param_prefix = f"/ai-ppt-assistant/dev/agents/{agent_type}"
            
            # 存储Agent ID
            ssm.put_parameter(
                Name=f"{param_prefix}/id",
                Value=agent_id,
                Type="String",
                Overwrite=True
            )
            
            # 存储别名ID
            ssm.put_parameter(
                Name=f"{param_prefix}/alias_id",
                Value=alias_id,
                Type="String",
                Overwrite=True
            )
            
            # 存储别名名称（供代码引用）
            ssm.put_parameter(
                Name=f"{param_prefix}/alias_name",
                Value=alias_name,
                Type="String",
                Overwrite=True
            )
            
            print(f"✅ {agent_type} Agent配置已存储到SSM")
            
            # 更新Lambda函数环境变量（引用SSM参数）
            for func_name in config['functions']:
                try:
                    # 获取当前配置
                    response = lambda_client.get_function_configuration(
                        FunctionName=func_name
                    )
                    
                    # 更新环境变量
                    env_vars = response.get('Environment', {}).get('Variables', {})
                    env_vars.update({
                        f'{agent_type.upper()}_AGENT_ALIAS': alias_name,
                        f'{agent_type.upper()}_AGENT_ALIAS_ID': alias_id,
                        'CONFIG_SOURCE': 'SSM_PARAMETER_STORE'
                    })
                    
                    lambda_client.update_function_configuration(
                        FunctionName=func_name,
                        Environment={'Variables': env_vars}
                    )
                    
                    print(f"✅ 更新Lambda函数 {func_name} 环境变量")
                    
                except Exception as e:
                    print(f"❌ 更新函数 {func_name} 失败: {e}")

if __name__ == "__main__":
    print("🚀 开始修复Agent配置...")
    store_config_in_ssm()
    print("✨ Agent配置修复完成")
```

### 1.2 统一API Gateway和Stage

**关键改进**: 只保留一个API和一个Stage，删除冗余资源

```bash
#!/bin/bash
# unify_api_gateway.sh

echo "🔍 检查现有API Gateway..."

# 获取所有API
aws apigateway get-rest-apis --region us-east-1 --query 'items[*].[id,name]' --output table

# 确定要保留的API（使用最活跃的）
PRIMARY_API_ID="otmr3noxg5"  # 根据实际情况选择
PRIMARY_STAGE="dev"

echo "✅ 将统一使用API: $PRIMARY_API_ID, Stage: $PRIMARY_STAGE"

# 步骤1: 删除legacy stage
aws apigateway delete-stage \
  --rest-api-id $PRIMARY_API_ID \
  --stage-name legacy \
  --region us-east-1 2>/dev/null || echo "legacy stage不存在或已删除"

# 步骤2: 确保dev stage存在并更新
aws apigateway create-deployment \
  --rest-api-id $PRIMARY_API_ID \
  --stage-name $PRIMARY_STAGE \
  --description "Unified deployment $(date +%Y%m%d-%H%M%S)" \
  --region us-east-1

# 步骤3: 更新使用计划 - 清空后重新添加
USAGE_PLAN_ID=$(aws apigateway get-usage-plans \
  --query 'items[0].id' \
  --output text \
  --region us-east-1)

# 移除所有现有stage关联
EXISTING_STAGES=$(aws apigateway get-usage-plan \
  --usage-plan-id $USAGE_PLAN_ID \
  --query 'apiStages[*].[apiId,stage]' \
  --output text \
  --region us-east-1)

while IFS=$'\t' read -r api_id stage_name; do
  if [ ! -z "$api_id" ]; then
    aws apigateway update-usage-plan \
      --usage-plan-id $USAGE_PLAN_ID \
      --patch-operations op=remove,path="/apiStages/${api_id}:${stage_name}" \
      --region us-east-1 2>/dev/null || true
  fi
done <<< "$EXISTING_STAGES"

# 添加唯一的stage关联
aws apigateway update-usage-plan \
  --usage-plan-id $USAGE_PLAN_ID \
  --patch-operations op=add,path=/apiStages,value="${PRIMARY_API_ID}:${PRIMARY_STAGE}" \
  --region us-east-1

# 步骤4: 存储到SSM
aws ssm put-parameter \
  --name "/ai-ppt-assistant/dev/api-gateway-url" \
  --value "https://${PRIMARY_API_ID}.execute-api.us-east-1.amazonaws.com/${PRIMARY_STAGE}" \
  --type "String" \
  --overwrite \
  --region us-east-1

echo "✅ API Gateway统一完成"

# 步骤5: 删除其他未使用的API（谨慎操作）
# aws apigateway get-rest-apis --query 'items[?id!=`'$PRIMARY_API_ID'`].id' --output text | \
#   xargs -I {} aws apigateway delete-rest-api --rest-api-id {} --region us-east-1
```

### 1.3 DynamoDB表统一和数据迁移

**关键改进**: 包含数据迁移脚本，确保无数据丢失

```python
#!/usr/bin/env python3
# migrate_dynamodb_data.py
import boto3
from datetime import datetime
import json

dynamodb = boto3.resource('dynamodb', region_name='us-east-1')
lambda_client = boto3.client('lambda', region_name='us-east-1')
ssm = boto3.client('ssm', region_name='us-east-1')

def migrate_data():
    """迁移tasks表数据到sessions表"""
    
    # 定义表
    tasks_table = dynamodb.Table('ai-ppt-assistant-dev-tasks')
    sessions_table = dynamodb.Table('ai-ppt-assistant-dev-sessions')
    
    print("📊 开始数据迁移...")
    
    # 步骤1: 备份现有数据
    backup_data = {
        'tasks': [],
        'sessions': [],
        'backup_time': datetime.now().isoformat()
    }
    
    # 扫描tasks表
    try:
        response = tasks_table.scan()
        backup_data['tasks'] = response.get('Items', [])
        print(f"✓ 从tasks表读取 {len(backup_data['tasks'])} 条记录")
    except Exception as e:
        print(f"⚠️ 读取tasks表失败: {e}")
    
    # 扫描sessions表
    try:
        response = sessions_table.scan()
        backup_data['sessions'] = response.get('Items', [])
        print(f"✓ 从sessions表读取 {len(backup_data['sessions'])} 条记录")
    except Exception as e:
        print(f"⚠️ 读取sessions表失败: {e}")
    
    # 保存备份
    with open(f'dynamodb_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json', 'w') as f:
        json.dump(backup_data, f, indent=2, default=str)
    print("✅ 数据备份完成")
    
    # 步骤2: 迁移数据
    migrated_count = 0
    failed_count = 0
    
    for item in backup_data['tasks']:
        try:
            # 检查是否已存在
            existing = sessions_table.get_item(
                Key={'taskId': item.get('taskId')}
            )
            
            if 'Item' not in existing:
                # 写入到sessions表
                sessions_table.put_item(Item=item)
                migrated_count += 1
                print(f"✓ 迁移记录: {item.get('taskId')}")
            else:
                print(f"→ 跳过已存在记录: {item.get('taskId')}")
                
        except Exception as e:
            print(f"❌ 迁移失败: {item.get('taskId')} - {e}")
            failed_count += 1
    
    print(f"\n📊 迁移完成:")
    print(f"  成功: {migrated_count}")
    print(f"  失败: {failed_count}")
    print(f"  跳过: {len(backup_data['tasks']) - migrated_count - failed_count}")
    
    # 步骤3: 更新所有Lambda函数使用sessions表
    functions_to_update = [
        'ai-ppt-assistant-api-generate-presentation',
        'ai-ppt-assistant-api-presentation-status',
        'ai-ppt-assistant-api-list-presentations',
        'ai-ppt-assistant-api-get-task'
    ]
    
    sessions_table_name = 'ai-ppt-assistant-dev-sessions'
    
    # 存储到SSM
    ssm.put_parameter(
        Name="/ai-ppt-assistant/dev/dynamodb-table",
        Value=sessions_table_name,
        Type="String",
        Overwrite=True
    )
    
    for func_name in functions_to_update:
        try:
            response = lambda_client.get_function_configuration(
                FunctionName=func_name
            )
            
            env_vars = response.get('Environment', {}).get('Variables', {})
            env_vars['DYNAMODB_TABLE'] = sessions_table_name
            
            lambda_client.update_function_configuration(
                FunctionName=func_name,
                Environment={'Variables': env_vars}
            )
            
            print(f"✅ 更新函数 {func_name} 使用表: {sessions_table_name}")
            
        except Exception as e:
            print(f"❌ 更新函数 {func_name} 失败: {e}")

if __name__ == "__main__":
    migrate_data()
```

---

## 第二阶段：配置中心化和IaC管控

### 2.1 建立SSM Parameter Store配置中心

```python
#!/usr/bin/env python3
# setup_config_center.py
import boto3
import json

ssm = boto3.client('ssm', region_name='us-east-1')

def setup_parameter_store():
    """建立完整的配置中心"""
    
    parameters = {
        # API配置
        "/ai-ppt-assistant/dev/api-gateway-url": "https://otmr3noxg5.execute-api.us-east-1.amazonaws.com/dev",
        "/ai-ppt-assistant/dev/api-stage": "dev",
        
        # DynamoDB配置
        "/ai-ppt-assistant/dev/dynamodb-table": "ai-ppt-assistant-dev-sessions",
        "/ai-ppt-assistant/dev/dynamodb-region": "us-east-1",
        
        # S3配置
        "/ai-ppt-assistant/dev/s3-bucket": "ai-ppt-assistant-dev-storage",
        
        # SQS配置
        "/ai-ppt-assistant/dev/sqs-queue": "ai-ppt-assistant-dev-tasks",
        
        # 环境配置
        "/ai-ppt-assistant/dev/environment": "development",
        "/ai-ppt-assistant/dev/log-level": "INFO",
        
        # 版本信息
        "/ai-ppt-assistant/dev/version": "2.0.0",
        "/ai-ppt-assistant/dev/deployment-date": "2025-09-11"
    }
    
    print("🔧 配置SSM Parameter Store...")
    
    for name, value in parameters.items():
        try:
            # 检查参数是否存在
            try:
                existing = ssm.get_parameter(Name=name)
                print(f"→ 更新参数: {name}")
            except:
                print(f"✓ 创建参数: {name}")
            
            # 创建或更新参数
            ssm.put_parameter(
                Name=name,
                Value=value,
                Type="String",
                Overwrite=True,
                Description=f"Configuration for AI PPT Assistant - {name.split('/')[-1]}"
            )
            
        except Exception as e:
            print(f"❌ 处理参数 {name} 失败: {e}")
    
    print("✅ 配置中心设置完成")

def create_lambda_config_reader():
    """创建Lambda函数读取配置的辅助代码"""
    
    code = '''
import boto3
import os
from functools import lru_cache

ssm = boto3.client('ssm', region_name=os.environ.get('AWS_REGION', 'us-east-1'))

@lru_cache(maxsize=128)
def get_parameter(name, decrypt=False):
    """从SSM Parameter Store获取参数值"""
    try:
        response = ssm.get_parameter(Name=name, WithDecryption=decrypt)
        return response['Parameter']['Value']
    except Exception as e:
        # 降级到环境变量
        env_key = name.split('/')[-1].upper().replace('-', '_')
        return os.environ.get(env_key, '')

def get_config():
    """获取完整配置"""
    prefix = "/ai-ppt-assistant/dev"
    
    return {
        'api_gateway_url': get_parameter(f'{prefix}/api-gateway-url'),
        'api_key': get_parameter(f'{prefix}/api-key', decrypt=True),
        'dynamodb_table': get_parameter(f'{prefix}/dynamodb-table'),
        's3_bucket': get_parameter(f'{prefix}/s3-bucket'),
        'sqs_queue': get_parameter(f'{prefix}/sqs-queue'),
        'environment': get_parameter(f'{prefix}/environment'),
    }

# 使用示例
config = get_config()
TABLE_NAME = config['dynamodb_table']
S3_BUCKET = config['s3_bucket']
'''
    
    # 保存配置读取器
    with open('lambda_config_reader.py', 'w') as f:
        f.write(code)
    
    print("✅ Lambda配置读取器已创建: lambda_config_reader.py")

if __name__ == "__main__":
    setup_parameter_store()
    create_lambda_config_reader()
```

### 2.2 Terraform状态同步和IaC完善

```hcl
# terraform/modules/config/main.tf
# 配置中心化的Terraform模块

resource "aws_ssm_parameter" "api_config" {
  for_each = {
    api_gateway_url = "https://${var.api_gateway_id}.execute-api.${var.region}.amazonaws.com/${var.stage}"
    api_stage       = var.stage
    dynamodb_table  = "${var.project}-${var.environment}-sessions"
    s3_bucket       = "${var.project}-${var.environment}-storage"
  }
  
  name  = "/${var.project}/${var.environment}/${each.key}"
  type  = "String"
  value = each.value
  
  tags = var.tags
}

resource "aws_ssm_parameter" "api_key" {
  name  = "/${var.project}/${var.environment}/api-key"
  type  = "SecureString"
  value = var.api_key  # 从terraform.tfvars或环境变量传入
  
  tags = var.tags
}

# Agent别名配置
resource "aws_ssm_parameter" "agent_aliases" {
  for_each = var.agent_configs
  
  name  = "/${var.project}/${var.environment}/agents/${each.key}/alias"
  type  = "String"
  value = "dev"  # 统一使用dev别名
  
  tags = var.tags
}

# Lambda函数环境变量引用SSM
data "aws_ssm_parameter" "config" {
  for_each = toset([
    "api_gateway_url",
    "dynamodb_table",
    "s3_bucket"
  ])
  
  name = "/${var.project}/${var.environment}/${each.key}"
}

# 输出供Lambda模块使用
output "lambda_environment_variables" {
  value = {
    CONFIG_SOURCE     = "SSM_PARAMETER_STORE"
    PARAMETER_PREFIX  = "/${var.project}/${var.environment}"
    DYNAMODB_TABLE    = data.aws_ssm_parameter.config["dynamodb_table"].value
    S3_BUCKET         = data.aws_ssm_parameter.config["s3_bucket"].value
    API_GATEWAY_URL   = data.aws_ssm_parameter.config["api_gateway_url"].value
  }
}
```

### 2.3 导入现有资源到Terraform状态

```bash
#!/bin/bash
# import_terraform_resources.sh

cd infrastructure

echo "🔄 导入现有资源到Terraform状态..."

# 导入IAM角色
terraform import module.bedrock.aws_iam_role.agent_roles[\"compiler\"] \
  ai-ppt-assistant-compiler-agent-role

terraform import module.bedrock.aws_iam_role.agent_roles[\"orchestrator\"] \
  ai-ppt-assistant-orchestrator-agent-role

terraform import module.bedrock.aws_iam_role.agent_roles[\"visual\"] \
  ai-ppt-assistant-visual-agent-role

terraform import module.bedrock.aws_iam_role.agent_roles[\"content\"] \
  ai-ppt-assistant-content-agent-role

# 导入IAM策略
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

terraform import module.bedrock.aws_iam_policy.agent_policies[\"compiler\"] \
  arn:aws:iam::${ACCOUNT_ID}:policy/ai-ppt-assistant-compiler-agent-policy

terraform import module.bedrock.aws_iam_policy.agent_policies[\"orchestrator\"] \
  arn:aws:iam::${ACCOUNT_ID}:policy/ai-ppt-assistant-orchestrator-agent-policy

terraform import module.bedrock.aws_iam_policy.agent_policies[\"visual\"] \
  arn:aws:iam::${ACCOUNT_ID}:policy/ai-ppt-assistant-visual-agent-policy

terraform import module.bedrock.aws_iam_policy.agent_policies[\"content\"] \
  arn:aws:iam::${ACCOUNT_ID}:policy/ai-ppt-assistant-content-agent-policy

# 导入CloudWatch日志组
terraform import module.monitoring.aws_cloudwatch_log_group.insights \
  /aws/cloudwatch/insights/ai-ppt-assistant-dev

# 导入KMS别名
terraform import module.kms.aws_kms_alias.sns_key \
  alias/ai-ppt-assistant-dev-sns-key

echo "✅ 资源导入完成"

# 验证状态
terraform plan -out=tfplan

if [ $? -eq 0 ]; then
  echo "✅ Terraform状态同步成功"
else
  echo "❌ Terraform状态存在问题，请检查"
fi
```

---

## 第三阶段：CI/CD和自动验证

### 3.1 部署后自动验证脚本

```python
#!/usr/bin/env python3
# post_deploy_validation.py
import boto3
import requests
import json
import sys
from datetime import datetime

def validate_deployment():
    """部署后自动验证"""
    
    ssm = boto3.client('ssm', region_name='us-east-1')
    
    # 获取配置
    api_url = ssm.get_parameter(Name='/ai-ppt-assistant/dev/api-gateway-url')['Parameter']['Value']
    api_key = ssm.get_parameter(Name='/ai-ppt-assistant/dev/api-key', WithDecryption=True)['Parameter']['Value']
    
    validations = []
    
    # 1. 健康检查
    print("🔍 执行健康检查...")
    try:
        response = requests.get(
            f"{api_url}/health",
            headers={'x-api-key': api_key},
            timeout=10
        )
        validations.append({
            'test': 'Health Check',
            'status': response.status_code == 200,
            'message': f"Status: {response.status_code}"
        })
    except Exception as e:
        validations.append({
            'test': 'Health Check',
            'status': False,
            'message': str(e)
        })
    
    # 2. 创建演示文稿测试
    print("🔍 测试创建演示文稿...")
    try:
        response = requests.post(
            f"{api_url}/presentations",
            headers={'x-api-key': api_key},
            json={
                'topic': 'Deployment Test',
                'slides': 3,
                'test': True
            },
            timeout=30
        )
        
        if response.status_code in [200, 201, 202]:
            task_id = response.json().get('taskId')
            validations.append({
                'test': 'Create Presentation',
                'status': True,
                'message': f"Task ID: {task_id}"
            })
        else:
            validations.append({
                'test': 'Create Presentation',
                'status': False,
                'message': f"Status: {response.status_code}"
            })
    except Exception as e:
        validations.append({
            'test': 'Create Presentation',
            'status': False,
            'message': str(e)
        })
    
    # 3. 验证Lambda配置
    print("🔍 验证Lambda配置...")
    lambda_client = boto3.client('lambda', region_name='us-east-1')
    
    functions = [
        'ai-ppt-assistant-api-generate-presentation',
        'ai-ppt-assistant-generate-content',
        'ai-ppt-assistant-generate-image',
        'ai-ppt-assistant-compile-pptx'
    ]
    
    for func_name in functions:
        try:
            config = lambda_client.get_function_configuration(FunctionName=func_name)
            env_vars = config.get('Environment', {}).get('Variables', {})
            
            # 检查关键环境变量
            has_config = 'CONFIG_SOURCE' in env_vars
            
            validations.append({
                'test': f'Lambda Config: {func_name.split("-")[-1]}',
                'status': has_config,
                'message': 'Config source: SSM' if has_config else 'Missing config'
            })
        except Exception as e:
            validations.append({
                'test': f'Lambda Config: {func_name.split("-")[-1]}',
                'status': False,
                'message': str(e)
            })
    
    # 生成报告
    print("\n" + "="*60)
    print("部署验证报告")
    print("="*60)
    
    passed = sum(1 for v in validations if v['status'])
    total = len(validations)
    
    for validation in validations:
        status_icon = "✅" if validation['status'] else "❌"
        print(f"{status_icon} {validation['test']}: {validation['message']}")
    
    print("\n" + "-"*60)
    print(f"结果: {passed}/{total} 通过")
    
    # 保存报告
    report = {
        'timestamp': datetime.now().isoformat(),
        'validations': validations,
        'summary': {
            'total': total,
            'passed': passed,
            'failed': total - passed,
            'success_rate': f"{(passed/total)*100:.1f}%"
        }
    }
    
    with open('deployment_validation_report.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    # 返回状态码
    return 0 if passed == total else 1

if __name__ == "__main__":
    sys.exit(validate_deployment())
```

### 3.2 Make命令改进

```makefile
# Makefile 改进版

.PHONY: deploy deploy-safe rollback validate

# 安全部署（带验证）
deploy-safe:
	@echo "🚀 开始安全部署..."
	@# 备份当前状态
	@cd infrastructure && cp terraform.tfstate terraform.tfstate.backup.$(shell date +%Y%m%d-%H%M%S)
	@# 执行部署
	@$(MAKE) deploy
	@# 执行验证
	@$(MAKE) validate
	@if [ $$? -ne 0 ]; then \
		echo "❌ 验证失败，开始回滚..."; \
		$(MAKE) rollback; \
		exit 1; \
	fi
	@echo "✅ 部署成功并通过验证"

# 验证部署
validate:
	@echo "🔍 验证部署..."
	@python3 post_deploy_validation.py

# 回滚
rollback:
	@echo "⏪ 执行回滚..."
	@cd infrastructure && \
		cp terraform.tfstate.backup.$(shell ls -t terraform.tfstate.backup.* | head -1 | cut -d. -f3-) terraform.tfstate && \
		terraform apply -auto-approve
	@echo "✅ 回滚完成"

# 配置同步
sync-config:
	@echo "🔄 同步配置到SSM..."
	@python3 setup_config_center.py
	@python3 fix_agent_config.py
	@echo "✅ 配置同步完成"
```

---

## 第四阶段：监控和长期优化

### 4.1 CloudWatch告警优化

```python
#!/usr/bin/env python3
# setup_monitoring.py
import boto3

cloudwatch = boto3.client('cloudwatch', region_name='us-east-1')

def setup_alarms():
    """设置优化的CloudWatch告警"""
    
    # Lambda函数错误率告警
    functions = [
        'ai-ppt-assistant-api-generate-presentation',
        'ai-ppt-assistant-generate-content',
        'ai-ppt-assistant-generate-image',
        'ai-ppt-assistant-compile-pptx'
    ]
    
    for func_name in functions:
        # 错误率告警
        cloudwatch.put_metric_alarm(
            AlarmName=f"{func_name}-error-rate",
            ComparisonOperator='GreaterThanThreshold',
            EvaluationPeriods=2,
            MetricName='Errors',
            Namespace='AWS/Lambda',
            Period=300,
            Statistic='Sum',
            Threshold=5.0,
            ActionsEnabled=True,
            AlarmDescription=f'Error rate for {func_name}',
            Dimensions=[
                {
                    'Name': 'FunctionName',
                    'Value': func_name
                }
            ],
            TreatMissingData='notBreaching'
        )
        
        # 持续时间告警
        cloudwatch.put_metric_alarm(
            AlarmName=f"{func_name}-duration",
            ComparisonOperator='GreaterThanThreshold',
            EvaluationPeriods=2,
            MetricName='Duration',
            Namespace='AWS/Lambda',
            Period=300,
            Statistic='Average',
            Threshold=10000.0,  # 10秒
            ActionsEnabled=True,
            AlarmDescription=f'Duration alarm for {func_name}',
            Dimensions=[
                {
                    'Name': 'FunctionName',
                    'Value': func_name
                }
            ],
            TreatMissingData='notBreaching'
        )
    
    print("✅ CloudWatch告警设置完成")

if __name__ == "__main__":
    setup_alarms()
```

### 4.2 S3生命周期和DynamoDB备份

```bash
#!/bin/bash
# setup_data_management.sh

# S3生命周期策略
cat > s3-lifecycle.json << 'EOF'
{
  "Rules": [
    {
      "Id": "DeleteOldPresentations",
      "Status": "Enabled",
      "Expiration": {
        "Days": 30
      },
      "NoncurrentVersionExpiration": {
        "NoncurrentDays": 7
      },
      "Filter": {
        "Prefix": "presentations/"
      }
    },
    {
      "Id": "TransitionToIA",
      "Status": "Enabled",
      "Transitions": [
        {
          "Days": 7,
          "StorageClass": "STANDARD_IA"
        },
        {
          "Days": 30,
          "StorageClass": "GLACIER"
        }
      ],
      "Filter": {
        "Prefix": "archives/"
      }
    }
  ]
}
EOF

aws s3api put-bucket-lifecycle-configuration \
  --bucket ai-ppt-assistant-dev-storage \
  --lifecycle-configuration file://s3-lifecycle.json \
  --region us-east-1

echo "✅ S3生命周期策略已配置"

# DynamoDB备份
for table in sessions tasks checkpoints; do
  # 启用Point-in-time Recovery
  aws dynamodb update-continuous-backups \
    --table-name ai-ppt-assistant-dev-$table \
    --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true \
    --region us-east-1
  
  echo "✅ 启用表 $table 的PITR备份"
done

# 创建按需备份
aws dynamodb create-backup \
  --table-name ai-ppt-assistant-dev-sessions \
  --backup-name "ai-ppt-assistant-dev-sessions-$(date +%Y%m%d)" \
  --region us-east-1

echo "✅ 数据管理策略配置完成"
```

---

## 执行计划总结

### 🚨 立即执行（0-1小时）
1. **API密钥轮换和安全加固**
   ```bash
   bash -c "$(curl -fsSL emergency_security_fix.sh)"
   ```

### 🔧 第一天（4-6小时）
2. **核心功能修复**
   ```bash
   python3 fix_agent_config.py
   bash unify_api_gateway.sh
   python3 migrate_dynamodb_data.py
   ```

3. **配置中心化**
   ```bash
   python3 setup_config_center.py
   bash import_terraform_resources.sh
   ```

### 📊 第二天（持续优化）
4. **CI/CD和监控**
   ```bash
   make deploy-safe
   python3 setup_monitoring.py
   bash setup_data_management.sh
   ```

## 成功标准

### 必须达成 ✅
- [ ] API密钥已轮换，旧密钥已禁用
- [ ] 所有Agent使用别名而非硬编码ID
- [ ] 只有一个API Gateway和一个Stage（dev）
- [ ] DynamoDB数据统一到sessions表
- [ ] 配置全部存储在SSM Parameter Store
- [ ] Terraform状态与实际资源同步
- [ ] 部署后自动验证通过

### 应该达成 📈
- [ ] CloudWatch告警正常工作
- [ ] S3生命周期策略已配置
- [ ] DynamoDB备份已启用
- [ ] Lambda并发限制已设置
- [ ] X-Ray追踪已启用

### 持续改进 🔄
- [ ] 自定义域名配置
- [ ] API版本管理实施
- [ ] 细粒度限流配置
- [ ] 成本优化措施

## 风险缓解

### 备份策略
- 所有操作前创建备份
- Terraform状态文件版本控制
- DynamoDB数据导出保存
- 配置变更记录审计

### 回滚方案
- 每个阶段都有独立回滚脚本
- 保留24小时内的所有备份
- 紧急联系方式和升级路径

## 联系支持

**技术支持**: aws-support@company.com  
**紧急电话**: +1-xxx-xxx-xxxx  
**Slack**: #ai-ppt-assistant-ops  
**文档库**: https://wiki.company.com/ai-ppt-assistant

---

**文档版本历史**:
- v2.0 (2025-09-11): 基于G老师建议的改进版，增加长期稳态方案
- v1.0 (2025-09-11): 初始版本

**下次更新**: 部署完成后的实施报告