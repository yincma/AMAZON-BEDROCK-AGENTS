# AI PPT Assistant - æ•…éšœæ’é™¤æŒ‡å—

## ç›®å½•

1. [å¿«é€Ÿè¯Šæ–­æµç¨‹](#å¿«é€Ÿè¯Šæ–­æµç¨‹)
2. [å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ](#å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ)
3. [é”™è¯¯ä»£ç å‚è€ƒ](#é”™è¯¯ä»£ç å‚è€ƒ)
4. [æ€§èƒ½é—®é¢˜è¯Šæ–­](#æ€§èƒ½é—®é¢˜è¯Šæ–­)
5. [æ—¥å¿—åˆ†ææŠ€å·§](#æ—¥å¿—åˆ†ææŠ€å·§)
6. [è°ƒè¯•å·¥å…·ä½¿ç”¨](#è°ƒè¯•å·¥å…·ä½¿ç”¨)
7. [ç´§æ€¥ä¿®å¤æµç¨‹](#ç´§æ€¥ä¿®å¤æµç¨‹)
8. [é—®é¢˜ä¸ŠæŠ¥æ¨¡æ¿](#é—®é¢˜ä¸ŠæŠ¥æ¨¡æ¿)

## å¿«é€Ÿè¯Šæ–­æµç¨‹

### è¯Šæ–­å†³ç­–æ ‘

```mermaid
graph TD
    Start[é—®é¢˜å‘ç”Ÿ] --> Check1{æœåŠ¡æ˜¯å¦å¯è®¿é—®?}

    Check1 -->|å¦| Network[æ£€æŸ¥ç½‘ç»œè¿æ¥]
    Check1 -->|æ˜¯| Check2{APIå“åº”æ­£å¸¸?}

    Network --> DNS[æ£€æŸ¥DNSè§£æ]
    Network --> SG[æ£€æŸ¥å®‰å…¨ç»„]
    Network --> NACL[æ£€æŸ¥ç½‘ç»œACL]

    Check2 -->|å¦| APIError[æ£€æŸ¥APIé”™è¯¯]
    Check2 -->|æ˜¯| Check3{åŠŸèƒ½æ˜¯å¦æ­£å¸¸?}

    APIError --> Auth[è®¤è¯é—®é¢˜]
    APIError --> Throttle[é™æµé—®é¢˜]
    APIError --> Gateway[ç½‘å…³é—®é¢˜]

    Check3 -->|å¦| Function[æ£€æŸ¥Lambdaå‡½æ•°]
    Check3 -->|æ˜¯| Check4{æ€§èƒ½æ˜¯å¦è¾¾æ ‡?}

    Function --> LambdaError[Lambdaé”™è¯¯]
    Function --> Timeout[è¶…æ—¶é—®é¢˜]
    Function --> Memory[å†…å­˜é—®é¢˜]

    Check4 -->|å¦| Performance[æ€§èƒ½ä¼˜åŒ–]
    Check4 -->|æ˜¯| Check5{æ•°æ®æ˜¯å¦æ­£ç¡®?}

    Performance --> ColdStart[å†·å¯åŠ¨]
    Performance --> Concurrent[å¹¶å‘é™åˆ¶]
    Performance --> DBSlow[æ•°æ®åº“æ…¢æŸ¥è¯¢]

    Check5 -->|å¦| Data[æ•°æ®é—®é¢˜]
    Check5 -->|æ˜¯| Resolved[é—®é¢˜è§£å†³]

    Data --> Corrupt[æ•°æ®æŸå]
    Data --> Missing[æ•°æ®ä¸¢å¤±]
    Data --> Inconsistent[æ•°æ®ä¸ä¸€è‡´]
```

### å¿«é€Ÿæ£€æŸ¥å‘½ä»¤

```bash
#!/bin/bash
# quick_diagnosis.sh - å¿«é€Ÿè¯Šæ–­è„šæœ¬

echo "=== AI PPT Assistant å¿«é€Ÿè¯Šæ–­ ==="

# 1. æ£€æŸ¥API Gateway
echo "1. æ£€æŸ¥API GatewayçŠ¶æ€..."
API_ID=$(aws apigatewayv2 get-apis --query "Items[?Name=='ai-ppt-assistant-api'].ApiId" --output text)
if [ -z "$API_ID" ]; then
    echo "  âŒ API Gatewayæœªæ‰¾åˆ°"
else
    echo "  âœ… API Gateway ID: $API_ID"
    API_ENDPOINT=$(aws apigatewayv2 get-api --api-id $API_ID --query "ApiEndpoint" --output text)
    echo "  ğŸ“ Endpoint: $API_ENDPOINT"

    # æµ‹è¯•è¿æ¥
    HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" $API_ENDPOINT/health)
    if [ "$HTTP_CODE" = "200" ]; then
        echo "  âœ… APIå¥åº·æ£€æŸ¥é€šè¿‡"
    else
        echo "  âŒ APIå¥åº·æ£€æŸ¥å¤±è´¥ (HTTP $HTTP_CODE)"
    fi
fi

# 2. æ£€æŸ¥Lambdaå‡½æ•°
echo -e "\n2. æ£€æŸ¥Lambdaå‡½æ•°çŠ¶æ€..."
FUNCTIONS=("generate_ppt" "compile_ppt" "status_check" "image_generator")
for func in "${FUNCTIONS[@]}"; do
    FULL_NAME="ai-ppt-assistant-${func}"
    STATE=$(aws lambda get-function --function-name $FULL_NAME --query "Configuration.State" --output text 2>/dev/null)
    if [ "$STATE" = "Active" ]; then
        echo "  âœ… $func: Active"

        # æ£€æŸ¥æœ€è¿‘é”™è¯¯
        ERROR_COUNT=$(aws cloudwatch get-metric-statistics \
            --namespace AWS/Lambda \
            --metric-name Errors \
            --dimensions Name=FunctionName,Value=$FULL_NAME \
            --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
            --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
            --period 3600 \
            --statistics Sum \
            --query "Datapoints[0].Sum" \
            --output text)

        if [ "$ERROR_COUNT" != "None" ] && [ "$ERROR_COUNT" -gt "0" ]; then
            echo "     âš ï¸  æœ€è¿‘1å°æ—¶é”™è¯¯: $ERROR_COUNT"
        fi
    else
        echo "  âŒ $func: $STATE"
    fi
done

# 3. æ£€æŸ¥DynamoDB
echo -e "\n3. æ£€æŸ¥DynamoDBçŠ¶æ€..."
TABLE_STATUS=$(aws dynamodb describe-table --table-name ai-ppt-presentations --query "Table.TableStatus" --output text 2>/dev/null)
if [ "$TABLE_STATUS" = "ACTIVE" ]; then
    echo "  âœ… DynamoDBè¡¨: ACTIVE"

    # æ£€æŸ¥é™æµ
    THROTTLES=$(aws cloudwatch get-metric-statistics \
        --namespace AWS/DynamoDB \
        --metric-name UserErrors \
        --dimensions Name=TableName,Value=ai-ppt-presentations \
        --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
        --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
        --period 3600 \
        --statistics Sum \
        --query "Datapoints[0].Sum" \
        --output text)

    if [ "$THROTTLES" != "None" ] && [ "$THROTTLES" -gt "0" ]; then
        echo "     âš ï¸  æœ€è¿‘1å°æ—¶é™æµ: $THROTTLES"
    fi
else
    echo "  âŒ DynamoDBè¡¨: $TABLE_STATUS"
fi

# 4. æ£€æŸ¥S3
echo -e "\n4. æ£€æŸ¥S3å­˜å‚¨æ¡¶..."
BUCKET_NAME="ai-ppt-presentations-prod"
if aws s3api head-bucket --bucket $BUCKET_NAME 2>/dev/null; then
    echo "  âœ… S3å­˜å‚¨æ¡¶å¯è®¿é—®"

    # æ£€æŸ¥å­˜å‚¨æ¡¶å¤§å°
    SIZE=$(aws s3 ls s3://$BUCKET_NAME --recursive --summarize | grep "Total Size" | cut -d: -f2)
    echo "     ğŸ“Š æ€»å¤§å°: $SIZE bytes"
else
    echo "  âŒ S3å­˜å‚¨æ¡¶ä¸å¯è®¿é—®"
fi

# 5. æ£€æŸ¥CloudWatchå‘Šè­¦
echo -e "\n5. æ£€æŸ¥æ´»è·ƒå‘Šè­¦..."
ALARMS=$(aws cloudwatch describe-alarms --state-value ALARM --query "MetricAlarms[?starts_with(AlarmName, 'ai-ppt')].[AlarmName,StateReason]" --output text)
if [ -z "$ALARMS" ]; then
    echo "  âœ… æ²¡æœ‰æ´»è·ƒå‘Šè­¦"
else
    echo "  âš ï¸  æ´»è·ƒå‘Šè­¦:"
    echo "$ALARMS" | while read name reason; do
        echo "     - $name: $reason"
    done
fi

echo -e "\n=== è¯Šæ–­å®Œæˆ ==="
```

## å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

### 1. API Gatewayé—®é¢˜

#### é—®é¢˜ï¼š403 Forbiddené”™è¯¯

**ç—‡çŠ¶**ï¼š
- APIè°ƒç”¨è¿”å›403é”™è¯¯
- é”™è¯¯ä¿¡æ¯ï¼š"User is not authorized to access this resource"

**åŸå› **ï¼š
1. APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ
2. IAMæƒé™ä¸è¶³
3. CORSé…ç½®é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# æ£€æŸ¥APIå¯†é’¥
import boto3

api_gateway = boto3.client('apigatewayv2')

# è·å–APIå¯†é’¥ä¿¡æ¯
def check_api_keys(api_id):
    """æ£€æŸ¥APIå¯†é’¥çŠ¶æ€"""
    response = api_gateway.get_api_keys(
        apiId=api_id,
        includeValues=False
    )

    for key in response['Items']:
        print(f"Key ID: {key['Id']}")
        print(f"Enabled: {key['Enabled']}")
        print(f"Created: {key['CreatedDate']}")

        # æ£€æŸ¥ä½¿ç”¨è®¡åˆ’
        usage_plans = api_gateway.get_usage_plan_keys(
            usagePlanId=key.get('StageKeys', [{}])[0].get('RestApiId')
        )
        print(f"Usage Plans: {usage_plans}")

# ä¿®å¤CORSé…ç½®
def fix_cors(api_id, route_id):
    """ä¿®å¤CORSé…ç½®"""
    api_gateway.update_route(
        ApiId=api_id,
        RouteId=route_id,
        RouteResponseSelectionExpression='$default',
        AuthorizationType='NONE',  # æˆ– 'JWT'
        CorsConfiguration={
            'AllowOrigins': ['*'],
            'AllowMethods': ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
            'AllowHeaders': ['*'],
            'ExposeHeaders': ['*'],
            'MaxAge': 86400
        }
    )
```

#### é—®é¢˜ï¼š429 Too Many Requests

**ç—‡çŠ¶**ï¼š
- APIè¿”å›429é”™è¯¯
- é”™è¯¯ä¿¡æ¯ï¼š"Rate limit exceeded"

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# ä¸´æ—¶å¢åŠ é™æµé…ç½®
aws apigatewayv2 update-stage \
    --api-id $API_ID \
    --stage-name prod \
    --throttle-settings '{
        "RateLimit": 10000,
        "BurstLimit": 20000
    }'

# ä¸ºç‰¹å®šè·¯ç”±è®¾ç½®é™æµ
aws apigatewayv2 update-route \
    --api-id $API_ID \
    --route-id $ROUTE_ID \
    --throttle-settings '{
        "RateLimit": 1000,
        "BurstLimit": 2000
    }'
```

### 2. Lambdaå‡½æ•°é—®é¢˜

#### é—®é¢˜ï¼šLambdaè¶…æ—¶

**ç—‡çŠ¶**ï¼š
- å‡½æ•°æ‰§è¡Œè¶…è¿‡é…ç½®çš„è¶…æ—¶æ—¶é—´
- CloudWatchæ—¥å¿—æ˜¾ç¤ºï¼š"Task timed out after X seconds"

**è¯Šæ–­è„šæœ¬**ï¼š

```python
# diagnose_lambda_timeout.py

import boto3
import json
from datetime import datetime, timedelta

def analyze_lambda_timeouts(function_name, hours=24):
    """åˆ†æLambdaè¶…æ—¶é—®é¢˜"""

    logs = boto3.client('logs')
    lambda_client = boto3.client('lambda')

    # è·å–å‡½æ•°é…ç½®
    config = lambda_client.get_function_configuration(
        FunctionName=function_name
    )
    print(f"å½“å‰è¶…æ—¶è®¾ç½®: {config['Timeout']}ç§’")
    print(f"å†…å­˜é…ç½®: {config['MemorySize']}MB")

    # æŸ¥è¯¢è¶…æ—¶æ—¥å¿—
    log_group = f'/aws/lambda/{function_name}'
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=hours)

    query = """
    fields @timestamp, @duration, @message
    | filter @message like /Task timed out/
    | stats count() as timeout_count, avg(@duration) as avg_duration, max(@duration) as max_duration
    """

    response = logs.start_query(
        logGroupName=log_group,
        startTime=int(start_time.timestamp()),
        endTime=int(end_time.timestamp()),
        queryString=query
    )

    # ç­‰å¾…æŸ¥è¯¢å®Œæˆ
    query_id = response['queryId']
    status = 'Running'

    while status == 'Running':
        response = logs.get_query_results(queryId=query_id)
        status = response['status']
        time.sleep(1)

    # åˆ†æç»“æœ
    if response['results']:
        stats = response['results'][0]
        print(f"\nè¿‡å»{hours}å°æ—¶è¶…æ—¶ç»Ÿè®¡:")
        for stat in stats:
            print(f"  {stat['field']}: {stat['value']}")

        # å»ºè®®
        max_duration = float(stats[2]['value']) if len(stats) > 2 else config['Timeout']
        recommended_timeout = int(max_duration * 1.5)
        print(f"\nå»ºè®®:")
        print(f"  - å°†è¶…æ—¶æ—¶é—´å¢åŠ åˆ°: {recommended_timeout}ç§’")

        if config['MemorySize'] < 1024:
            print(f"  - è€ƒè™‘å¢åŠ å†…å­˜åˆ°: 1024MB (å¯èƒ½æé«˜CPUæ€§èƒ½)")

# ä½¿ç”¨ç¤ºä¾‹
analyze_lambda_timeouts('ai-ppt-assistant-generate_ppt')
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# å¢åŠ è¶…æ—¶æ—¶é—´
aws lambda update-function-configuration \
    --function-name ai-ppt-assistant-generate_ppt \
    --timeout 300

# å¢åŠ å†…å­˜ï¼ˆåŒæ—¶å¢åŠ CPUï¼‰
aws lambda update-function-configuration \
    --function-name ai-ppt-assistant-generate_ppt \
    --memory-size 3008
```

#### é—®é¢˜ï¼šLambdaå†…å­˜ä¸è¶³

**ç—‡çŠ¶**ï¼š
- CloudWatchæ—¥å¿—ï¼š"Runtime.ExitError"
- æ—¥å¿—æ˜¾ç¤ºï¼š"Runtime exited with error: signal: killed"

**è¯Šæ–­å’Œè§£å†³**ï¼š

```python
# memory_analysis.py

def analyze_memory_usage(function_name):
    """åˆ†æLambdaå†…å­˜ä½¿ç”¨æƒ…å†µ"""

    cloudwatch = boto3.client('cloudwatch')

    # è·å–å†…å­˜ä½¿ç”¨ç»Ÿè®¡
    response = cloudwatch.get_metric_statistics(
        Namespace='AWS/Lambda',
        MetricName='Duration',
        Dimensions=[
            {'Name': 'FunctionName', 'Value': function_name}
        ],
        StartTime=datetime.utcnow() - timedelta(hours=1),
        EndTime=datetime.utcnow(),
        Period=300,
        Statistics=['Average', 'Maximum']
    )

    # æŸ¥è¯¢å®é™…å†…å­˜ä½¿ç”¨
    logs = boto3.client('logs')
    log_group = f'/aws/lambda/{function_name}'

    query = """
    fields @timestamp, @memorySize, @maxMemoryUsed
    | filter @type = "REPORT"
    | stats avg(@maxMemoryUsed) as avg_memory, max(@maxMemoryUsed) as max_memory, @memorySize as allocated
    """

    # æ‰§è¡ŒæŸ¥è¯¢...

    print(f"å†…å­˜ä½¿ç”¨åˆ†æ:")
    print(f"  åˆ†é…å†…å­˜: {allocated}MB")
    print(f"  å¹³å‡ä½¿ç”¨: {avg_memory}MB")
    print(f"  æœ€å¤§ä½¿ç”¨: {max_memory}MB")
    print(f"  ä½¿ç”¨ç‡: {(max_memory/allocated)*100:.1f}%")

    if max_memory > allocated * 0.9:
        print("âš ï¸ å†…å­˜ä½¿ç”¨æ¥è¿‘ä¸Šé™ï¼Œå»ºè®®å¢åŠ å†…å­˜é…ç½®")
```

### 3. DynamoDBé—®é¢˜

#### é—®é¢˜ï¼šDynamoDBé™æµ

**ç—‡çŠ¶**ï¼š
- ProvisionedThroughputExceededExceptioné”™è¯¯
- è¯·æ±‚è¢«é™æµ

**è§£å†³æ–¹æ¡ˆ**ï¼š

```python
# fix_dynamodb_throttling.py

def fix_throttling(table_name):
    """ä¿®å¤DynamoDBé™æµé—®é¢˜"""

    dynamodb = boto3.client('dynamodb')

    # æ£€æŸ¥å½“å‰å®¹é‡
    table = dynamodb.describe_table(TableName=table_name)
    billing_mode = table['Table'].get('BillingModeSummary', {}).get('BillingMode')

    if billing_mode == 'PROVISIONED':
        # å¢åŠ é¢„ç½®å®¹é‡
        dynamodb.update_table(
            TableName=table_name,
            ProvisionedThroughput={
                'ReadCapacityUnits': 100,
                'WriteCapacityUnits': 100
            }
        )
        print("å·²å¢åŠ é¢„ç½®å®¹é‡")
    else:
        # åˆ‡æ¢åˆ°æŒ‰éœ€æ¨¡å¼
        dynamodb.update_table(
            TableName=table_name,
            BillingMode='PAY_PER_REQUEST'
        )
        print("å·²åˆ‡æ¢åˆ°æŒ‰éœ€è®¡è´¹æ¨¡å¼")

    # é…ç½®è‡ªåŠ¨æ‰©å±•
    autoscaling = boto3.client('application-autoscaling')

    autoscaling.register_scalable_target(
        ServiceNamespace='dynamodb',
        ResourceId=f'table/{table_name}',
        ScalableDimension='dynamodb:table:ReadCapacityUnits',
        MinCapacity=5,
        MaxCapacity=40000
    )

    autoscaling.put_scaling_policy(
        PolicyName=f'{table_name}-read-scaling',
        ServiceNamespace='dynamodb',
        ResourceId=f'table/{table_name}',
        ScalableDimension='dynamodb:table:ReadCapacityUnits',
        PolicyType='TargetTrackingScaling',
        TargetTrackingScalingPolicyConfiguration={
            'TargetValue': 70.0,
            'PredefinedMetricSpecification': {
                'PredefinedMetricType': 'DynamoDBReadCapacityUtilization'
            }
        }
    )
```

### 4. Bedrockç›¸å…³é—®é¢˜

#### é—®é¢˜ï¼šBedrockæ¨¡å‹è°ƒç”¨å¤±è´¥

**ç—‡çŠ¶**ï¼š
- "ModelNotReadyException"é”™è¯¯
- "ThrottlingException"é”™è¯¯

**è¯Šæ–­è„šæœ¬**ï¼š

```python
# diagnose_bedrock.py

import boto3
import time

def test_bedrock_model(model_id='anthropic.claude-3-sonnet-20240229-v1:0'):
    """æµ‹è¯•Bedrockæ¨¡å‹å¯ç”¨æ€§"""

    bedrock = boto3.client('bedrock-runtime')

    test_prompt = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 100,
        "messages": [
            {
                "role": "user",
                "content": "Hello, please respond with 'OK' if you're working."
            }
        ]
    }

    try:
        # æµ‹è¯•æ¨¡å‹è°ƒç”¨
        start_time = time.time()
        response = bedrock.invoke_model(
            modelId=model_id,
            contentType='application/json',
            accept='application/json',
            body=json.dumps(test_prompt)
        )
        elapsed = time.time() - start_time

        result = json.loads(response['body'].read())
        print(f"âœ… æ¨¡å‹å“åº”æ­£å¸¸")
        print(f"   å“åº”æ—¶é—´: {elapsed:.2f}ç§’")
        print(f"   Tokenä½¿ç”¨: {result.get('usage', {})}")

    except Exception as e:
        print(f"âŒ æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")

        if 'ThrottlingException' in str(e):
            print("   å»ºè®®: å®æ–½é‡è¯•é€»è¾‘å’Œè¯·æ±‚é™æµ")
        elif 'ModelNotReadyException' in str(e):
            print("   å»ºè®®: ç­‰å¾…æ¨¡å‹å‡†å¤‡å°±ç»ªæˆ–åˆ‡æ¢åˆ°å…¶ä»–åŒºåŸŸ")

# æµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹
def test_all_models():
    """æµ‹è¯•æ‰€æœ‰å¯ç”¨çš„Bedrockæ¨¡å‹"""

    bedrock = boto3.client('bedrock')

    models = bedrock.list_foundation_models()
    for model in models['modelSummaries']:
        if model['modelLifecycle']['status'] == 'ACTIVE':
            print(f"\næµ‹è¯•æ¨¡å‹: {model['modelId']}")
            test_bedrock_model(model['modelId'])
            time.sleep(1)  # é¿å…é™æµ
```

## é”™è¯¯ä»£ç å‚è€ƒ

### HTTPçŠ¶æ€ç 

| çŠ¶æ€ç  | å«ä¹‰ | å¸¸è§åŸå›  | è§£å†³æ–¹æ³• |
|--------|------|----------|----------|
| **400** | Bad Request | è¯·æ±‚å‚æ•°é”™è¯¯ | æ£€æŸ¥è¯·æ±‚æ ¼å¼å’Œå‚æ•° |
| **401** | Unauthorized | è®¤è¯å¤±è´¥ | æ£€æŸ¥APIå¯†é’¥æˆ–Token |
| **403** | Forbidden | æƒé™ä¸è¶³ | æ£€æŸ¥IAMæƒé™ |
| **404** | Not Found | èµ„æºä¸å­˜åœ¨ | éªŒè¯èµ„æºIDå’Œè·¯å¾„ |
| **429** | Too Many Requests | é™æµ | å®æ–½é‡è¯•é€»è¾‘ |
| **500** | Internal Server Error | æœåŠ¡å™¨é”™è¯¯ | æ£€æŸ¥Lambdaæ—¥å¿— |
| **502** | Bad Gateway | ç½‘å…³é”™è¯¯ | æ£€æŸ¥Lambdaå‡½æ•°çŠ¶æ€ |
| **503** | Service Unavailable | æœåŠ¡ä¸å¯ç”¨ | æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€ |
| **504** | Gateway Timeout | ç½‘å…³è¶…æ—¶ | å¢åŠ è¶…æ—¶é…ç½® |

### è‡ªå®šä¹‰é”™è¯¯ä»£ç 

```python
# error_codes.py

class ErrorCodes:
    """è‡ªå®šä¹‰é”™è¯¯ä»£ç å®šä¹‰"""

    # 1000-1999: è¾“å…¥éªŒè¯é”™è¯¯
    INVALID_TOPIC = 1001       # ä¸»é¢˜æ— æ•ˆ
    INVALID_PAGE_COUNT = 1002  # é¡µæ•°æ— æ•ˆ
    INVALID_TEMPLATE = 1003    # æ¨¡æ¿æ— æ•ˆ

    # 2000-2999: ä¸šåŠ¡é€»è¾‘é”™è¯¯
    PPT_GENERATION_FAILED = 2001  # PPTç”Ÿæˆå¤±è´¥
    IMAGE_GENERATION_FAILED = 2002 # å›¾åƒç”Ÿæˆå¤±è´¥
    CONTENT_TOO_LONG = 2003        # å†…å®¹è¿‡é•¿

    # 3000-3999: ç³»ç»Ÿé”™è¯¯
    DATABASE_ERROR = 3001      # æ•°æ®åº“é”™è¯¯
    S3_UPLOAD_FAILED = 3002    # S3ä¸Šä¼ å¤±è´¥
    BEDROCK_ERROR = 3003       # Bedrockè°ƒç”¨å¤±è´¥

    # 4000-4999: å¤–éƒ¨æœåŠ¡é”™è¯¯
    EXTERNAL_API_ERROR = 4001  # å¤–éƒ¨APIé”™è¯¯
    NETWORK_ERROR = 4002       # ç½‘ç»œé”™è¯¯

    @staticmethod
    def get_message(code):
        """è·å–é”™è¯¯æ¶ˆæ¯"""
        messages = {
            1001: "æä¾›çš„ä¸»é¢˜æ— æ•ˆæˆ–åŒ…å«ä¸æ”¯æŒçš„å­—ç¬¦",
            1002: "é¡µæ•°å¿…é¡»åœ¨1-50ä¹‹é—´",
            1003: "æŒ‡å®šçš„æ¨¡æ¿ä¸å­˜åœ¨",
            2001: "PPTç”Ÿæˆè¿‡ç¨‹å¤±è´¥ï¼Œè¯·é‡è¯•",
            2002: "å›¾åƒç”Ÿæˆå¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤å›¾åƒ",
            2003: "ç”Ÿæˆçš„å†…å®¹è¶…è¿‡æœ€å¤§é•¿åº¦é™åˆ¶",
            3001: "æ•°æ®åº“æ“ä½œå¤±è´¥",
            3002: "æ–‡ä»¶ä¸Šä¼ åˆ°S3å¤±è´¥",
            3003: "BedrockæœåŠ¡è°ƒç”¨å¤±è´¥",
            4001: "å¤–éƒ¨APIæœåŠ¡ä¸å¯ç”¨",
            4002: "ç½‘ç»œè¿æ¥é”™è¯¯"
        }
        return messages.get(code, "æœªçŸ¥é”™è¯¯")
```

## æ€§èƒ½é—®é¢˜è¯Šæ–­

### Lambdaå†·å¯åŠ¨ä¼˜åŒ–

```python
# cold_start_analysis.py

def analyze_cold_starts(function_name, hours=24):
    """åˆ†æLambdaå†·å¯åŠ¨æƒ…å†µ"""

    logs = boto3.client('logs')
    log_group = f'/aws/lambda/{function_name}'

    # CloudWatch InsightsæŸ¥è¯¢
    query = """
    fields @timestamp, @duration, @initDuration
    | filter @type = "REPORT"
    | filter @initDuration > 0
    | stats count() as cold_starts,
            avg(@initDuration) as avg_init_time,
            max(@initDuration) as max_init_time,
            avg(@duration) as avg_total_duration
    """

    # æ‰§è¡ŒæŸ¥è¯¢...

    print(f"å†·å¯åŠ¨åˆ†æ ({hours}å°æ—¶):")
    print(f"  å†·å¯åŠ¨æ¬¡æ•°: {cold_starts}")
    print(f"  å¹³å‡åˆå§‹åŒ–æ—¶é—´: {avg_init_time:.0f}ms")
    print(f"  æœ€å¤§åˆå§‹åŒ–æ—¶é—´: {max_init_time:.0f}ms")

    # ä¼˜åŒ–å»ºè®®
    if avg_init_time > 1000:
        print("\nä¼˜åŒ–å»ºè®®:")
        print("  1. å¯ç”¨é¢„ç•™å¹¶å‘")
        print("  2. å‡å°‘ä¾èµ–åŒ…å¤§å°")
        print("  3. ä½¿ç”¨Lambdaå±‚")
        print("  4. ä¼˜åŒ–åˆå§‹åŒ–ä»£ç ")

        # è‡ªåŠ¨é…ç½®é¢„ç•™å¹¶å‘
        lambda_client = boto3.client('lambda')
        lambda_client.put_provisioned_concurrency_config(
            FunctionName=function_name,
            ProvisionedConcurrentExecutions=5,
            Qualifier='$LATEST'
        )
        print("\nâœ… å·²é…ç½®5ä¸ªé¢„ç•™å¹¶å‘å®ä¾‹")
```

### æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–

```python
# db_performance_analysis.py

def analyze_db_performance(table_name):
    """åˆ†æDynamoDBæ€§èƒ½"""

    cloudwatch = boto3.client('cloudwatch')

    metrics = [
        'ConsumedReadCapacityUnits',
        'ConsumedWriteCapacityUnits',
        'SuccessfulRequestLatency',
        'ThrottledRequests'
    ]

    for metric in metrics:
        response = cloudwatch.get_metric_statistics(
            Namespace='AWS/DynamoDB',
            MetricName=metric,
            Dimensions=[
                {'Name': 'TableName', 'Value': table_name}
            ],
            StartTime=datetime.utcnow() - timedelta(hours=1),
            EndTime=datetime.utcnow(),
            Period=300,
            Statistics=['Average', 'Maximum', 'Sum']
        )

        if response['Datapoints']:
            data = response['Datapoints'][0]
            print(f"\n{metric}:")
            for stat in ['Average', 'Maximum', 'Sum']:
                if stat in data:
                    print(f"  {stat}: {data[stat]:.2f}")

    # æŸ¥è¯¢æ¨¡å¼åˆ†æ
    print("\nå¸¸è§æŸ¥è¯¢æ¨¡å¼ä¼˜åŒ–å»ºè®®:")
    print("  1. ä½¿ç”¨æ‰¹é‡æ“ä½œå‡å°‘è¯·æ±‚æ¬¡æ•°")
    print("  2. å®æ–½æŸ¥è¯¢ç»“æœç¼“å­˜")
    print("  3. ä½¿ç”¨æŠ•å½±è¡¨è¾¾å¼å‡å°‘æ•°æ®ä¼ è¾“")
    print("  4. è€ƒè™‘ä½¿ç”¨å…¨å±€äºŒçº§ç´¢å¼•")
```

## æ—¥å¿—åˆ†ææŠ€å·§

### CloudWatch InsightsæŸ¥è¯¢ç¤ºä¾‹

```sql
-- æŸ¥æ‰¾æœ€æ…¢çš„è¯·æ±‚
fields @timestamp, @duration, @message
| filter @type = "REPORT"
| sort @duration desc
| limit 20

-- åˆ†æé”™è¯¯åˆ†å¸ƒ
fields @timestamp, @message
| filter @message like /ERROR/
| parse @message /ERROR.*: (?<error_message>.*)/
| stats count() by error_message

-- è¿½è¸ªç‰¹å®šè¯·æ±‚
fields @timestamp, @message, @requestId
| filter @requestId = "abc-123-def"
| sort @timestamp asc

-- ç»Ÿè®¡æ¯å°æ—¶è¯·æ±‚é‡
fields @timestamp
| filter @type = "REPORT"
| stats count() by bin(1h)

-- åˆ†æå†…å­˜ä½¿ç”¨è¶‹åŠ¿
fields @timestamp, @maxMemoryUsed, @memorySize
| filter @type = "REPORT"
| stats avg(@maxMemoryUsed/@memorySize * 100) as memory_usage_percent by bin(5m)
```

### æ—¥å¿—èšåˆè„šæœ¬

```python
# log_aggregator.py

import boto3
from collections import defaultdict

def aggregate_errors(log_group, hours=24):
    """èšåˆé”™è¯¯æ—¥å¿—"""

    logs = boto3.client('logs')

    # è·å–æ‰€æœ‰é”™è¯¯
    query = """
    fields @timestamp, @message, @logStream
    | filter @message like /ERROR|Exception|Failed/
    | limit 1000
    """

    # æ‰§è¡ŒæŸ¥è¯¢å¹¶å¤„ç†ç»“æœ...

    # åˆ†ç±»é”™è¯¯
    error_categories = defaultdict(list)

    for log in results:
        message = log['@message']

        if 'TimeoutError' in message:
            error_categories['timeout'].append(log)
        elif 'MemoryError' in message:
            error_categories['memory'].append(log)
        elif 'ThrottlingException' in message:
            error_categories['throttling'].append(log)
        elif 'ValidationException' in message:
            error_categories['validation'].append(log)
        else:
            error_categories['other'].append(log)

    # ç”ŸæˆæŠ¥å‘Š
    print("é”™è¯¯åˆ†ç±»ç»Ÿè®¡:")
    for category, logs in error_categories.items():
        print(f"  {category}: {len(logs)} æ¬¡")

        if logs:
            print(f"    æœ€è¿‘ç¤ºä¾‹: {logs[0]['@message'][:100]}...")

    return error_categories
```

## è°ƒè¯•å·¥å…·ä½¿ç”¨

### AWS X-Rayè¿½è¸ª

```python
# xray_trace_analysis.py

import boto3

def analyze_traces(service_name, hours=1):
    """åˆ†æX-Rayè¿½è¸ªæ•°æ®"""

    xray = boto3.client('xray')

    # è·å–è¿½è¸ªæ‘˜è¦
    response = xray.get_trace_summaries(
        TimeRangeType='LastHours',
        TimeRange={'Hours': hours},
        FilterExpression=f'service("{service_name}")'
    )

    slow_traces = []
    error_traces = []

    for trace in response['TraceSummaries']:
        duration = trace.get('Duration', 0)

        if duration > 5:  # è¶…è¿‡5ç§’
            slow_traces.append(trace)

        if trace.get('HasError'):
            error_traces.append(trace)

    print(f"X-Rayè¿½è¸ªåˆ†æ (æœ€è¿‘{hours}å°æ—¶):")
    print(f"  æ€»è¿½è¸ªæ•°: {len(response['TraceSummaries'])}")
    print(f"  æ…¢è¯·æ±‚: {len(slow_traces)}")
    print(f"  é”™è¯¯è¯·æ±‚: {len(error_traces)}")

    # åˆ†ææ…¢è¯·æ±‚
    if slow_traces:
        print("\næœ€æ…¢çš„5ä¸ªè¯·æ±‚:")
        for trace in sorted(slow_traces, key=lambda x: x['Duration'], reverse=True)[:5]:
            print(f"  - ID: {trace['Id']}")
            print(f"    Duration: {trace['Duration']:.2f}s")
            print(f"    URL: {trace.get('Http', {}).get('HttpURL', 'N/A')}")

    # åˆ†æé”™è¯¯
    if error_traces:
        print("\næœ€è¿‘çš„é”™è¯¯:")
        for trace in error_traces[:5]:
            # è·å–è¯¦ç»†è¿½è¸ª
            detail = xray.get_trace_graph(TraceIds=[trace['Id']])
            for service in detail['Services']:
                if service.get('ErrorStatistics', {}).get('TotalCount', 0) > 0:
                    print(f"  - Service: {service['Name']}")
                    print(f"    Errors: {service['ErrorStatistics']}")
```

### æœ¬åœ°è°ƒè¯•ç¯å¢ƒ

```python
# local_debug.py

import os
import sys
import json
from unittest.mock import Mock, patch

class LocalDebugger:
    """æœ¬åœ°è°ƒè¯•å·¥å…·"""

    def __init__(self):
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['AWS_REGION'] = 'us-east-1'
        os.environ['ENVIRONMENT'] = 'local'
        os.environ['DYNAMODB_TABLE'] = 'ai-ppt-presentations-local'
        os.environ['S3_BUCKET'] = 'ai-ppt-local'

    def mock_aws_services(self):
        """æ¨¡æ‹ŸAWSæœåŠ¡"""

        # æ¨¡æ‹ŸDynamoDB
        mock_dynamodb = Mock()
        mock_dynamodb.put_item.return_value = {'ResponseMetadata': {'HTTPStatusCode': 200}}
        mock_dynamodb.get_item.return_value = {
            'Item': {
                'presentation_id': {'S': 'test-123'},
                'status': {'S': 'completed'}
            }
        }

        # æ¨¡æ‹ŸS3
        mock_s3 = Mock()
        mock_s3.upload_fileobj.return_value = None
        mock_s3.generate_presigned_url.return_value = 'https://mock-url.com/file.pptx'

        # æ¨¡æ‹ŸBedrock
        mock_bedrock = Mock()
        mock_bedrock.invoke_model.return_value = {
            'body': json.dumps({
                'content': [{'text': 'Generated content'}]
            }).encode()
        }

        return {
            'dynamodb': mock_dynamodb,
            's3': mock_s3,
            'bedrock': mock_bedrock
        }

    def test_lambda_handler(self, handler, event):
        """æµ‹è¯•Lambdaå¤„ç†å™¨"""

        # åˆ›å»ºæ¨¡æ‹Ÿcontext
        context = Mock()
        context.aws_request_id = 'test-request-id'
        context.invoked_function_arn = 'arn:aws:lambda:test'
        context.get_remaining_time_in_millis = Mock(return_value=300000)

        # æ¨¡æ‹ŸAWSæœåŠ¡
        mocks = self.mock_aws_services()

        with patch('boto3.client') as mock_client:
            def client_side_effect(service):
                return mocks.get(service, Mock())

            mock_client.side_effect = client_side_effect

            # æ‰§è¡Œå¤„ç†å™¨
            try:
                result = handler(event, context)
                print(f"âœ… æ‰§è¡ŒæˆåŠŸ:")
                print(json.dumps(result, indent=2))
                return result
            except Exception as e:
                print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                raise

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    debugger = LocalDebugger()

    # å¯¼å…¥Lambdaå‡½æ•°
    sys.path.insert(0, '../lambdas')
    from generate_ppt import handler

    # åˆ›å»ºæµ‹è¯•äº‹ä»¶
    test_event = {
        'body': json.dumps({
            'topic': 'AI Technology Trends',
            'pages': 5
        })
    }

    # æµ‹è¯•
    result = debugger.test_lambda_handler(handler, test_event)
```

## ç´§æ€¥ä¿®å¤æµç¨‹

### ç´§æ€¥å›æ»šè„šæœ¬

```bash
#!/bin/bash
# emergency_rollback.sh

set -e

FUNCTION_NAME=$1
VERSION=$2

if [ -z "$FUNCTION_NAME" ] || [ -z "$VERSION" ]; then
    echo "Usage: ./emergency_rollback.sh <function_name> <version>"
    exit 1
fi

echo "ğŸš¨ æ‰§è¡Œç´§æ€¥å›æ»š..."

# 1. æ›´æ–°Lambdaåˆ«å
echo "å›æ»šLambdaå‡½æ•°åˆ°ç‰ˆæœ¬ $VERSION..."
aws lambda update-alias \
    --function-name $FUNCTION_NAME \
    --name PROD \
    --function-version $VERSION

# 2. éªŒè¯å›æ»š
echo "éªŒè¯å›æ»š..."
CURRENT_VERSION=$(aws lambda get-alias --function-name $FUNCTION_NAME --name PROD --query "FunctionVersion" --output text)

if [ "$CURRENT_VERSION" = "$VERSION" ]; then
    echo "âœ… å›æ»šæˆåŠŸ"
else
    echo "âŒ å›æ»šå¤±è´¥"
    exit 1
fi

# 3. æµ‹è¯•åŠŸèƒ½
echo "æµ‹è¯•åŠŸèƒ½..."
aws lambda invoke \
    --function-name $FUNCTION_NAME \
    --qualifier PROD \
    --payload '{"test": true}' \
    response.json

if [ $? -eq 0 ]; then
    echo "âœ… åŠŸèƒ½æµ‹è¯•é€šè¿‡"
else
    echo "âŒ åŠŸèƒ½æµ‹è¯•å¤±è´¥"
fi

# 4. å‘é€é€šçŸ¥
aws sns publish \
    --topic-arn arn:aws:sns:us-east-1:123456789012:ops-alerts \
    --subject "ç´§æ€¥å›æ»šå®Œæˆ" \
    --message "å‡½æ•° $FUNCTION_NAME å·²å›æ»šåˆ°ç‰ˆæœ¬ $VERSION"

echo "ğŸ‰ ç´§æ€¥å›æ»šå®Œæˆ"
```

### çƒ­ä¿®å¤æµç¨‹

```python
# hotfix.py

import boto3
import zipfile
import io

def apply_hotfix(function_name, fix_code):
    """åº”ç”¨çƒ­ä¿®å¤"""

    lambda_client = boto3.client('lambda')

    # 1. ä¸‹è½½å½“å‰ä»£ç 
    response = lambda_client.get_function(
        FunctionName=function_name,
        Qualifier='$LATEST'
    )

    code_url = response['Code']['Location']

    # 2. ä¸‹è½½å¹¶è§£å‹ä»£ç 
    import requests
    r = requests.get(code_url)
    zip_content = io.BytesIO(r.content)

    with zipfile.ZipFile(zip_content, 'r') as zip_ref:
        # è¯»å–æ‰€æœ‰æ–‡ä»¶
        file_list = zip_ref.namelist()

    # 3. åˆ›å»ºæ–°çš„zipåŒ…
    new_zip = io.BytesIO()

    with zipfile.ZipFile(new_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
        # å¤åˆ¶åŸæœ‰æ–‡ä»¶
        with zipfile.ZipFile(zip_content, 'r') as zip_ref:
            for file in file_list:
                if file != 'lambda_function.py':  # è·³è¿‡è¦ä¿®æ”¹çš„æ–‡ä»¶
                    zipf.writestr(file, zip_ref.read(file))

        # æ·»åŠ ä¿®å¤ä»£ç 
        zipf.writestr('lambda_function.py', fix_code)

    # 4. æ›´æ–°Lambdaå‡½æ•°
    new_zip.seek(0)

    response = lambda_client.update_function_code(
        FunctionName=function_name,
        ZipFile=new_zip.read(),
        Publish=True
    )

    new_version = response['Version']
    print(f"çƒ­ä¿®å¤å·²åº”ç”¨ï¼Œæ–°ç‰ˆæœ¬: {new_version}")

    # 5. æ›´æ–°åˆ«å
    lambda_client.update_alias(
        FunctionName=function_name,
        Name='PROD',
        FunctionVersion=new_version
    )

    return new_version
```

## é—®é¢˜ä¸ŠæŠ¥æ¨¡æ¿

### é—®é¢˜æŠ¥å‘Šæ¨¡æ¿

```markdown
# é—®é¢˜æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **æŠ¥å‘Šäºº**: [å§“å]
- **æ—¥æœŸæ—¶é—´**: [YYYY-MM-DD HH:MM:SS UTC]
- **ä¸¥é‡çº§åˆ«**: [P0/P1/P2/P3/P4]
- **å½±å“èŒƒå›´**: [å—å½±å“çš„ç”¨æˆ·æ•°/åŠŸèƒ½]

## é—®é¢˜æè¿°
[è¯¦ç»†æè¿°é—®é¢˜ç°è±¡]

## é‡ç°æ­¥éª¤
1. [æ­¥éª¤1]
2. [æ­¥éª¤2]
3. [æ­¥éª¤3]

## é¢„æœŸè¡Œä¸º
[æè¿°æ­£å¸¸æƒ…å†µä¸‹çš„é¢„æœŸè¡Œä¸º]

## å®é™…è¡Œä¸º
[æè¿°å®é™…å‘ç”Ÿçš„è¡Œä¸º]

## é”™è¯¯ä¿¡æ¯
```
[ç²˜è´´é”™è¯¯æ—¥å¿—æˆ–æˆªå›¾]
```

## ç¯å¢ƒä¿¡æ¯
- **ç¯å¢ƒ**: [dev/staging/prod]
- **åŒºåŸŸ**: [us-east-1]
- **æœåŠ¡**: [å…·ä½“çš„Lambdaå‡½æ•°/APIç«¯ç‚¹]
- **è¯·æ±‚ID**: [å¦‚æœæœ‰]
- **è¿½è¸ªID**: [X-Rayè¿½è¸ªID]

## è¯Šæ–­æ­¥éª¤å·²æ‰§è¡Œ
- [ ] æ£€æŸ¥CloudWatchæ—¥å¿—
- [ ] æŸ¥çœ‹X-Rayè¿½è¸ª
- [ ] éªŒè¯é…ç½®
- [ ] æµ‹è¯•å…¶ä»–ç¯å¢ƒ

## ä¸´æ—¶è§£å†³æ–¹æ¡ˆ
[å¦‚æœæœ‰ä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼Œè¯·æè¿°]

## æ ¹æœ¬åŸå› åˆ†æ
[å¦‚æœå·²çŸ¥ï¼Œæè¿°æ ¹æœ¬åŸå› ]

## å»ºè®®ä¿®å¤æ–¹æ¡ˆ
[æå‡ºä¿®å¤å»ºè®®]

## é™„ä»¶
- [æ—¥å¿—æ–‡ä»¶]
- [æˆªå›¾]
- [é…ç½®æ–‡ä»¶]
```

### è‡ªåŠ¨åŒ–é—®é¢˜æ”¶é›†

```python
# issue_collector.py

import boto3
import json
from datetime import datetime

class IssueCollector:
    """è‡ªåŠ¨æ”¶é›†é—®é¢˜ä¿¡æ¯"""

    def __init__(self, issue_id):
        self.issue_id = issue_id
        self.report = {
            'issue_id': issue_id,
            'timestamp': datetime.utcnow().isoformat(),
            'diagnostics': {}
        }

    def collect_logs(self, function_name, request_id=None):
        """æ”¶é›†ç›¸å…³æ—¥å¿—"""

        logs = boto3.client('logs')
        log_group = f'/aws/lambda/{function_name}'

        filter_pattern = f'"{request_id}"' if request_id else "ERROR"

        response = logs.filter_log_events(
            logGroupName=log_group,
            filterPattern=filter_pattern,
            limit=100
        )

        self.report['diagnostics']['logs'] = response['events']

    def collect_metrics(self, function_name):
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""

        cloudwatch = boto3.client('cloudwatch')

        metrics = ['Errors', 'Duration', 'Throttles']
        self.report['diagnostics']['metrics'] = {}

        for metric in metrics:
            response = cloudwatch.get_metric_statistics(
                Namespace='AWS/Lambda',
                MetricName=metric,
                Dimensions=[
                    {'Name': 'FunctionName', 'Value': function_name}
                ],
                StartTime=datetime.utcnow() - timedelta(hours=1),
                EndTime=datetime.utcnow(),
                Period=300,
                Statistics=['Sum', 'Average', 'Maximum']
            )

            self.report['diagnostics']['metrics'][metric] = response['Datapoints']

    def collect_traces(self, trace_id):
        """æ”¶é›†X-Rayè¿½è¸ª"""

        xray = boto3.client('xray')

        response = xray.get_trace_graph(
            TraceIds=[trace_id]
        )

        self.report['diagnostics']['traces'] = response['Services']

    def generate_report(self):
        """ç”Ÿæˆé—®é¢˜æŠ¥å‘Š"""

        # ä¿å­˜åˆ°S3
        s3 = boto3.client('s3')
        report_key = f'issue-reports/{self.issue_id}.json'

        s3.put_object(
            Bucket='ai-ppt-diagnostics',
            Key=report_key,
            Body=json.dumps(self.report, indent=2),
            ContentType='application/json'
        )

        print(f"é—®é¢˜æŠ¥å‘Šå·²ç”Ÿæˆ: s3://ai-ppt-diagnostics/{report_key}")

        # åˆ›å»ºGitHub Issue
        self.create_github_issue()

        return self.report

    def create_github_issue(self):
        """åˆ›å»ºGitHub Issue"""

        import requests

        issue_data = {
            'title': f'[AUTO] Issue {self.issue_id}',
            'body': self.format_issue_body(),
            'labels': ['bug', 'auto-generated']
        }

        headers = {
            'Authorization': f'token {os.environ["GITHUB_TOKEN"]}',
            'Accept': 'application/vnd.github.v3+json'
        }

        response = requests.post(
            'https://api.github.com/repos/org/repo/issues',
            json=issue_data,
            headers=headers
        )

        if response.status_code == 201:
            print(f"GitHub Issueåˆ›å»ºæˆåŠŸ: {response.json()['html_url']}")

# ä½¿ç”¨ç¤ºä¾‹
collector = IssueCollector('issue-2024-01-14-001')
collector.collect_logs('ai-ppt-assistant-generate_ppt')
collector.collect_metrics('ai-ppt-assistant-generate_ppt')
collector.generate_report()
```

## æ•…éšœæ’é™¤æ£€æŸ¥æ¸…å•

### å¿«é€Ÿæ£€æŸ¥æ¸…å•

- [ ] **æœåŠ¡å¯ç”¨æ€§**
  - [ ] API Gatewayå“åº”æ­£å¸¸
  - [ ] Lambdaå‡½æ•°çŠ¶æ€Active
  - [ ] DynamoDBè¡¨çŠ¶æ€ACTIVE
  - [ ] S3å­˜å‚¨æ¡¶å¯è®¿é—®

- [ ] **æ€§èƒ½æŒ‡æ ‡**
  - [ ] APIå»¶è¿Ÿ < 3ç§’
  - [ ] Lambdaé”™è¯¯ç‡ < 1%
  - [ ] DynamoDBæ— é™æµ
  - [ ] å†…å­˜ä½¿ç”¨ < 90%

- [ ] **æ—¥å¿—æ£€æŸ¥**
  - [ ] æ— ERRORçº§åˆ«æ—¥å¿—
  - [ ] æ— å¼‚å¸¸å †æ ˆè·Ÿè¸ª
  - [ ] æ— è¶…æ—¶è­¦å‘Š

- [ ] **ç›‘æ§å‘Šè­¦**
  - [ ] CloudWatchæ— æ´»è·ƒå‘Šè­¦
  - [ ] X-Rayæ— é”™è¯¯è¿½è¸ª
  - [ ] æˆæœ¬åœ¨é¢„ç®—å†…

### æ·±åº¦è¯Šæ–­æ¸…å•

- [ ] **ä»£ç çº§æ£€æŸ¥**
  - [ ] æœ€è¿‘éƒ¨ç½²éªŒè¯
  - [ ] é…ç½®æ›´æ”¹å®¡æŸ¥
  - [ ] ä¾èµ–ç‰ˆæœ¬æ£€æŸ¥

- [ ] **ç½‘ç»œè¯Šæ–­**
  - [ ] VPCé…ç½®éªŒè¯
  - [ ] å®‰å…¨ç»„è§„åˆ™æ£€æŸ¥
  - [ ] DNSè§£ææµ‹è¯•

- [ ] **æ•°æ®å®Œæ•´æ€§**
  - [ ] æ•°æ®åº“ä¸€è‡´æ€§æ£€æŸ¥
  - [ ] S3å¯¹è±¡éªŒè¯
  - [ ] ç¼“å­˜åŒæ­¥çŠ¶æ€

- [ ] **å¤–éƒ¨ä¾èµ–**
  - [ ] BedrockæœåŠ¡çŠ¶æ€
  - [ ] ç¬¬ä¸‰æ–¹APIå¯ç”¨æ€§
  - [ ] CDNè¿è¡ŒçŠ¶æ€

---

*æœ€åæ›´æ–°: 2024-01-14*
*ç‰ˆæœ¬: 1.0.0*
*æŠ€æœ¯æ”¯æŒ: support@ai-ppt.com*