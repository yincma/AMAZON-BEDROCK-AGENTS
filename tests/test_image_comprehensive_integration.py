"""
å›¾ç‰‡ç”ŸæˆæœåŠ¡ç»¼åˆé›†æˆæµ‹è¯•å¥—ä»¶
æµ‹è¯•è¦†ç›–æ­£å¸¸æµç¨‹ã€å¼‚å¸¸æµç¨‹ã€æ€§èƒ½ã€å¹¶å‘ã€ç¼“å­˜ç­‰å„ç§åœºæ™¯
"""

import pytest
import asyncio
import time
import json
import concurrent.futures
import threading
from unittest.mock import Mock, patch, MagicMock, call
import io
from PIL import Image
import hashlib
import base64
import boto3
from botocore.exceptions import ClientError, BotoCoreError
import statistics

# å¯¼å…¥è¢«æµ‹è¯•çš„æ¨¡å—
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'lambdas'))

from image_processing_service import ImageProcessingService
from image_config import CONFIG
from image_exceptions import (
    ImageProcessingError, NovaServiceError, S3OperationError,
    ValidationError, ConfigurationError
)


class TestImageProcessingServiceIntegration:
    """å›¾ç‰‡å¤„ç†æœåŠ¡é›†æˆæµ‹è¯•"""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰çš„è®¾ç½®"""
        self.test_prompt = "ä¸“ä¸šå•†åŠ¡æ¼”ç¤ºå›¾ç‰‡ï¼Œç°ä»£ç®€æ´é£æ ¼ï¼Œé«˜è´¨é‡4Kåˆ†è¾¨ç‡"
        self.test_slide_content = {
            "title": "äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•",
            "content": [
                "æœºå™¨å­¦ä¹ ç®—æ³•çš„çªç ´",
                "æ·±åº¦å­¦ä¹ çš„å¹¿æ³›åº”ç”¨",
                "AIå¯¹å„è¡Œä¸šçš„å½±å“"
            ]
        }

    @pytest.fixture
    def mock_bedrock_client(self):
        """æ¨¡æ‹ŸBedrockå®¢æˆ·ç«¯"""
        client = Mock()

        # æ¨¡æ‹ŸNova CanvasæˆåŠŸå“åº”
        nova_response_body = {
            "images": ["iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChAI/hRqYEAAAAABJRU5ErkJggg=="]
        }

        # æ¨¡æ‹ŸStability AIæˆåŠŸå“åº”
        stability_response_body = {
            "artifacts": [{
                "base64": "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChAI/hRqYEAAAAABJRU5ErkJggg=="
            }]
        }

        def mock_invoke_model(**kwargs):
            model_id = kwargs.get('modelId', '')
            body = json.loads(kwargs.get('body', '{}'))

            if 'nova' in model_id:
                response_body = nova_response_body
            elif 'stability' in model_id:
                response_body = stability_response_body
            else:
                response_body = {"error": "Unsupported model"}

            mock_response = Mock()
            mock_response.read.return_value = json.dumps(response_body).encode('utf-8')

            return {
                'body': mock_response,
                'ResponseMetadata': {'HTTPStatusCode': 200}
            }

        client.invoke_model.side_effect = mock_invoke_model
        return client

    @pytest.fixture
    def mock_s3_client(self):
        """æ¨¡æ‹ŸS3å®¢æˆ·ç«¯"""
        client = Mock()

        # æ¨¡æ‹Ÿget_object - ç¼“å­˜æœªå‘½ä¸­
        client.get_object.side_effect = ClientError(
            {'Error': {'Code': 'NoSuchKey'}}, 'GetObject'
        )

        # æ¨¡æ‹Ÿput_object - ç¼“å­˜ä¿å­˜æˆåŠŸ
        client.put_object.return_value = {'ETag': 'test-etag'}

        return client

    def test_complete_image_generation_workflow(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•å®Œæ•´çš„å›¾ç‰‡ç”Ÿæˆå·¥ä½œæµ"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        # æµ‹è¯•ç”Ÿæˆæç¤ºè¯
        prompt = service.generate_prompt(self.test_slide_content)
        assert isinstance(prompt, str)
        assert len(prompt) > 20
        assert "äººå·¥æ™ºèƒ½" in prompt or "AI" in prompt

        # æµ‹è¯•å›¾ç‰‡ç”Ÿæˆ
        image_data = service.call_image_generation(prompt)
        assert isinstance(image_data, bytes)
        assert len(image_data) > 0

        # éªŒè¯å›¾ç‰‡æ ¼å¼
        assert service.validate_image_format(image_data, 'PNG')

        # æµ‹è¯•å›¾ç‰‡ä¼˜åŒ–
        optimized_data = service.optimize_image_size(image_data)
        assert isinstance(optimized_data, bytes)

    def test_fallback_mechanism_all_models(self, mock_s3_client):
        """æµ‹è¯•å¤šæ¨¡å‹fallbackæœºåˆ¶"""
        # åˆ›å»ºä¸€ä¸ªä¼šè®©æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥çš„å®¢æˆ·ç«¯
        failing_client = Mock()
        failing_client.invoke_model.side_effect = ClientError(
            {'Error': {'Code': 'ThrottlingException'}}, 'InvokeModel'
        )

        service = ImageProcessingService(
            bedrock_client=failing_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        # åº”è¯¥å›é€€åˆ°å ä½å›¾
        image_data = service.call_image_generation(self.test_prompt)
        assert isinstance(image_data, bytes)
        assert len(image_data) > 0

        # éªŒè¯æ˜¯å ä½å›¾ï¼ˆPNGæ ¼å¼ï¼‰
        assert service.validate_image_format(image_data, 'PNG')

    def test_caching_system_comprehensive(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•ç¼“å­˜ç³»ç»Ÿçš„å®Œæ•´åŠŸèƒ½"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        # ç¬¬ä¸€æ¬¡è°ƒç”¨ - åº”è¯¥è°ƒç”¨Bedrock
        prompt = "æµ‹è¯•ç¼“å­˜åŠŸèƒ½"
        image_data_1 = service.call_image_generation(prompt)
        assert mock_bedrock_client.invoke_model.call_count == 1

        # ç¬¬äºŒæ¬¡è°ƒç”¨ç›¸åŒæç¤ºè¯ - åº”è¯¥ä»å†…å­˜ç¼“å­˜è¿”å›
        image_data_2 = service.call_image_generation(prompt)
        assert mock_bedrock_client.invoke_model.call_count == 1  # ä¸åº”è¯¥å¢åŠ 
        assert image_data_1 == image_data_2

        # æµ‹è¯•ç¼“å­˜ç»Ÿè®¡
        stats = service.get_cache_stats()
        assert stats['memory_cache_size'] == 1
        assert stats['cache_enabled'] is True
        assert stats['s3_cache_enabled'] is True

        # æ¸…é™¤ç¼“å­˜
        service.clear_cache()
        stats = service.get_cache_stats()
        assert stats['memory_cache_size'] == 0

    def test_s3_cache_integration(self, mock_bedrock_client):
        """æµ‹è¯•S3ç¼“å­˜é›†æˆ"""
        # æ¨¡æ‹ŸS3ç¼“å­˜å‘½ä¸­
        cached_image_data = base64.b64decode(
            "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChAI/hRqYEAAAAABJRU5ErkJggg=="
        )

        mock_s3_client = Mock()
        mock_response = Mock()
        mock_response.read.return_value = cached_image_data
        mock_s3_client.get_object.return_value = {'Body': mock_response}

        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        prompt = "S3ç¼“å­˜æµ‹è¯•"
        image_data = service.call_image_generation(prompt)

        # åº”è¯¥ä»S3ç¼“å­˜è¿”å›ï¼Œä¸è°ƒç”¨Bedrock
        assert mock_bedrock_client.invoke_model.call_count == 0
        assert image_data == cached_image_data

    def test_error_handling_comprehensive(self, mock_s3_client):
        """æµ‹è¯•å…¨é¢çš„é”™è¯¯å¤„ç†"""

        # æµ‹è¯•1: BedrockæœåŠ¡ä¸´æ—¶ä¸å¯ç”¨
        failing_client = Mock()
        failing_client.invoke_model.side_effect = [
            ClientError({'Error': {'Code': 'ThrottlingException'}}, 'InvokeModel'),
            ClientError({'Error': {'Code': 'ThrottlingException'}}, 'InvokeModel'),
            # ç¬¬ä¸‰æ¬¡æˆåŠŸ
            Mock(body=Mock(read=Mock(return_value=json.dumps({
                "images": ["iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChAI/hRqYEAAAAABJRU5ErkJggg=="]
            }).encode())))
        ]

        service = ImageProcessingService(
            bedrock_client=failing_client,
            s3_client=mock_s3_client
        )

        # åº”è¯¥é‡è¯•åæˆåŠŸ
        with patch('time.sleep'):  # è·³è¿‡å®é™…çš„sleep
            image_data = service.call_image_generation(self.test_prompt)

        assert isinstance(image_data, bytes)
        assert failing_client.invoke_model.call_count >= 2

    def test_concurrent_generation_safety(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•å¹¶å‘å›¾ç‰‡ç”Ÿæˆçš„å®‰å…¨æ€§"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        def generate_image(prompt_suffix):
            prompt = f"å¹¶å‘æµ‹è¯• {prompt_suffix}"
            return service.call_image_generation(prompt)

        # å¹¶å‘ç”Ÿæˆå¤šä¸ªå›¾ç‰‡
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(generate_image, i) for i in range(10)]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]

        # æ‰€æœ‰ç»“æœéƒ½åº”è¯¥æˆåŠŸ
        assert len(results) == 10
        for result in results:
            assert isinstance(result, bytes)
            assert len(result) > 0

    def test_model_priority_and_preference(self, mock_s3_client):
        """æµ‹è¯•æ¨¡å‹ä¼˜å…ˆçº§å’Œåå¥½è®¾ç½®"""
        mock_client = Mock()

        def mock_invoke_with_tracking(**kwargs):
            model_id = kwargs.get('modelId', '')
            # è®°å½•è°ƒç”¨çš„æ¨¡å‹
            if not hasattr(mock_invoke_with_tracking, 'called_models'):
                mock_invoke_with_tracking.called_models = []
            mock_invoke_with_tracking.called_models.append(model_id)

            # æ¨¡æ‹ŸæˆåŠŸå“åº”
            mock_response = Mock()
            mock_response.read.return_value = json.dumps({
                "images": ["iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChAI/hRqYEAAAAABJRU5ErkJggg=="]
            }).encode()

            return {'body': mock_response}

        mock_client.invoke_model.side_effect = mock_invoke_with_tracking

        service = ImageProcessingService(
            bedrock_client=mock_client,
            s3_client=mock_s3_client
        )

        # æµ‹è¯•æŒ‡å®šé¦–é€‰æ¨¡å‹
        service.call_image_generation(
            self.test_prompt,
            model_preference="stability.stable-diffusion-xl-v1"
        )

        # éªŒè¯é¦–é€‰æ¨¡å‹è¢«é¦–å…ˆè°ƒç”¨
        called_models = mock_invoke_with_tracking.called_models
        assert len(called_models) == 1
        assert "stability" in called_models[0]

    def test_prompt_optimization_effectiveness(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•æç¤ºè¯ä¼˜åŒ–çš„æœ‰æ•ˆæ€§"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client
        )

        # æµ‹è¯•ä¸åŒç±»å‹çš„å†…å®¹ä¼˜åŒ–
        test_cases = [
            {
                "content": {"title": "AIæŠ€æœ¯", "content": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ "]},
                "audience": "business",
                "expected_keywords": ["ç§‘æŠ€", "å•†åŠ¡", "ä¸“ä¸š"]
            },
            {
                "content": {"title": "æ•™è‚²åŸ¹è®­", "content": ["è¯¾ç¨‹è®¾è®¡", "å­¦ä¹ æ–¹æ³•"]},
                "audience": "academic",
                "expected_keywords": ["æ•™è‚²", "å­¦æœ¯", "çŸ¥è¯†"]
            },
            {
                "content": {"title": "åˆ›æ„è®¾è®¡", "content": ["è§†è§‰è‰ºæœ¯", "åˆ›æ–°æ€ç»´"]},
                "audience": "creative",
                "expected_keywords": ["åˆ›æ„", "è‰ºæœ¯", "è®¾è®¡"]
            }
        ]

        for case in test_cases:
            prompt = service.generate_prompt(case["content"], case["audience"])

            # éªŒè¯æç¤ºè¯åŒ…å«é¢„æœŸå…³é”®è¯
            assert any(keyword in prompt for keyword in case["expected_keywords"])

            # éªŒè¯æç¤ºè¯è´¨é‡
            assert "é«˜è´¨é‡" in prompt or "4K" in prompt
            assert len(prompt) > 30
            assert len(prompt) < 600  # ä¸åº”è¿‡é•¿

    def test_image_validation_comprehensive(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•å›¾ç‰‡éªŒè¯çš„å…¨é¢åŠŸèƒ½"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client
        )

        # åˆ›å»ºä¸åŒæ ¼å¼çš„æµ‹è¯•å›¾ç‰‡
        def create_test_image(format='PNG', size=(800, 600)):
            image = Image.new('RGB', size, color='blue')
            img_bytes = io.BytesIO()
            image.save(img_bytes, format=format)
            return img_bytes.getvalue()

        # æµ‹è¯•PNGæ ¼å¼éªŒè¯
        png_data = create_test_image('PNG')
        assert service.validate_image_format(png_data, 'PNG') is True
        assert service.validate_image_format(png_data, 'JPEG') is False

        # æµ‹è¯•JPEGæ ¼å¼éªŒè¯
        jpg_data = create_test_image('JPEG')
        assert service.validate_image_format(jpg_data, 'JPEG') is True
        assert service.validate_image_format(jpg_data, 'PNG') is False

        # æµ‹è¯•æ— æ•ˆæ•°æ®
        invalid_data = b"è¿™ä¸æ˜¯å›¾ç‰‡æ•°æ®"
        assert service.validate_image_format(invalid_data, 'PNG') is False

    def test_image_optimization_performance(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•å›¾ç‰‡ä¼˜åŒ–æ€§èƒ½"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client
        )

        # åˆ›å»ºå¤§å°ºå¯¸æµ‹è¯•å›¾ç‰‡
        def create_large_image():
            image = Image.new('RGB', (2000, 1500), color='red')
            img_bytes = io.BytesIO()
            image.save(img_bytes, format='PNG')
            return img_bytes.getvalue()

        large_image_data = create_large_image()
        original_size = len(large_image_data)

        # æµ‹è¯•å°ºå¯¸ä¼˜åŒ–
        start_time = time.time()
        optimized_data = service.optimize_image_size(large_image_data, 800, 600)
        optimization_time = time.time() - start_time

        # éªŒè¯ä¼˜åŒ–æ•ˆæœ
        optimized_size = len(optimized_data)

        # ä¼˜åŒ–åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        assert optimization_time < 2.0

        # éªŒè¯ä¼˜åŒ–åçš„å›¾ç‰‡å°ºå¯¸
        optimized_image = Image.open(io.BytesIO(optimized_data))
        assert optimized_image.width <= 800
        assert optimized_image.height <= 600

    def test_placeholder_image_creation(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•å ä½å›¾åˆ›å»ºçš„å„ç§åœºæ™¯"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client
        )

        # æµ‹è¯•é»˜è®¤å ä½å›¾
        placeholder_data = service.create_placeholder_image()
        assert isinstance(placeholder_data, bytes)
        assert service.validate_image_format(placeholder_data, 'PNG')

        # æµ‹è¯•è‡ªå®šä¹‰å°ºå¯¸å ä½å›¾
        custom_placeholder = service.create_placeholder_image(400, 300, "è‡ªå®šä¹‰æ–‡æœ¬")
        assert isinstance(custom_placeholder, bytes)

        # éªŒè¯å°ºå¯¸
        custom_image = Image.open(io.BytesIO(custom_placeholder))
        assert custom_image.width == 400
        assert custom_image.height == 300

        # æµ‹è¯•é•¿æ–‡æœ¬å¤„ç†
        long_text = "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æ–‡æœ¬" * 10
        long_text_placeholder = service.create_placeholder_image(text=long_text)
        assert isinstance(long_text_placeholder, bytes)

    def test_edge_cases_and_boundary_conditions(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•è¾¹ç•Œæ¡ä»¶å’Œæç«¯æƒ…å†µ"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client
        )

        # æµ‹è¯•ç©ºå†…å®¹
        empty_content = {"title": "", "content": []}
        prompt = service.generate_prompt(empty_content)
        assert isinstance(prompt, str)
        assert len(prompt) > 0

        # æµ‹è¯•åªæœ‰æ ‡é¢˜çš„å†…å®¹
        title_only = {"title": "ä»…æ ‡é¢˜æµ‹è¯•", "content": []}
        prompt = service.generate_prompt(title_only)
        assert "ä»…æ ‡é¢˜æµ‹è¯•" in prompt

        # æµ‹è¯•åªæœ‰å†…å®¹çš„æƒ…å†µ
        content_only = {"title": "", "content": ["å†…å®¹1", "å†…å®¹2"]}
        prompt = service.generate_prompt(content_only)
        assert "å†…å®¹1" in prompt or "å†…å®¹2" in prompt

        # æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å¤„ç†
        special_chars = {
            "title": "æ ‡é¢˜@#$%^&*()",
            "content": ["å†…å®¹åŒ…å«emoji ğŸš€", "æ•°å­—123", "ç¬¦å·!@#$%"]
        }
        prompt = service.generate_prompt(special_chars)
        assert isinstance(prompt, str)
        assert len(prompt) > 0

        # æµ‹è¯•éå¸¸é•¿çš„å†…å®¹
        long_content = {
            "title": "è¶…é•¿æ ‡é¢˜" * 20,
            "content": ["è¶…é•¿å†…å®¹é¡¹ç›®" * 50 for _ in range(10)]
        }
        prompt = service.generate_prompt(long_content)
        assert isinstance(prompt, str)
        assert len(prompt) < 600  # åº”è¯¥è¢«ä¼˜åŒ–æˆªæ–­

    def test_memory_management_and_cleanup(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•å†…å­˜ç®¡ç†å’Œæ¸…ç†"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        # ç”Ÿæˆå¤§é‡å›¾ç‰‡ä»¥å¡«å……ç¼“å­˜
        for i in range(20):
            prompt = f"å†…å­˜æµ‹è¯• {i}"
            service.call_image_generation(prompt)

        # æ£€æŸ¥ç¼“å­˜å¤§å°
        stats_before = service.get_cache_stats()
        assert stats_before['memory_cache_size'] == 20

        # æ¸…é™¤ç¼“å­˜
        service.clear_cache()

        # éªŒè¯æ¸…ç†æ•ˆæœ
        stats_after = service.get_cache_stats()
        assert stats_after['memory_cache_size'] == 0

    def test_configuration_flexibility(self):
        """æµ‹è¯•é…ç½®çš„çµæ´»æ€§"""
        # æµ‹è¯•ä¸åŒé…ç½®çš„æœåŠ¡åˆ›å»º

        # ç¦ç”¨ç¼“å­˜çš„æœåŠ¡
        service_no_cache = ImageProcessingService(enable_caching=False)
        assert service_no_cache.enable_caching is False
        assert service_no_cache.s3_client is None

        # è‡ªå®šä¹‰æ¨¡å‹åˆ—è¡¨
        service_custom = ImageProcessingService()
        original_models = service_custom.supported_models.copy()

        # éªŒè¯æ”¯æŒçš„æ¨¡å‹
        assert "amazon.nova-canvas-v1:0" in service_custom.supported_models
        assert "stability.stable-diffusion-xl-v1" in service_custom.supported_models

    def test_exception_handling_specificity(self, mock_s3_client):
        """æµ‹è¯•å…·ä½“å¼‚å¸¸çš„å¤„ç†"""

        # æµ‹è¯•NovaServiceError
        failing_client = Mock()
        failing_client.invoke_model.side_effect = ClientError(
            {'Error': {'Code': 'ValidationException', 'Message': 'æ¨¡å‹ä¸å­˜åœ¨'}},
            'InvokeModel'
        )

        service = ImageProcessingService(
            bedrock_client=failing_client,
            s3_client=mock_s3_client
        )

        # åº”è¯¥å¤„ç†å¼‚å¸¸å¹¶å›é€€åˆ°å ä½å›¾
        image_data = service.call_image_generation(self.test_prompt)
        assert isinstance(image_data, bytes)

        # éªŒè¯æ˜¯å ä½å›¾
        assert service.validate_image_format(image_data, 'PNG')

    def test_integration_with_real_aws_format(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•ä¸çœŸå®AWSå“åº”æ ¼å¼çš„é›†æˆ"""
        # æ¨¡æ‹ŸçœŸå®çš„AWS Bedrockå“åº”æ ¼å¼
        realistic_nova_response = {
            "images": [
                # è¿™æ˜¯ä¸€ä¸ª1x1åƒç´ çš„PNGå›¾ç‰‡çš„base64
                "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAABhGlDQ1BJQ0MgcHJvZmlsZQAAKJF9kT1Iw0AcxV9TpSItDnYQcchQnSyIijhKFYtgobQVWnUwufQLmjQkKS6OgmvBwY/FqoOLs64OroIg+AHi5uak6CIl/i8ptIjx4Lgf7+497t4BQqPCVLNrAlA1y0jFY2I2tyoGXuHHCPogICgxU5+TkiS085jT3S936p1lW5mf+5OC3TGbAXpEOsb0LYvwOvn0ZFXOeY89wsoSySDOnHhU0A9Jlwy4hvAeY7SYN4gni09FLpk8QixKdBSzmFE5ocWyLisyauUs8QiPptBDki/JrhQyLnfcayWdqt37c3wjVyxkKg3l4piAOcEJZKhGDWE0sJKokMFIhngn1j8s68eRLBVZAwXQAAdKWIUEMmf9i3Wt8y6LuYtKdDOQfrDbQMTn6Iysk30YxXo2yL8fQ2N/cj5SYLwbaH5zjLs6CPA2cHjDp1P2u6Dqe5+F4V1oJgCJCNgdAGFuJiD2BPp5qe35J4lIkFXG7qILMfFh6PggYNaVN8I"
            ],
            "seed": 12345,
            "finishReason": "SUCCESS"
        }

        mock_bedrock_client.invoke_model.return_value = {
            'body': Mock(read=Mock(return_value=json.dumps(realistic_nova_response).encode())),
            'ResponseMetadata': {'HTTPStatusCode': 200}
        }

        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client
        )

        image_data = service.call_image_generation(self.test_prompt)
        assert isinstance(image_data, bytes)
        assert len(image_data) > 0


class TestPerformanceBenchmarks:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""

    def setup_method(self):
        """æ€§èƒ½æµ‹è¯•è®¾ç½®"""
        self.performance_thresholds = {
            "single_generation_max_time": 5.0,  # å•æ¬¡ç”Ÿæˆæœ€å¤§æ—¶é—´ï¼ˆç§’ï¼‰
            "batch_generation_max_time": 30.0,  # æ‰¹é‡ç”Ÿæˆæœ€å¤§æ—¶é—´ï¼ˆç§’ï¼‰
            "prompt_generation_max_time": 0.1,  # æç¤ºè¯ç”Ÿæˆæœ€å¤§æ—¶é—´ï¼ˆç§’ï¼‰
            "cache_lookup_max_time": 0.01,     # ç¼“å­˜æŸ¥æ‰¾æœ€å¤§æ—¶é—´ï¼ˆç§’ï¼‰
            "concurrent_max_time": 10.0,       # å¹¶å‘å¤„ç†æœ€å¤§æ—¶é—´ï¼ˆç§’ï¼‰
        }

    @pytest.mark.performance
    def test_single_image_generation_performance(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•å•å¼ å›¾ç‰‡ç”Ÿæˆæ€§èƒ½"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client
        )

        prompt = "æ€§èƒ½æµ‹è¯•ç”¨æç¤ºè¯ï¼Œç°ä»£å•†åŠ¡é£æ ¼"

        # é¢„çƒ­
        service.call_image_generation(prompt)

        # æ€§èƒ½æµ‹è¯•
        start_time = time.time()
        image_data = service.call_image_generation(prompt)
        end_time = time.time()

        generation_time = end_time - start_time

        # éªŒè¯æ€§èƒ½
        assert generation_time < self.performance_thresholds["single_generation_max_time"]
        assert isinstance(image_data, bytes)
        assert len(image_data) > 0

    @pytest.mark.performance
    def test_prompt_generation_performance(self):
        """æµ‹è¯•æç¤ºè¯ç”Ÿæˆæ€§èƒ½"""
        service = ImageProcessingService()

        test_content = {
            "title": "AIæŠ€æœ¯å‘å±•è¶‹åŠ¿åˆ†ææŠ¥å‘Š",
            "content": [
                "æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„çªç ´ä¸åˆ›æ–°",
                "è‡ªç„¶è¯­è¨€å¤„ç†çš„å•†ä¸šåŒ–åº”ç”¨",
                "è®¡ç®—æœºè§†è§‰åœ¨å„è¡Œä¸šçš„è½åœ°å®è·µ",
                "æœºå™¨å­¦ä¹ ç®—æ³•çš„ä¼˜åŒ–ä¸æ”¹è¿›",
                "äººå·¥æ™ºèƒ½ä¼¦ç†ä¸å¯æŒç»­å‘å±•"
            ]
        }

        # æ‰¹é‡æ€§èƒ½æµ‹è¯•
        times = []
        for _ in range(100):
            start_time = time.perf_counter()
            prompt = service.generate_prompt(test_content)
            end_time = time.perf_counter()

            times.append(end_time - start_time)
            assert isinstance(prompt, str)
            assert len(prompt) > 0

        # æ€§èƒ½åˆ†æ
        avg_time = statistics.mean(times)
        max_time = max(times)
        p95_time = statistics.quantiles(times, n=20)[18]  # 95th percentile

        assert avg_time < self.performance_thresholds["prompt_generation_max_time"]
        assert max_time < self.performance_thresholds["prompt_generation_max_time"] * 2

        print(f"æç¤ºè¯ç”Ÿæˆæ€§èƒ½ç»Ÿè®¡:")
        print(f"å¹³å‡æ—¶é—´: {avg_time:.4f}s")
        print(f"æœ€å¤§æ—¶é—´: {max_time:.4f}s")
        print(f"P95æ—¶é—´: {p95_time:.4f}s")

    @pytest.mark.performance
    def test_cache_performance(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        prompt = "ç¼“å­˜æ€§èƒ½æµ‹è¯•"

        # ç¬¬ä¸€æ¬¡ç”Ÿæˆï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
        start_time = time.perf_counter()
        service.call_image_generation(prompt)
        first_time = time.perf_counter() - start_time

        # ç¬¬äºŒæ¬¡ç”Ÿæˆï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
        start_time = time.perf_counter()
        service.call_image_generation(prompt)
        cached_time = time.perf_counter() - start_time

        # ç¼“å­˜æŸ¥æ‰¾åº”è¯¥éå¸¸å¿«
        assert cached_time < self.performance_thresholds["cache_lookup_max_time"]

        # ç¼“å­˜å‘½ä¸­åº”è¯¥æ¯”é¦–æ¬¡ç”Ÿæˆå¿«å¾ˆå¤š
        assert cached_time < first_time * 0.1

        print(f"ç¼“å­˜æ€§èƒ½å¯¹æ¯”:")
        print(f"é¦–æ¬¡ç”Ÿæˆ: {first_time:.4f}s")
        print(f"ç¼“å­˜å‘½ä¸­: {cached_time:.4f}s")
        print(f"æ€§èƒ½æå‡: {first_time/cached_time:.1f}x")

    @pytest.mark.performance
    def test_concurrent_generation_performance(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•å¹¶å‘ç”Ÿæˆæ€§èƒ½"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        def generate_single(index):
            prompt = f"å¹¶å‘æ€§èƒ½æµ‹è¯• {index}"
            start_time = time.perf_counter()
            result = service.call_image_generation(prompt)
            end_time = time.perf_counter()
            return {
                'index': index,
                'time': end_time - start_time,
                'success': isinstance(result, bytes) and len(result) > 0
            }

        # å¹¶å‘æ‰§è¡Œ
        concurrent_count = 8
        start_time = time.time()

        with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_count) as executor:
            futures = [executor.submit(generate_single, i) for i in range(concurrent_count)]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]

        total_time = time.time() - start_time

        # æ€§èƒ½éªŒè¯
        assert total_time < self.performance_thresholds["concurrent_max_time"]
        assert len(results) == concurrent_count
        assert all(r['success'] for r in results)

        # ç»Ÿè®¡åˆ†æ
        individual_times = [r['time'] for r in results]
        avg_individual_time = statistics.mean(individual_times)

        print(f"å¹¶å‘æ€§èƒ½ç»Ÿè®¡:")
        print(f"æ€»æ—¶é—´: {total_time:.2f}s")
        print(f"å¹³å‡å•æ¬¡æ—¶é—´: {avg_individual_time:.4f}s")
        print(f"å¹¶å‘æ•ˆç‡: {(avg_individual_time * concurrent_count) / total_time:.1f}x")

    @pytest.mark.performance
    def test_memory_usage_optimization(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨ä¼˜åŒ–"""
        import psutil
        import gc

        process = psutil.Process()

        # è®°å½•åˆå§‹å†…å­˜ä½¿ç”¨
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        # ç”Ÿæˆå¤§é‡å›¾ç‰‡
        for i in range(50):
            prompt = f"å†…å­˜æµ‹è¯• {i}"
            service.call_image_generation(prompt)

            # æ¯10æ¬¡æ£€æŸ¥å†…å­˜
            if i % 10 == 0:
                current_memory = process.memory_info().rss / 1024 / 1024
                memory_increase = current_memory - initial_memory

                # å†…å­˜å¢é•¿åº”è¯¥æ§åˆ¶åœ¨åˆç†èŒƒå›´
                assert memory_increase < 200  # ä¸è¶…è¿‡200MB

        # æ¸…ç†ç¼“å­˜
        service.clear_cache()
        gc.collect()

        # æ£€æŸ¥å†…å­˜é‡Šæ”¾
        final_memory = process.memory_info().rss / 1024 / 1024
        memory_after_cleanup = final_memory - initial_memory

        print(f"å†…å­˜ä½¿ç”¨ç»Ÿè®¡:")
        print(f"åˆå§‹å†…å­˜: {initial_memory:.1f}MB")
        print(f"æœ€ç»ˆå†…å­˜: {final_memory:.1f}MB")
        print(f"å‡€å¢é•¿: {memory_after_cleanup:.1f}MB")


class TestStressTesting:
    """å‹åŠ›æµ‹è¯•"""

    @pytest.mark.stress
    def test_high_volume_generation(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•é«˜å®¹é‡å›¾ç‰‡ç”Ÿæˆ"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        # å¤§æ‰¹é‡ç”Ÿæˆæµ‹è¯•
        batch_size = 100
        success_count = 0
        error_count = 0

        start_time = time.time()

        for i in range(batch_size):
            try:
                prompt = f"å‹åŠ›æµ‹è¯•æ‰¹æ¬¡ {i}"
                result = service.call_image_generation(prompt)
                if isinstance(result, bytes) and len(result) > 0:
                    success_count += 1
                else:
                    error_count += 1
            except Exception as e:
                error_count += 1
                print(f"ç¬¬{i}æ¬¡ç”Ÿæˆå¤±è´¥: {str(e)}")

        total_time = time.time() - start_time

        # éªŒè¯å‹åŠ›æµ‹è¯•ç»“æœ
        success_rate = success_count / batch_size
        assert success_rate >= 0.95  # 95%æˆåŠŸç‡
        assert total_time < 120  # 2åˆ†é’Ÿå†…å®Œæˆ

        print(f"å‹åŠ›æµ‹è¯•ç»“æœ:")
        print(f"æ€»æ•°: {batch_size}")
        print(f"æˆåŠŸ: {success_count}")
        print(f"å¤±è´¥: {error_count}")
        print(f"æˆåŠŸç‡: {success_rate:.2%}")
        print(f"æ€»æ—¶é—´: {total_time:.1f}s")
        print(f"å¹³å‡æ¯æ¬¡: {total_time/batch_size:.3f}s")

    @pytest.mark.stress
    def test_memory_stress(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•å†…å­˜å‹åŠ›"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        # ç”Ÿæˆå¤§é‡ä¸åŒçš„å›¾ç‰‡ä»¥æµ‹è¯•å†…å­˜ç®¡ç†
        large_batch = 200

        for i in range(large_batch):
            # åˆ›å»ºä¸åŒçš„æç¤ºè¯ä»¥é¿å…ç¼“å­˜
            prompt = f"å†…å­˜å‹åŠ›æµ‹è¯• {i} {time.time()}"

            try:
                result = service.call_image_generation(prompt)
                assert isinstance(result, bytes)

                # å‘¨æœŸæ€§æ¸…ç†ç¼“å­˜
                if i % 50 == 0:
                    service.clear_cache()

            except Exception as e:
                pytest.fail(f"å†…å­˜å‹åŠ›æµ‹è¯•åœ¨ç¬¬{i}æ¬¡å¤±è´¥: {str(e)}")

    @pytest.mark.stress
    def test_concurrent_stress(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•å¹¶å‘å‹åŠ›"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        def stress_worker(worker_id, iterations):
            results = []
            for i in range(iterations):
                try:
                    prompt = f"å¹¶å‘å‹åŠ›æµ‹è¯• Worker{worker_id} Iter{i}"
                    result = service.call_image_generation(prompt)
                    results.append(True if isinstance(result, bytes) else False)
                except Exception as e:
                    results.append(False)
                    print(f"Worker {worker_id} Iteration {i} å¤±è´¥: {str(e)}")
            return results

        # å¯åŠ¨å¤šä¸ªå·¥ä½œçº¿ç¨‹
        workers = 10
        iterations_per_worker = 20

        start_time = time.time()

        with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:
            futures = [
                executor.submit(stress_worker, worker_id, iterations_per_worker)
                for worker_id in range(workers)
            ]

            all_results = []
            for future in concurrent.futures.as_completed(futures):
                all_results.extend(future.result())

        total_time = time.time() - start_time

        # åˆ†æç»“æœ
        total_operations = workers * iterations_per_worker
        successful_operations = sum(all_results)
        success_rate = successful_operations / total_operations

        # éªŒè¯å¹¶å‘å‹åŠ›æµ‹è¯•
        assert success_rate >= 0.90  # 90%æˆåŠŸç‡
        assert total_time < 60  # 1åˆ†é’Ÿå†…å®Œæˆ

        print(f"å¹¶å‘å‹åŠ›æµ‹è¯•ç»“æœ:")
        print(f"å·¥ä½œçº¿ç¨‹: {workers}")
        print(f"æ¯çº¿ç¨‹è¿­ä»£: {iterations_per_worker}")
        print(f"æ€»æ“ä½œæ•°: {total_operations}")
        print(f"æˆåŠŸæ“ä½œ: {successful_operations}")
        print(f"æˆåŠŸç‡: {success_rate:.2%}")
        print(f"æ€»æ—¶é—´: {total_time:.1f}s")
        print(f"ååé‡: {total_operations/total_time:.1f} ops/s")


class TestErrorRecoveryAndResilience:
    """é”™è¯¯æ¢å¤å’Œå¼¹æ€§æµ‹è¯•"""

    def test_service_degradation_graceful_handling(self, mock_s3_client):
        """æµ‹è¯•æœåŠ¡é™çº§çš„ä¼˜é›…å¤„ç†"""
        # åˆ›å»ºé€æ­¥å¤±è´¥çš„å®¢æˆ·ç«¯
        call_count = 0

        def failing_invoke_model(**kwargs):
            nonlocal call_count
            call_count += 1

            # å‰3æ¬¡è°ƒç”¨å¤±è´¥ï¼Œç¬¬4æ¬¡æˆåŠŸ
            if call_count <= 3:
                raise ClientError(
                    {'Error': {'Code': 'ThrottlingException', 'Message': 'æœåŠ¡å¿™'}},
                    'InvokeModel'
                )
            else:
                # æˆåŠŸå“åº”
                mock_response = Mock()
                mock_response.read.return_value = json.dumps({
                    "images": ["iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChAI/hRqYEAAAAABJRU5ErkJggg=="]
                }).encode()
                return {'body': mock_response}

        mock_client = Mock()
        mock_client.invoke_model.side_effect = failing_invoke_model

        service = ImageProcessingService(
            bedrock_client=mock_client,
            s3_client=mock_s3_client
        )

        # æµ‹è¯•é‡è¯•æœºåˆ¶
        with patch('time.sleep'):  # è·³è¿‡å®é™…sleep
            result = service.call_image_generation("æ¢å¤æµ‹è¯•")

        # åº”è¯¥æœ€ç»ˆæˆåŠŸ
        assert isinstance(result, bytes)
        assert call_count >= 3  # éªŒè¯é‡è¯•å‘ç”Ÿ

    def test_partial_failure_recovery(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•éƒ¨åˆ†å¤±è´¥çš„æ¢å¤"""
        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client,
            enable_caching=True
        )

        # æ¨¡æ‹Ÿéƒ¨åˆ†æ“ä½œæˆåŠŸï¼Œéƒ¨åˆ†å¤±è´¥çš„åœºæ™¯
        success_prompts = ["æˆåŠŸ1", "æˆåŠŸ2", "æˆåŠŸ3"]
        mixed_results = []

        for prompt in success_prompts:
            try:
                result = service.call_image_generation(prompt)
                mixed_results.append({
                    'prompt': prompt,
                    'success': True,
                    'result': result
                })
            except Exception as e:
                mixed_results.append({
                    'prompt': prompt,
                    'success': False,
                    'error': str(e)
                })

        # éªŒè¯éƒ¨åˆ†æˆåŠŸ
        successful_results = [r for r in mixed_results if r['success']]
        assert len(successful_results) >= 1  # è‡³å°‘æœ‰ä¸€ä¸ªæˆåŠŸ

    def test_configuration_error_handling(self):
        """æµ‹è¯•é…ç½®é”™è¯¯å¤„ç†"""
        # æµ‹è¯•æ— æ•ˆçš„Bedrockå®¢æˆ·ç«¯
        invalid_client = None

        service = ImageProcessingService(bedrock_client=invalid_client, enable_caching=False)

        # åº”è¯¥åˆ›å»ºé»˜è®¤å®¢æˆ·ç«¯
        assert service.bedrock_client is not None

    def test_data_corruption_handling(self, mock_bedrock_client, mock_s3_client):
        """æµ‹è¯•æ•°æ®æŸåå¤„ç†"""
        # æ¨¡æ‹Ÿè¿”å›æŸåæ•°æ®çš„å®¢æˆ·ç«¯
        mock_bedrock_client.invoke_model.return_value = {
            'body': Mock(read=Mock(return_value=b'invalid json'))
        }

        service = ImageProcessingService(
            bedrock_client=mock_bedrock_client,
            s3_client=mock_s3_client
        )

        # åº”è¯¥å¤„ç†æŸåæ•°æ®å¹¶å›é€€åˆ°å ä½å›¾
        result = service.call_image_generation("æ•°æ®æŸåæµ‹è¯•")
        assert isinstance(result, bytes)
        assert service.validate_image_format(result, 'PNG')  # å ä½å›¾


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•æ—¶çš„é…ç½®
    pytest.main([
        __file__,
        "-v",
        "--tb=short",
        "--strict-markers",
        "-m", "not (stress or performance)"  # é»˜è®¤è·³è¿‡å‹åŠ›å’Œæ€§èƒ½æµ‹è¯•
    ])