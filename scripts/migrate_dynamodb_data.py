#!/usr/bin/env python3
"""
migrate_dynamodb_data.py - DynamoDBæ•°æ®è¿ç§»è„šæœ¬
ç»Ÿä¸€æ•°æ®åˆ°sessionsè¡¨ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
"""

import boto3
import json
import sys
from datetime import datetime
from typing import Dict, List, Any
from decimal import Decimal

# é…ç½®
REGION = 'us-east-1'
PROJECT = 'ai-ppt-assistant'
ENVIRONMENT = 'dev'

# è¡¨åé…ç½®
TABLES = {
    'tasks': f'{PROJECT}-{ENVIRONMENT}-tasks',
    'sessions': f'{PROJECT}-{ENVIRONMENT}-sessions',
    'checkpoints': f'{PROJECT}-{ENVIRONMENT}-checkpoints'
}

# ç›®æ ‡è¡¨ï¼ˆç»Ÿä¸€åˆ°sessionsè¡¨ï¼‰
TARGET_TABLE = TABLES['sessions']

class DecimalEncoder(json.JSONEncoder):
    """å¤„ç†DynamoDBçš„Decimalç±»å‹"""
    def default(self, obj):
        if isinstance(obj, Decimal):
            return float(obj)
        return super(DecimalEncoder, self).default(obj)

class DynamoDBMigrator:
    def __init__(self):
        """åˆå§‹åŒ–DynamoDBå®¢æˆ·ç«¯"""
        self.dynamodb = boto3.resource('dynamodb', region_name=REGION)
        self.lambda_client = boto3.client('lambda', region_name=REGION)
        self.ssm = boto3.client('ssm', region_name=REGION)
        self.backup_data = {}
        self.migration_stats = {
            'total_scanned': 0,
            'migrated': 0,
            'skipped': 0,
            'failed': 0,
            'errors': []
        }
    
    def log(self, message: str, level: str = "INFO"):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        prefix = {
            "INFO": "â„¹ï¸",
            "SUCCESS": "âœ…",
            "WARNING": "âš ï¸",
            "ERROR": "âŒ",
            "DATA": "ğŸ“Š"
        }.get(level, "")
        
        print(f"{prefix} [{timestamp}] {message}")
    
    def check_table_exists(self, table_name: str) -> bool:
        """æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨"""
        try:
            table = self.dynamodb.Table(table_name)
            table.load()
            return True
        except:
            return False
    
    def scan_table(self, table_name: str) -> List[Dict]:
        """æ‰«ææ•´ä¸ªè¡¨"""
        items = []
        
        if not self.check_table_exists(table_name):
            self.log(f"è¡¨ {table_name} ä¸å­˜åœ¨", "WARNING")
            return items
        
        table = self.dynamodb.Table(table_name)
        
        try:
            # æ‰§è¡Œæ‰«æ
            response = table.scan()
            items.extend(response.get('Items', []))
            
            # å¤„ç†åˆ†é¡µ
            while 'LastEvaluatedKey' in response:
                response = table.scan(ExclusiveStartKey=response['LastEvaluatedKey'])
                items.extend(response.get('Items', []))
            
            self.log(f"ä»è¡¨ {table_name} æ‰«æäº† {len(items)} æ¡è®°å½•", "DATA")
            self.migration_stats['total_scanned'] += len(items)
            
        except Exception as e:
            self.log(f"æ‰«æè¡¨ {table_name} å¤±è´¥: {str(e)}", "ERROR")
            self.migration_stats['errors'].append(f"Scan {table_name}: {str(e)}")
        
        return items
    
    def backup_tables(self) -> str:
        """å¤‡ä»½æ‰€æœ‰è¡¨æ•°æ®"""
        self.log("å¼€å§‹å¤‡ä»½è¡¨æ•°æ®...", "INFO")
        
        for table_key, table_name in TABLES.items():
            self.log(f"å¤‡ä»½è¡¨: {table_name}", "INFO")
            items = self.scan_table(table_name)
            self.backup_data[table_key] = items
        
        # ä¿å­˜å¤‡ä»½åˆ°æ–‡ä»¶
        backup_file = f'dynamodb_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        
        with open(backup_file, 'w') as f:
            json.dump({
                'backup_time': datetime.now().isoformat(),
                'region': REGION,
                'tables': self.backup_data,
                'table_names': TABLES
            }, f, indent=2, cls=DecimalEncoder)
        
        self.log(f"å¤‡ä»½å·²ä¿å­˜åˆ°: {backup_file}", "SUCCESS")
        return backup_file
    
    def migrate_data(self) -> bool:
        """æ‰§è¡Œæ•°æ®è¿ç§»"""
        self.log("=" * 60, "INFO")
        self.log("å¼€å§‹æ•°æ®è¿ç§»", "INFO")
        self.log("=" * 60, "INFO")
        
        # ç¡®ä¿ç›®æ ‡è¡¨å­˜åœ¨
        if not self.check_table_exists(TARGET_TABLE):
            self.log(f"ç›®æ ‡è¡¨ {TARGET_TABLE} ä¸å­˜åœ¨ï¼", "ERROR")
            return False
        
        target_table = self.dynamodb.Table(TARGET_TABLE)
        
        # ä»tasksè¡¨è¿ç§»æ•°æ®
        self.log(f"\nè¿ç§»æ•°æ®: tasks -> sessions", "INFO")
        
        tasks_items = self.backup_data.get('tasks', [])
        
        for item in tasks_items:
            try:
                # æ£€æŸ¥è®°å½•æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŸºäºtaskIdï¼‰
                task_id = item.get('taskId')
                
                if not task_id:
                    self.log(f"è·³è¿‡æ— taskIdçš„è®°å½•", "WARNING")
                    self.migration_stats['skipped'] += 1
                    continue
                
                # æŸ¥è¯¢æ˜¯å¦å·²å­˜åœ¨
                response = target_table.get_item(Key={'taskId': task_id})
                
                if 'Item' in response:
                    self.log(f"è®°å½•å·²å­˜åœ¨ï¼Œè·³è¿‡: {task_id}", "INFO")
                    self.migration_stats['skipped'] += 1
                else:
                    # å‡†å¤‡æ•°æ®ï¼ˆå¯èƒ½éœ€è¦è½¬æ¢æ ¼å¼ï¼‰
                    migrated_item = self.transform_item(item)
                    
                    # å†™å…¥ç›®æ ‡è¡¨
                    target_table.put_item(Item=migrated_item)
                    self.log(f"è¿ç§»æˆåŠŸ: {task_id}", "SUCCESS")
                    self.migration_stats['migrated'] += 1
                    
            except Exception as e:
                self.log(f"è¿ç§»è®°å½•å¤±è´¥: {str(e)}", "ERROR")
                self.migration_stats['failed'] += 1
                self.migration_stats['errors'].append(str(e))
        
        return True
    
    def transform_item(self, item: Dict) -> Dict:
        """è½¬æ¢æ•°æ®æ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        # æ·»åŠ è¿ç§»å…ƒæ•°æ®
        item['migration_timestamp'] = datetime.now().isoformat()
        item['migration_source'] = 'tasks_table'
        
        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
        if 'created_at' not in item:
            item['created_at'] = datetime.now().isoformat()
        
        if 'status' not in item:
            item['status'] = 'migrated'
        
        return item
    
    def update_lambda_configurations(self) -> int:
        """æ›´æ–°Lambdaå‡½æ•°é…ç½®"""
        self.log("\næ›´æ–°Lambdaå‡½æ•°é…ç½®...", "INFO")
        
        functions_to_update = [
            'ai-ppt-assistant-api-generate-presentation',
            'ai-ppt-assistant-api-presentation-status',
            'ai-ppt-assistant-api-list-presentations',
            'ai-ppt-assistant-api-get-task',
            'ai-ppt-assistant-task-processor'
        ]
        
        updated_count = 0
        
        for func_name in functions_to_update:
            try:
                # è·å–å½“å‰é…ç½®
                response = self.lambda_client.get_function_configuration(
                    FunctionName=func_name
                )
                
                env_vars = response.get('Environment', {}).get('Variables', {})
                
                # æ›´æ–°è¡¨å
                env_vars['DYNAMODB_TABLE'] = TARGET_TABLE
                env_vars['DYNAMODB_REGION'] = REGION
                
                # æ›´æ–°Lambdaé…ç½®
                self.lambda_client.update_function_configuration(
                    FunctionName=func_name,
                    Environment={'Variables': env_vars}
                )
                
                self.log(f"æ›´æ–°Lambdaå‡½æ•° {func_name} æˆåŠŸ", "SUCCESS")
                updated_count += 1
                
            except self.lambda_client.exceptions.ResourceNotFoundException:
                self.log(f"Lambdaå‡½æ•° {func_name} ä¸å­˜åœ¨", "WARNING")
            except Exception as e:
                self.log(f"æ›´æ–°Lambdaå‡½æ•° {func_name} å¤±è´¥: {str(e)}", "ERROR")
        
        return updated_count
    
    def update_ssm_parameters(self) -> bool:
        """æ›´æ–°SSMå‚æ•°"""
        self.log("\næ›´æ–°SSMå‚æ•°...", "INFO")
        
        try:
            # æ›´æ–°DynamoDBè¡¨åå‚æ•°
            self.ssm.put_parameter(
                Name=f"/{PROJECT}/{ENVIRONMENT}/dynamodb-table",
                Value=TARGET_TABLE,
                Type="String",
                Overwrite=True,
                Description="Primary DynamoDB table for AI PPT Assistant"
            )
            
            # æ›´æ–°è¡¨é…ç½®
            self.ssm.put_parameter(
                Name=f"/{PROJECT}/{ENVIRONMENT}/dynamodb-tables",
                Value=json.dumps({
                    'primary': TARGET_TABLE,
                    'deprecated': {
                        'tasks': TABLES['tasks'],
                        'reason': 'Migrated to sessions table'
                    }
                }),
                Type="String",
                Overwrite=True
            )
            
            self.log("SSMå‚æ•°æ›´æ–°æˆåŠŸ", "SUCCESS")
            return True
            
        except Exception as e:
            self.log(f"æ›´æ–°SSMå‚æ•°å¤±è´¥: {str(e)}", "ERROR")
            return False
    
    def verify_migration(self) -> bool:
        """éªŒè¯è¿ç§»ç»“æœ"""
        self.log("\néªŒè¯è¿ç§»ç»“æœ...", "INFO")
        
        # éªŒè¯ç›®æ ‡è¡¨è®°å½•æ•°
        target_table = self.dynamodb.Table(TARGET_TABLE)
        
        try:
            response = target_table.scan(Select='COUNT')
            total_items = response['Count']
            
            # å¤„ç†åˆ†é¡µ
            while 'LastEvaluatedKey' in response:
                response = target_table.scan(
                    Select='COUNT',
                    ExclusiveStartKey=response['LastEvaluatedKey']
                )
                total_items += response['Count']
            
            self.log(f"ç›®æ ‡è¡¨ {TARGET_TABLE} å…±æœ‰ {total_items} æ¡è®°å½•", "DATA")
            
            # éªŒè¯å…³é”®è®°å½•
            if len(self.backup_data.get('tasks', [])) > 0:
                # æŠ½æ ·éªŒè¯
                sample_item = self.backup_data['tasks'][0]
                task_id = sample_item.get('taskId')
                
                if task_id:
                    response = target_table.get_item(Key={'taskId': task_id})
                    if 'Item' in response:
                        self.log(f"æŠ½æ ·éªŒè¯æˆåŠŸ: æ‰¾åˆ°è®°å½• {task_id}", "SUCCESS")
                    else:
                        self.log(f"æŠ½æ ·éªŒè¯å¤±è´¥: æœªæ‰¾åˆ°è®°å½• {task_id}", "ERROR")
                        return False
            
            return True
            
        except Exception as e:
            self.log(f"éªŒè¯å¤±è´¥: {str(e)}", "ERROR")
            return False
    
    def generate_report(self):
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        report = {
            'migration_time': datetime.now().isoformat(),
            'region': REGION,
            'target_table': TARGET_TABLE,
            'statistics': self.migration_stats,
            'backup_data_summary': {
                table: len(items) for table, items in self.backup_data.items()
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f'migration_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        self.log(f"\næŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}", "SUCCESS")
        
        # æ‰“å°æ‘˜è¦
        print("\n" + "=" * 60)
        print("ğŸ“Š è¿ç§»æ‘˜è¦")
        print("=" * 60)
        print(f"æ‰«æè®°å½•æ€»æ•°: {self.migration_stats['total_scanned']}")
        print(f"âœ… æˆåŠŸè¿ç§»: {self.migration_stats['migrated']}")
        print(f"â­ï¸  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {self.migration_stats['skipped']}")
        print(f"âŒ å¤±è´¥: {self.migration_stats['failed']}")
        
        if self.migration_stats['errors']:
            print(f"\né”™è¯¯åˆ—è¡¨:")
            for error in self.migration_stats['errors'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                print(f"  - {error}")
        
        print("=" * 60)
    
    def run(self) -> bool:
        """æ‰§è¡Œå®Œæ•´çš„è¿ç§»æµç¨‹"""
        try:
            # æ­¥éª¤1: å¤‡ä»½
            backup_file = self.backup_tables()
            
            # æ­¥éª¤2: è¿ç§»æ•°æ®
            if not self.migrate_data():
                self.log("æ•°æ®è¿ç§»å¤±è´¥", "ERROR")
                return False
            
            # æ­¥éª¤3: æ›´æ–°Lambdaé…ç½®
            lambda_updated = self.update_lambda_configurations()
            self.log(f"æ›´æ–°äº† {lambda_updated} ä¸ªLambdaå‡½æ•°", "INFO")
            
            # æ­¥éª¤4: æ›´æ–°SSMå‚æ•°
            self.update_ssm_parameters()
            
            # æ­¥éª¤5: éªŒè¯
            if not self.verify_migration():
                self.log("è¿ç§»éªŒè¯å¤±è´¥", "WARNING")
            
            # æ­¥éª¤6: ç”ŸæˆæŠ¥å‘Š
            self.generate_report()
            
            return True
            
        except Exception as e:
            self.log(f"è¿ç§»è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}", "ERROR")
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ DynamoDBæ•°æ®è¿ç§»å·¥å…·")
    print("=" * 60)
    print(f"ç›®æ ‡è¡¨: {TARGET_TABLE}")
    print(f"åŒºåŸŸ: {REGION}")
    print("=" * 60)
    
    # ç¡®è®¤æ‰§è¡Œ
    print("\nâš ï¸  æ­¤æ“ä½œå°†:")
    print("  1. å¤‡ä»½æ‰€æœ‰DynamoDBè¡¨")
    print("  2. å°†tasksè¡¨æ•°æ®è¿ç§»åˆ°sessionsè¡¨")
    print("  3. æ›´æ–°æ‰€æœ‰Lambdaå‡½æ•°é…ç½®")
    print("  4. æ›´æ–°SSMå‚æ•°")
    print("")
    
    response = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(yes/no): ")
    
    if response.lower() != 'yes':
        print("æ“ä½œå·²å–æ¶ˆ")
        return 1
    
    # æ‰§è¡Œè¿ç§»
    migrator = DynamoDBMigrator()
    
    if migrator.run():
        print("\nğŸ‰ æ•°æ®è¿ç§»æˆåŠŸå®Œæˆï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œ: python3 setup_config_center.py")
        print("2. è¿è¡Œ: python3 test_all_backend_apis.py")
        print("3. éªŒè¯åº”ç”¨åŠŸèƒ½æ­£å¸¸")
        return 0
    else:
        print("\nâŒ æ•°æ®è¿ç§»å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—")
        return 1

if __name__ == "__main__":
    sys.exit(main())