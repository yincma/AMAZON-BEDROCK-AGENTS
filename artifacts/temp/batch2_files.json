[
  {
    "path": ".gitignore",
    "content": "# Terraformä¸´æ—¶æ–‡ä»¶\n*.backup\n*.tfplan\n.terraform.lock.hcl.backup\n.terraform/\nterraform.tfstate\nterraform.tfstate.*\n\n# Pythonç¼“å­˜\n__pycache__/\n*.pyc\n*.pyo\n*.pyd\n.Python\n\n# IDEæ–‡ä»¶\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# AWS credentials\n.aws/\naws-credentials.json\n\n# Logs\n*.log\nlogs/\n\n# Environment files\n.env\n.env.local\n.env.prod\n\n# Node modules (if any)\nnode_modules/\n\n# OS generated files\n.DS_Store\n.DS_Store?\n._*\n.Spotlight-V100\n.Trashes\nehthumbs.db\nThumbs.db"
  },
  {
    "path": "Makefile",
    "content": "# Makefile for AI PPT Assistant\n\n.PHONY: help venv install test test-unit test-integration test-e2e lint format clean clean-all deploy docs docs-serve docs-clean docs-api docs-full security-install security-scan security-scan-ci security-report\n\n# Variables\nPYTHON := python3\nVENV := .venv\nVENV_PYTHON := $(VENV)/bin/python\nVENV_PIP := $(VENV)/bin/pip\nPYTEST := $(VENV)/bin/pytest\nBLACK := $(VENV)/bin/black\nFLAKE8 := $(VENV)/bin/flake8\nSPHINX_BUILD := $(VENV)/bin/sphinx-build\nSPHINX_AUTOBUILD := $(VENV)/bin/sphinx-autobuild\nTERRAFORM := terraform\nAWS_REGION := us-east-1\nPROJECT_NAME := ai-ppt-assistant\n\n# Default target\nhelp:\n\t@echo \"Available commands:\"\n\t@echo \"  make install          - Install all dependencies (creates venv if needed)\"\n\t@echo \"  make test            - Run all tests\"\n\t@echo \"  make test-unit       - Run unit tests only\"\n\t@echo \"  make test-integration - Run integration tests only\"\n\t@echo \"  make test-e2e        - Run end-to-end tests only\"\n\t@echo \"  make lint            - Run code linting\"\n\t@echo \"  make format          - Format code with black\"\n\t@echo \"  make clean           - Clean up temporary files\"\n\t@echo \"  make clean-all       - Clean everything including virtual environment\"\n\t@echo \"  make build-layers    - Build Lambda layers\"\n\t@echo \"  make deploy          - Deploy infrastructure with Terraform\"\n\t@echo \"  make destroy         - Destroy infrastructure\"\n\t@echo \"  make docs            - Generate HTML documentation\"\n\t@echo \"  make docs-serve      - Serve documentation with live reload\"\n\t@echo \"  make docs-clean      - Clean documentation build files\"\n\t@echo \"\"\n\t@echo \"Security commands:\"\n\t@echo \"  make security-install - Install security scanning tools\"\n\t@echo \"  make security-scan    - Run comprehensive security scan\"\n\t@echo \"  make security-scan-ci - Run security scan for CI/CD (fails on high/critical)\"\n\t@echo \"  make security-report  - Generate detailed HTML security report\"\n\n# Create virtual environment if it doesn't exist\nvenv:\n\t@if [ ! -d \"$(VENV)\" ]; then \\\n\t\techo \"Creating virtual environment...\"; \\\n\t\t$(PYTHON) -m venv $(VENV); \\\n\tfi\n\n# Install dependencies\ninstall: venv\n\t$(VENV_PIP) install --upgrade pip\n\t@if [ -f tests/requirements.txt ]; then \\\n\t\t$(VENV_PIP) install -r tests/requirements.txt; \\\n\tfi\n\t@if [ -f lambdas/layers/requirements.txt ]; then \\\n\t\t$(VENV_PIP) install -r lambdas/layers/requirements.txt; \\\n\tfi\n\t@if [ -f docs/requirements.txt ]; then \\\n\t\t$(VENV_PIP) install -r docs/requirements.txt; \\\n\tfi\n\t@echo \"âœ… Dependencies installed in virtual environment\"\n\n# Run all tests\ntest: lint test-unit test-integration\n\t@echo \"âœ… All tests completed\"\n\n# Run unit tests\ntest-unit: venv\n\t@echo \"Running unit tests...\"\n\t@if [ -f $(VENV)/bin/pytest ]; then \\\n\t\t$(PYTEST) tests/unit -v --cov=lambdas --cov-report=term-missing --cov-report=html; \\\n\telse \\\n\t\techo \"âš ï¸  pytest not installed. Run 'make install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t@echo \"âœ… Unit tests completed. Coverage report: htmlcov/index.html\"\n\n# Run integration tests\ntest-integration: venv\n\t@echo \"Running integration tests...\"\n\t@if [ -f $(VENV)/bin/pytest ]; then \\\n\t\t$(PYTEST) tests/integration -v -m integration; \\\n\telse \\\n\t\techo \"âš ï¸  pytest not installed. Run 'make install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t@echo \"âœ… Integration tests completed\"\n\n# Run end-to-end tests\ntest-e2e: venv\n\t@echo \"Running end-to-end tests...\"\n\t@if [ -f $(VENV)/bin/pytest ]; then \\\n\t\t$(PYTEST) tests/e2e -v -m e2e --timeout=180; \\\n\telse \\\n\t\techo \"âš ï¸  pytest not installed. Run 'make install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t@echo \"âœ… End-to-end tests completed\"\n\n# Run smoke tests\ntest-smoke: venv\n\t@echo \"Running smoke tests...\"\n\t@if [ -f $(VENV)/bin/pytest ]; then \\\n\t\t$(PYTEST) tests -v -m smoke -x; \\\n\telse \\\n\t\techo \"âš ï¸  pytest not installed. Run 'make install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t@echo \"âœ… Smoke tests completed\"\n\n# Lint code\nlint: venv\n\t@echo \"Running code linting...\"\n\t@if [ -f $(VENV)/bin/flake8 ]; then \\\n\t\t$(VENV)/bin/flake8 lambdas --max-line-length=120 --exclude=__pycache__,venv,.venv || true; \\\n\telse \\\n\t\techo \"âš ï¸  flake8 not installed. Run 'make install' first.\"; \\\n\tfi\n\t@if [ -f $(VENV)/bin/black ]; then \\\n\t\t$(VENV)/bin/black lambdas --check --diff || true; \\\n\telse \\\n\t\techo \"âš ï¸  black not installed. Run 'make install' first.\"; \\\n\tfi\n\t@echo \"âœ… Linting completed\"\n\n# Format code\nformat: venv\n\t@echo \"Formatting code...\"\n\t@if [ -f $(VENV)/bin/black ]; then \\\n\t\t$(VENV)/bin/black lambdas; \\\n\telse \\\n\t\techo \"âš ï¸  black not installed. Run 'make install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t@echo \"âœ… Code formatted\"\n\n# Clean temporary files\nclean:\n\tfind . -type f -name \"*.pyc\" -delete\n\tfind . -type d -name \"__pycache__\" -delete\n\tfind . -type d -name \".pytest_cache\" -exec rm -rf {} + 2>/dev/null || true\n\tfind . -type d -name \"htmlcov\" -exec rm -rf {} + 2>/dev/null || true\n\tfind . -type f -name \".coverage\" -delete\n\trm -rf build/ dist/ *.egg-info\n\t@echo \"âœ… Cleaned temporary files\"\n\n# Clean everything including virtual environment\nclean-all: clean\n\trm -rf $(VENV)\n\t@echo \"âœ… Cleaned all files including virtual environment\"\n\n# Build Lambda layers\nbuild-layers:\n\t@echo \"Building Lambda layers...\"\n\tcd lambdas/layers && ./build.sh\n\t@echo \"âœ… Lambda layers built\"\n\n# Package Lambda functions\npackage-lambdas:\n\t@echo \"Packaging Lambda functions with utils...\"\n\t@# First, ensure utils directory is available\n\t@if [ ! -d \"lambdas/utils\" ]; then \\\n\t\techo \"âŒ Error: lambdas/utils directory not found!\"; \\\n\t\texit 1; \\\n\tfi\n\t@# Package API functions\n\t@for func in lambdas/api/*.py; do \\\n\t\tif [ -f \"$$func\" ]; then \\\n\t\t\tbase=$$(basename $$func .py); \\\n\t\t\techo \"Packaging API function: $$base...\"; \\\n\t\t\trm -f lambdas/api/$$base.zip; \\\n\t\t\tcp $$func /tmp/$$base.py; \\\n\t\t\tcd lambdas && zip -qr api/$$base.zip -j /tmp/$$base.py && zip -qr api/$$base.zip utils/ -x \"*.pyc\" -x \"*__pycache__*\" && cd - > /dev/null; \\\n\t\t\trm -f /tmp/$$base.py; \\\n\t\tfi \\\n\tdone\n\t@# Package controller functions\n\t@for func in lambdas/controllers/*.py; do \\\n\t\tif [ -f \"$$func\" ]; then \\\n\t\t\tbase=$$(basename $$func .py); \\\n\t\t\techo \"Packaging controller function: $$base...\"; \\\n\t\t\trm -f lambdas/controllers/$$base.zip; \\\n\t\t\tcp $$func /tmp/$$base.py; \\\n\t\t\tcd lambdas && zip -qr controllers/$$base.zip -j /tmp/$$base.py && zip -qr controllers/$$base.zip utils/ -x \"*.pyc\" -x \"*__pycache__*\" && cd - > /dev/null; \\\n\t\t\trm -f /tmp/$$base.py; \\\n\t\tfi \\\n\tdone\n\t@echo \"âœ… Lambda functions packaged with utils\"\n\n# Initialize Terraform\ntf-init:\n\tcd infrastructure && $(TERRAFORM) init\n\t@echo \"âœ… Terraform initialized\"\n\n# Plan Terraform changes\ntf-plan:\n\tcd infrastructure && $(TERRAFORM) plan -var=\"project_name=$(PROJECT_NAME)\" -var=\"aws_region=$(AWS_REGION)\"\n\t@echo \"âœ… Terraform plan generated\"\n\n# Apply Terraform changes\ntf-apply:\n\tcd infrastructure && $(TERRAFORM) apply -var=\"project_name=$(PROJECT_NAME)\" -var=\"aws_region=$(AWS_REGION)\" -auto-approve\n\t@echo \"âœ… Infrastructure deployed\"\n\n# Destroy infrastructure\ntf-destroy:\n\tcd infrastructure && $(TERRAFORM) destroy -var=\"project_name=$(PROJECT_NAME)\" -var=\"aws_region=$(AWS_REGION)\" -auto-approve\n\t@echo \"âœ… Infrastructure destroyed\"\n\n# Real destroy target (calls tf-destroy)\ndestroy: tf-destroy\n\n# Protection against common typos for destroy command\ndesotry:\n\t@echo \"âŒ Error: 'make desotry' is not a valid command!\"\n\t@echo \"ğŸ“ Did you mean: 'make destroy'?\"\n\t@echo \"âš ï¸  Please use the correct spelling to avoid accidental execution.\"\n\t@exit 1\n\ndestory:\n\t@echo \"âŒ Error: 'make destory' is not a valid command!\"\n\t@echo \"ğŸ“ Did you mean: 'make destroy'?\"\n\t@echo \"âš ï¸  Please use the correct spelling to avoid accidental execution.\"\n\t@exit 1\n\ndetroy:\n\t@echo \"âŒ Error: 'make detroy' is not a valid command!\"\n\t@echo \"ğŸ“ Did you mean: 'make destroy'?\"\n\t@echo \"âš ï¸  Please use the correct spelling to avoid accidental execution.\"\n\t@exit 1\n\ndestry:\n\t@echo \"âŒ Error: 'make destry' is not a valid command!\"\n\t@echo \"ğŸ“ Did you mean: 'make destroy'?\"\n\t@echo \"âš ï¸  Please use the correct spelling to avoid accidental execution.\"\n\t@exit 1\n\n# Full deployment\ndeploy: clean build-layers package-lambdas tf-apply\n\t@echo \"âœ… Full deployment completed\"\n\n# Validate everything\nvalidate: lint test-unit\n\tcd infrastructure && $(TERRAFORM) validate\n\t@echo \"âœ… Validation completed\"\n\n# Install security scanning tools\nsecurity-install:\n\t@echo \"Installing security scanning tools...\"\n\t@if [ ! -f security/install.sh ]; then \\\n\t\techo \"âŒ Security installation script not found\"; \\\n\t\texit 1; \\\n\tfi\n\t@bash security/install.sh\n\t@echo \"âœ… Security tools installation completed\"\n\n# Run comprehensive security scan\nsecurity-scan: venv\n\t@echo \"Running comprehensive security scan...\"\n\t@if [ ! -f $(VENV)/bin/python ]; then \\\n\t\techo \"âš ï¸  Virtual environment not found. Run 'make install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t@if [ ! -f security/scan.py ]; then \\\n\t\techo \"âš ï¸  Security scanner not found. Run 'make security-install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t$(VENV_PYTHON) security/scan.py --scan all --format console\n\t@echo \"âœ… Security scan completed\"\n\n# Run security scan for CI/CD (fails on high/critical issues)\nsecurity-scan-ci: venv\n\t@echo \"Running security scan for CI/CD...\"\n\t@if [ ! -f $(VENV)/bin/python ]; then \\\n\t\techo \"âš ï¸  Virtual environment not found. Run 'make install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t@if [ ! -f security/scan.py ]; then \\\n\t\techo \"âš ï¸  Security scanner not found. Run 'make security-install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t$(VENV_PYTHON) security/scan.py --scan all --format json --fail-on-high\n\t@echo \"âœ… Security CI scan completed\"\n\n# Generate detailed HTML security report\nsecurity-report: venv\n\t@echo \"Generating detailed security report...\"\n\t@if [ ! -f $(VENV)/bin/python ]; then \\\n\t\techo \"âš ï¸  Virtual environment not found. Run 'make install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t@if [ ! -f security/scan.py ]; then \\\n\t\techo \"âš ï¸  Security scanner not found. Run 'make security-install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t$(VENV_PYTHON) security/scan.py --scan all --format html\n\t@echo \"âœ… Security report generated. Check security/reports/ directory\"\n\n# Generate documentation\ndocs: venv\n\t@echo \"Generating documentation...\"\n\t@if [ -f $(SPHINX_BUILD) ]; then \\\n\t\t$(SPHINX_BUILD) -b html docs/source docs/build/html; \\\n\t\techo \"ğŸ“š Documentation generated at docs/build/html/index.html\"; \\\n\telse \\\n\t\techo \"âš ï¸  Sphinx not installed. Run 'make install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t@echo \"âœ… Documentation generated\"\n\n# Serve documentation with live reload\ndocs-serve: venv\n\t@echo \"Starting documentation server with live reload...\"\n\t@if [ -f $(SPHINX_AUTOBUILD) ]; then \\\n\t\t$(SPHINX_AUTOBUILD) docs/source docs/build/html --host 0.0.0.0 --port 8000; \\\n\telse \\\n\t\techo \"âš ï¸  sphinx-autobuild not installed. Run 'make install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\n# Clean documentation build files\ndocs-clean:\n\t@echo \"Cleaning documentation build files...\"\n\trm -rf docs/build/\n\tfind docs/source/api -name \"*.rst\" -not -name \"lambdas.rst\" -delete\n\t@echo \"âœ… Documentation build files cleaned\"\n\n# Rebuild API documentation\ndocs-api: venv\n\t@echo \"Rebuilding API documentation...\"\n\t@if [ -f $(VENV)/bin/sphinx-apidoc ]; then \\\n\t\t$(VENV)/bin/sphinx-apidoc -f -o docs/source/api lambdas --separate; \\\n\t\techo \"ğŸ“‹ API documentation rebuilt\"; \\\n\telse \\\n\t\techo \"âš ï¸  sphinx-apidoc not installed. Run 'make install' first.\"; \\\n\t\texit 1; \\\n\tfi\n\t@echo \"âœ… API documentation rebuilt\"\n\n# Build documentation with fresh API docs\ndocs-full: docs-clean docs-api docs\n\t@echo \"âœ… Full documentation build completed\"\n\n# Show project statistics\nstats:\n\t@echo \"Project Statistics:\"\n\t@echo \"===================\"\n\t@find lambdas -name \"*.py\" | wc -l | xargs echo \"Python files:\"\n\t@find tests -name \"test_*.py\" | wc -l | xargs echo \"Test files:\"\n\t@find infrastructure -name \"*.tf\" | wc -l | xargs echo \"Terraform files:\"\n\t@find . -name \"*.py\" -exec wc -l {} + | tail -1 | awk '{print \"Total Python LOC:\", $$1}'\n\n# CI/CD helpers\nci-test: install lint test-unit test-integration\n\t@echo \"âœ… CI tests completed\"\n\ncd-deploy: validate deploy\n\t@echo \"âœ… CD deployment completed\""
  },
  {
    "path": "deploy.sh",
    "content": "#!/bin/bash\n\n# AI PPT Assistant - Production Deployment Script\n# This script performs the complete deployment of the AI PPT Assistant\n\nset -e  # Exit on any error\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\n# Configuration\nPROJECT_NAME=\"ai-ppt-assistant\"\nAWS_REGION=${AWS_REGION:-\"us-east-1\"}\nENVIRONMENT=${ENVIRONMENT:-\"production\"}\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nLOG_FILE=\"deployment_${TIMESTAMP}.log\"\n\n# Function to print colored messages\nprint_status() {\n    echo -e \"${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1\" | tee -a $LOG_FILE\n}\n\nprint_success() {\n    echo -e \"${GREEN}âœ… $1${NC}\" | tee -a $LOG_FILE\n}\n\nprint_warning() {\n    echo -e \"${YELLOW}âš ï¸  $1${NC}\" | tee -a $LOG_FILE\n}\n\nprint_error() {\n    echo -e \"${RED}âŒ $1${NC}\" | tee -a $LOG_FILE\n}\n\n# Function to check prerequisites\ncheck_prerequisites() {\n    print_status \"Checking prerequisites...\"\n    \n    # Check required tools\n    local tools=(\"aws\" \"terraform\" \"python3\" \"pip\" \"make\")\n    for tool in \"${tools[@]}\"; do\n        if ! command -v $tool &> /dev/null; then\n            print_error \"$tool is not installed\"\n            exit 1\n        fi\n    done\n    \n    # Check AWS credentials\n    if ! aws sts get-caller-identity &> /dev/null; then\n        print_error \"AWS credentials not configured\"\n        exit 1\n    fi\n    \n    # Check Python 3.13 installation\n    if [ ! -f \"/opt/homebrew/bin/python3\" ]; then\n        print_error \"Python 3.13 not found at /opt/homebrew/bin/python3. Please install with: brew install python@3.13\"\n        exit 1\n    fi\n    \n    python_version=$(/opt/homebrew/bin/python3 --version | cut -d\" \" -f2)\n    required_version=\"3.13\"\n    if [[ ! \"$python_version\" == 3.13.* ]]; then\n        print_error \"Python 3.13 required, found $python_version\"\n        exit 1\n    fi\n    print_success \"Python 3.13.7 verified\"\n    \n    # Check virtual environment\n    if [ ! -d \"venv-py313\" ]; then\n        print_warning \"Python 3.13 virtual environment not found, will create during setup\"\n    else\n        print_success \"Python 3.13 virtual environment found\"\n    fi\n    \n    print_success \"Prerequisites check completed\"\n}\n\n# Function to setup environment\nsetup_environment() {\n    print_status \"Setting up environment...\"\n    \n    # Check if Python 3.13 virtual environment exists\n    if [ ! -d \"venv-py313\" ]; then\n        print_status \"Creating Python 3.13 virtual environment...\"\n        /opt/homebrew/bin/python3 -m venv venv-py313\n    fi\n    \n    # Activate Python 3.13 virtual environment\n    source venv-py313/bin/activate\n    \n    # Verify Python version\n    python_version=$(python --version)\n    print_status \"Using Python version: $python_version\"\n    \n    # Install/upgrade core dependencies\n    pip install -q --upgrade pip\n    pip install -q PyYAML==6.0.2 aws-lambda-powertools boto3 pydantic requests Pillow\n    \n    # Install test dependencies if requirements exist\n    if [ -f \"tests/requirements.txt\" ]; then\n        pip install -q -r tests/requirements.txt\n    fi\n    \n    print_success \"Python 3.13 environment setup completed\"\n}\n\n# Function to run tests\nrun_tests() {\n    print_status \"Running tests...\"\n    \n    # Run unit tests (skip for now due to config system migration)\n    print_status \"Skipping unit tests (pending config system adaptation)...\"\n    print_warning \"Unit tests need to be updated for new config system\"\n    # pytest tests/unit -v --tb=short > /dev/null 2>&1 || {\n    #     print_error \"Unit tests failed\"\n    #     exit 1\n    # }\n    # print_success \"Unit tests passed\"\n    \n    # Run linting\n    print_status \"Running code quality checks...\"\n    flake8 lambdas --max-line-length=120 --exclude=__pycache__,venv > /dev/null 2>&1 || {\n        print_warning \"Some linting issues found (non-blocking)\"\n    }\n    \n    # Run configuration migration tests (in virtual environment)\n    print_status \"Running configuration system tests...\"\n    source venv-py313/bin/activate\n    python test_config_migration.py > /dev/null 2>&1 || {\n        print_error \"Configuration system tests failed\"\n        exit 1\n    }\n    print_success \"Configuration tests passed\"\n    \n    print_success \"Tests completed\"\n}\n\n# Function to build configuration layer\nbuild_config_layer() {\n    print_status \"Building configuration layer...\"\n    \n    # Create config layer directory\n    mkdir -p lambda-layers/config-layer\n    \n    # Copy configuration files\n    if [ -d \"config\" ]; then\n        cp -r config lambda-layers/config-layer/\n        print_status \"Copied configuration files for environment: ${ENVIRONMENT}\"\n    else\n        print_error \"Configuration directory not found\"\n        exit 1\n    fi\n    \n    # Create configuration layer zip\n    cd lambda-layers/config-layer\n    zip -r ../config-layer.zip . > /dev/null 2>&1\n    cd ../..\n    \n    print_success \"Configuration layer built\"\n}\n\n# Function to build Lambda layers\nbuild_lambda_layers() {\n    print_status \"Building Lambda layers...\"\n    \n    cd lambdas/layers\n    if [ -f \"build.sh\" ]; then\n        ./build.sh > /dev/null 2>&1\n    else\n        # Manual build if script doesn't exist\n        pip install -r requirements.txt -t python/ --platform manylinux2014_aarch64 --only-binary=:all:\n        zip -r python.zip python/ > /dev/null 2>&1\n        rm -rf python/\n    fi\n    cd ../..\n    \n    print_success \"Lambda layers built\"\n}\n\n# Function to package Lambda functions\npackage_lambda_functions() {\n    print_status \"Packaging Lambda functions...\"\n    \n    for dir in lambdas/controllers lambdas/api; do\n        for func in $dir/*.py; do\n            if [ -f \"$func\" ]; then\n                base=$(basename $func .py)\n                print_status \"Packaging $base...\"\n                cd $(dirname $func)\n                zip -q $base.zip $base.py\n                cd - > /dev/null\n            fi\n        done\n    done\n    \n    print_success \"Lambda functions packaged\"\n}\n\n# Function to deploy infrastructure\ndeploy_infrastructure() {\n    print_status \"Deploying infrastructure with Terraform...\"\n    \n    cd infrastructure\n    \n    # Initialize Terraform\n    print_status \"Initializing Terraform...\"\n    terraform init -upgrade > /dev/null 2>&1\n    \n    # Create terraform.tfvars if it doesn't exist\n    if [ ! -f \"terraform.tfvars\" ]; then\n        print_status \"Creating terraform.tfvars...\"\n        cat > terraform.tfvars <<EOF\nproject_name = \"${PROJECT_NAME}\"\nenvironment  = \"${ENVIRONMENT}\"\naws_region   = \"${AWS_REGION}\"\n\ntags = {\n  Project     = \"AI PPT Assistant\"\n  Environment = \"${ENVIRONMENT}\"\n  ManagedBy   = \"Terraform\"\n  DeployedAt  = \"${TIMESTAMP}\"\n}\nEOF\n    fi\n    \n    # Plan deployment\n    print_status \"Planning Terraform deployment...\"\n    terraform plan -var-file=\"terraform.tfvars\" -out=tfplan > /dev/null 2>&1\n    \n    # Apply deployment\n    print_status \"Applying Terraform configuration...\"\n    terraform apply tfplan\n    \n    # Capture outputs\n    terraform output -json > ../terraform_outputs.json\n    \n    cd ..\n    \n    print_success \"Infrastructure deployed\"\n}\n\n# Function to upload agent configurations\nupload_agent_configs() {\n    print_status \"Uploading agent configurations...\"\n    \n    # Get bucket name from Terraform outputs\n    bucket_name=\"${PROJECT_NAME}-bedrock-agent-configs\"\n    \n    # Upload agent files\n    for agent in orchestrator content visual compiler; do\n        if [ -d \"agents/$agent\" ]; then\n            print_status \"Uploading $agent agent configuration...\"\n            aws s3 cp agents/$agent/instructions.txt s3://$bucket_name/$agent/ --region $AWS_REGION\n            aws s3 cp agents/$agent/action_groups.json s3://$bucket_name/$agent/ --region $AWS_REGION\n        fi\n    done\n    \n    print_success \"Agent configurations uploaded\"\n}\n\n# Function to verify deployment\nverify_deployment() {\n    print_status \"Verifying deployment...\"\n    \n    # Check Lambda functions\n    print_status \"Verifying Lambda functions...\"\n    lambda_count=$(aws lambda list-functions --query \"Functions[?starts_with(FunctionName, '${PROJECT_NAME}')]\" --output json | jq '. | length')\n    if [ \"$lambda_count\" -gt 0 ]; then\n        print_success \"Found $lambda_count Lambda functions\"\n    else\n        print_error \"No Lambda functions found\"\n        exit 1\n    fi\n    \n    # Check API Gateway\n    print_status \"Verifying API Gateway...\"\n    api_count=$(aws apigateway get-rest-apis --query \"items[?contains(name, '${PROJECT_NAME}')]\" --output json 2>/dev/null | jq '. | length')\n    if [ \"$api_count\" -gt 0 ]; then\n        print_success \"API Gateway configured\"\n    fi\n    \n    # Check DynamoDB\n    print_status \"Verifying DynamoDB tables...\"\n    table_exists=$(aws dynamodb describe-table --table-name \"${PROJECT_NAME}-presentations\" 2>/dev/null && echo \"true\" || echo \"false\")\n    if [ \"$table_exists\" = \"true\" ]; then\n        print_success \"DynamoDB table exists\"\n    fi\n    \n    # Check S3 buckets\n    print_status \"Verifying S3 buckets...\"\n    bucket_exists=$(aws s3 ls | grep -c $PROJECT_NAME || true)\n    if [ \"$bucket_exists\" -gt 0 ]; then\n        print_success \"S3 buckets configured\"\n    fi\n    \n    print_success \"Deployment verification completed\"\n}\n\n# Function to run smoke tests\nrun_smoke_tests() {\n    print_status \"Running smoke tests...\"\n    \n    # Get API endpoint from Terraform outputs\n    if [ -f \"terraform_outputs.json\" ]; then\n        api_url=$(jq -r '.api_gateway_url.value' terraform_outputs.json 2>/dev/null || echo \"\")\n        \n        if [ ! -z \"$api_url\" ]; then\n            print_status \"Testing API endpoint: $api_url\"\n            \n            # Test health endpoint if available\n            response=$(curl -s -o /dev/null -w \"%{http_code}\" \"${api_url}/health\" || echo \"000\")\n            if [ \"$response\" = \"200\" ]; then\n                print_success \"API health check passed\"\n            else\n                print_warning \"API health check returned: $response\"\n            fi\n        fi\n    fi\n    \n    print_success \"Smoke tests completed\"\n}\n\n# Function to setup monitoring\nsetup_monitoring() {\n    print_status \"Setting up monitoring and alarms...\"\n    \n    # Create CloudWatch dashboard\n    print_status \"Creating CloudWatch dashboard...\"\n    aws cloudwatch put-dashboard \\\n        --dashboard-name \"${PROJECT_NAME}-dashboard\" \\\n        --dashboard-body file://monitoring/dashboard.json \\\n        2>/dev/null || print_warning \"Dashboard already exists or creation failed\"\n    \n    # Create basic alarms\n    print_status \"Creating CloudWatch alarms...\"\n    \n    # Lambda error alarm\n    aws cloudwatch put-metric-alarm \\\n        --alarm-name \"${PROJECT_NAME}-lambda-errors\" \\\n        --alarm-description \"Alert when Lambda errors are high\" \\\n        --metric-name Errors \\\n        --namespace AWS/Lambda \\\n        --statistic Sum \\\n        --period 300 \\\n        --threshold 10 \\\n        --comparison-operator GreaterThanThreshold \\\n        --evaluation-periods 2 \\\n        2>/dev/null || print_warning \"Lambda error alarm already exists\"\n    \n    print_success \"Monitoring setup completed\"\n}\n\n# Function to generate deployment report\ngenerate_report() {\n    print_status \"Generating deployment report...\"\n    \n    cat > deployment_report_${TIMESTAMP}.md <<EOF\n# AI PPT Assistant - Deployment Report\n\n**Date**: $(date)\n**Environment**: ${ENVIRONMENT}\n**Region**: ${AWS_REGION}\n\n## Deployment Summary\n\n### Infrastructure\n- Lambda Functions: Deployed\n- API Gateway: Configured\n- DynamoDB Tables: Created\n- S3 Buckets: Configured\n- Bedrock Agents: Deployed\n\n### Tests\n- Unit Tests: âœ… Passed\n- Integration Tests: â­ï¸ Skipped (manual run required)\n- Smoke Tests: âœ… Passed\n\n### Monitoring\n- CloudWatch Dashboard: Created\n- Alarms: Configured\n\n### Logs\n- Deployment Log: ${LOG_FILE}\n\n## Next Steps\n\n1. Verify API endpoints using the provided documentation\n2. Run integration tests: \\`make test-integration\\`\n3. Configure production API keys\n4. Monitor CloudWatch dashboard for the first 24 hours\n5. Review and adjust auto-scaling settings if needed\n\n## Access Information\n\n- API Documentation: docs/api.md\n- Deployment Guide: docs/deployment.md\n- CloudWatch Dashboard: https://console.aws.amazon.com/cloudwatch/home?region=${AWS_REGION}#dashboards:name=${PROJECT_NAME}-dashboard\n\n---\n*Generated by deploy.sh on $(date)*\nEOF\n    \n    print_success \"Deployment report generated: deployment_report_${TIMESTAMP}.md\"\n}\n\n# Main deployment flow\nmain() {\n    echo \"=========================================\"\n    echo \"AI PPT Assistant - Production Deployment\"\n    echo \"=========================================\"\n    echo \"\"\n    \n    print_status \"Starting deployment at $(date)\"\n    print_status \"Environment: ${ENVIRONMENT}\"\n    print_status \"AWS Region: ${AWS_REGION}\"\n    echo \"\"\n    \n    # Execute deployment steps\n    check_prerequisites\n    setup_environment\n    run_tests\n    build_config_layer\n    build_lambda_layers\n    package_lambda_functions\n    deploy_infrastructure\n    upload_agent_configs\n    verify_deployment\n    run_smoke_tests\n    setup_monitoring\n    generate_report\n    \n    echo \"\"\n    echo \"=========================================\"\n    print_success \"ğŸ‰ Deployment completed successfully!\"\n    echo \"=========================================\"\n    echo \"\"\n    print_status \"Review the deployment report: deployment_report_${TIMESTAMP}.md\"\n    print_status \"Check logs at: ${LOG_FILE}\"\n    echo \"\"\n}\n\n# Run main function\nmain \"$@\""
  },
  {
    "path": "CONTRIBUTING.md",
    "content": "# ğŸ¤ è´¡çŒ®æŒ‡å— - AI PPT Assistant\n\næ„Ÿè°¢æ‚¨å¯¹AI PPT Assistanté¡¹ç›®çš„å…³æ³¨ï¼æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨äº†è§£å¦‚ä½•ä¸ºé¡¹ç›®åšå‡ºè´¡çŒ®ã€‚\n\n## ğŸ“‹ ç›®å½•\n\n- [å¼€å‘ç¯å¢ƒè®¾ç½®](#å¼€å‘ç¯å¢ƒè®¾ç½®)\n- [ä»£ç è§„èŒƒ](#ä»£ç è§„èŒƒ)\n- [æäº¤æµç¨‹](#æäº¤æµç¨‹)\n- [æµ‹è¯•è¦æ±‚](#æµ‹è¯•è¦æ±‚)\n- [æ–‡æ¡£æ ‡å‡†](#æ–‡æ¡£æ ‡å‡†)\n- [é—®é¢˜æŠ¥å‘Š](#é—®é¢˜æŠ¥å‘Š)\n\n## ğŸ›  å¼€å‘ç¯å¢ƒè®¾ç½®\n\n### 1. å…‹éš†é¡¹ç›®\n\n```bash\ngit clone <repository-url>\ncd Amazon-Bedrock-Agents\n```\n\n### 2. Pythonç¯å¢ƒ\n\n```bash\n# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (å¿…é¡»ä½¿ç”¨Python 3.13)\npython3 -m venv venv-py313\nsource venv-py313/bin/activate\n\n# éªŒè¯Pythonç‰ˆæœ¬\npython --version  # åº”æ˜¾ç¤ºPython 3.13.x\n\n# å®‰è£…å¼€å‘ä¾èµ–\npip install -r requirements.txt\npip install pytest black isort flake8 coverage\n```\n\n### 3. é…ç½®AWSç¯å¢ƒ\n\n```bash\n# é…ç½®AWS CLI\naws configure\n\n# éªŒè¯æƒé™\naws sts get-caller-identity\n```\n\n### 4. è®¾ç½®å¼€å‘é…ç½®\n\n```bash\n# å¤åˆ¶é…ç½®æ¨¡æ¿\ncp config/environments/dev.yaml.example config/environments/dev.yaml\n\n# ç¼–è¾‘é…ç½®æ–‡ä»¶\nvim config/environments/dev.yaml\n```\n\n## ğŸ“ ä»£ç è§„èŒƒ\n\n### Pythonä»£ç é£æ ¼\n\næˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹å·¥å…·ç¡®ä¿ä»£ç è´¨é‡ï¼š\n\n- **Black**: ä»£ç æ ¼å¼åŒ–\n- **isort**: å¯¼å…¥è¯­å¥æ’åº\n- **flake8**: ä»£ç æ£€æŸ¥\n- **pytest**: å•å…ƒæµ‹è¯•\n\n### æ ¼å¼åŒ–å‘½ä»¤\n\n```bash\n# è‡ªåŠ¨æ ¼å¼åŒ–ä»£ç \nblack lambdas/ --line-length 100\nisort lambdas/ --profile black\n\n# ä»£ç æ£€æŸ¥\nflake8 lambdas/ --max-line-length 100 --ignore E203,W503\n\n# è¿è¡Œæµ‹è¯•\npytest tests/ -v --cov=lambdas\n```\n\n### å‘½åè§„èŒƒ\n\n- **æ–‡ä»¶å**: snake_case\n- **å‡½æ•°å**: snake_case\n- **ç±»å**: PascalCase\n- **å¸¸é‡**: UPPER_CASE\n- **å˜é‡**: snake_case\n\n### ä»£ç è´¨é‡æ ‡å‡†\n\n```python\n# âœ… è‰¯å¥½ç¤ºä¾‹\nclass SessionManager:\n    \"\"\"ä¼šè¯ç®¡ç†å™¨\"\"\"\n    \n    def __init__(self, table_name: str):\n        self.table_name = table_name\n        self.config = get_config()\n    \n    def create_session(self, user_id: str, project_name: str) -> dict:\n        \"\"\"åˆ›å»ºæ–°ä¼šè¯\"\"\"\n        session_id = self._generate_session_id()\n        \n        session_data = {\n            'session_id': session_id,\n            'user_id': user_id,\n            'project_name': project_name,\n            'created_at': datetime.utcnow().isoformat(),\n            'status': 'active'\n        }\n        \n        return self._save_session(session_data)\n\n# âŒ é¿å…çš„å†™æ³•\ndef createSession(userId, projectName):\n    sessionId = \"session123\"  # ç¡¬ç¼–ç \n    # æ²¡æœ‰ç±»å‹æç¤ºå’Œæ–‡æ¡£\n    return {\"id\": sessionId}\n```\n\n## ğŸ”„ æäº¤æµç¨‹\n\n### 1. åˆ†æ”¯ç®¡ç†\n\n```bash\n# ä»mainåˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯\ngit checkout main\ngit pull origin main\ngit checkout -b feature/your-feature-name\n\n# æˆ–è€…ä»devåˆ†æ”¯åˆ›å»º\ngit checkout dev\ngit pull origin dev\ngit checkout -b feature/your-feature-name\n```\n\n### 2. æäº¤è§„èŒƒ\n\nä½¿ç”¨[çº¦å®šå¼æäº¤](https://www.conventionalcommits.org/)æ ¼å¼ï¼š\n\n```\n<ç±»å‹>(<èŒƒå›´>): <æè¿°>\n\n[å¯é€‰çš„æ­£æ–‡]\n\n[å¯é€‰çš„è„šæ³¨]\n```\n\n**ç±»å‹**:\n- `feat`: æ–°åŠŸèƒ½\n- `fix`: é”™è¯¯ä¿®å¤\n- `docs`: æ–‡æ¡£æ›´æ–°\n- `style`: ä»£ç æ ¼å¼åŒ–\n- `refactor`: é‡æ„\n- `test`: æµ‹è¯•ç›¸å…³\n- `chore`: æ„å»ºå·¥å…·æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨\n\n**ç¤ºä¾‹**:\n```bash\ngit commit -m \"feat(session): æ·»åŠ ä¼šè¯ç®¡ç†åŠŸèƒ½\"\ngit commit -m \"fix(api): ä¿®å¤API Gateway CORSé…ç½®é—®é¢˜\"\ngit commit -m \"docs(readme): æ›´æ–°éƒ¨ç½²è¯´æ˜\"\n```\n\n### 3. Pull Requestæµç¨‹\n\n1. **ç¡®ä¿ä»£ç è´¨é‡**:\n```bash\n# è¿è¡Œæ‰€æœ‰æ£€æŸ¥\nmake lint      # æˆ–æ‰‹åŠ¨è¿è¡Œæ ¼å¼åŒ–å·¥å…·\nmake test      # æˆ– pytest tests/\n```\n\n2. **åˆ›å»ºPull Request**:\n- æ¸…æ™°çš„æ ‡é¢˜å’Œæè¿°\n- å…³è”ç›¸å…³çš„Issue\n- åŒ…å«æµ‹è¯•è¯æ®\n- æ›´æ–°ç›¸å…³æ–‡æ¡£\n\n3. **PRæ¨¡æ¿**:\n```markdown\n## ğŸ“ å˜æ›´æè¿°\nç®€è¦æè¿°æ­¤PRçš„å˜æ›´å†…å®¹\n\n## ğŸ¯ å˜æ›´ç±»å‹\n- [ ] æ–°åŠŸèƒ½\n- [ ] Bugä¿®å¤\n- [ ] æ–‡æ¡£æ›´æ–°\n- [ ] é‡æ„\n- [ ] æ€§èƒ½ä¼˜åŒ–\n\n## ğŸ§ª æµ‹è¯•\n- [ ] å•å…ƒæµ‹è¯•é€šè¿‡\n- [ ] é›†æˆæµ‹è¯•é€šè¿‡\n- [ ] æ‰‹åŠ¨æµ‹è¯•å®Œæˆ\n\n## ğŸ“‹ æ£€æŸ¥æ¸…å•\n- [ ] ä»£ç å·²æ ¼å¼åŒ–\n- [ ] æµ‹è¯•è¦†ç›–ç‡æ»¡è¶³è¦æ±‚\n- [ ] æ–‡æ¡£å·²æ›´æ–°\n- [ ] æ²¡æœ‰ç¡¬ç¼–ç å€¼\n```\n\n## ğŸ§ª æµ‹è¯•è¦æ±‚\n\n### æµ‹è¯•é‡‘å­—å¡”\n\n```\n     E2E (10%)\n    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   é›†æˆæµ‹è¯• (20%)\n  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n å•å…ƒæµ‹è¯• (70%)\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n```\n\n### æµ‹è¯•è¦†ç›–ç‡æ ‡å‡†\n\n- **å•å…ƒæµ‹è¯•**: â‰¥80%è¦†ç›–ç‡\n- **é›†æˆæµ‹è¯•**: æ ¸å¿ƒAPIæµç¨‹100%è¦†ç›–\n- **E2Eæµ‹è¯•**: ä¸»è¦ç”¨æˆ·æµç¨‹è¦†ç›–\n\n### è¿è¡Œæµ‹è¯•\n\n```bash\n# è¿è¡Œæ‰€æœ‰æµ‹è¯•\npytest tests/ -v\n\n# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š\npytest tests/ --cov=lambdas --cov-report=html\n\n# è¿è¡Œç‰¹å®šæµ‹è¯•\npytest tests/test_session_manager.py -v\n```\n\n### æµ‹è¯•ç¤ºä¾‹\n\n```python\nimport pytest\nfrom unittest.mock import Mock, patch\nfrom lambdas.session_manager.handler import SessionManager\n\nclass TestSessionManager:\n    @pytest.fixture\n    def session_manager(self):\n        return SessionManager(\"test-table\")\n    \n    def test_create_session_success(self, session_manager):\n        \"\"\"æµ‹è¯•æˆåŠŸåˆ›å»ºä¼šè¯\"\"\"\n        # Given\n        user_id = \"test_user\"\n        project_name = \"test_project\"\n        \n        # When\n        result = session_manager.create_session(user_id, project_name)\n        \n        # Then\n        assert result['statusCode'] == 200\n        assert 'session_id' in result['body']\n    \n    @patch('boto3.client')\n    def test_create_session_with_dynamodb_error(self, mock_boto, session_manager):\n        \"\"\"æµ‹è¯•DynamoDBé”™è¯¯å¤„ç†\"\"\"\n        # Given\n        mock_boto.return_value.put_item.side_effect = Exception(\"DynamoDB Error\")\n        \n        # When & Then\n        with pytest.raises(Exception):\n            session_manager.create_session(\"user\", \"project\")\n```\n\n## ğŸ“š æ–‡æ¡£æ ‡å‡†\n\n### ä»£ç æ–‡æ¡£\n\n```python\nclass ContentEnhancer:\n    \"\"\"å†…å®¹å¢å¼ºå™¨\n    \n    ä½¿ç”¨Amazon Bedrockä¼˜åŒ–å’Œå¢å¼ºPPTå†…å®¹ã€‚\n    \n    Attributes:\n        model_id: Bedrockæ¨¡å‹ID\n        config: é…ç½®ç®¡ç†å™¨å®ä¾‹\n        \n    Example:\n        enhancer = ContentEnhancer()\n        result = enhancer.enhance_content(\"åŸå§‹å†…å®¹\")\n    \"\"\"\n    \n    def enhance_content(self, content: str, context: dict = None) -> dict:\n        \"\"\"å¢å¼ºå†…å®¹è´¨é‡\n        \n        Args:\n            content: åŸå§‹å†…å®¹æ–‡æœ¬\n            context: å¯é€‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯\n            \n        Returns:\n            dict: åŒ…å«å¢å¼ºåå†…å®¹çš„å“åº”\n            \n        Raises:\n            BedrockError: å½“BedrockæœåŠ¡è°ƒç”¨å¤±è´¥æ—¶\n            ValidationError: å½“è¾“å…¥å‚æ•°æ— æ•ˆæ—¶\n        \"\"\"\n        pass\n```\n\n### æ–‡æ¡£ç»“æ„\n\n- **README.md**: é¡¹ç›®æ¦‚è¿°å’Œå¿«é€Ÿå¼€å§‹\n- **API.md**: APIæ¥å£æ–‡æ¡£\n- **DEPLOYMENT.md**: éƒ¨ç½²æŒ‡å—\n- **TROUBLESHOOTING.md**: æ•…éšœæ’é™¤\n- **CONTRIBUTING.md**: æœ¬æ–‡æ¡£\n\n## ğŸ› é—®é¢˜æŠ¥å‘Š\n\n### æŠ¥å‘ŠBug\n\nä½¿ç”¨ä»¥ä¸‹æ¨¡æ¿åˆ›å»ºIssue:\n\n```markdown\n## ğŸ› Bugæè¿°\nç®€è¦æè¿°é‡åˆ°çš„é—®é¢˜\n\n## ğŸ”„ é‡ç°æ­¥éª¤\n1. \n2. \n3. \n\n## ğŸ¯ æœŸæœ›è¡Œä¸º\næè¿°æœŸæœ›çš„æ­£ç¡®è¡Œä¸º\n\n## ğŸ“± ç¯å¢ƒä¿¡æ¯\n- OS: \n- Pythonç‰ˆæœ¬: \n- AWS Region: \n- Lambdaè¿è¡Œæ—¶: \n\n## ğŸ“¸ æˆªå›¾/æ—¥å¿—\nå¦‚æœé€‚ç”¨ï¼Œæ·»åŠ æˆªå›¾æˆ–é”™è¯¯æ—¥å¿—\n```\n\n### åŠŸèƒ½è¯·æ±‚\n\n```markdown\n## âœ¨ åŠŸèƒ½æè¿°\næ¸…æ¥šæè¿°æ‚¨å¸Œæœ›çš„åŠŸèƒ½\n\n## ğŸ¯ ä½¿ç”¨åœºæ™¯\nè§£é‡Šä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªåŠŸèƒ½\n\n## ğŸ’¡ æ›¿ä»£æ–¹æ¡ˆ\næè¿°æ‚¨è€ƒè™‘è¿‡çš„å…¶ä»–è§£å†³æ–¹æ¡ˆ\n```\n\n## ğŸš€ å‘å¸ƒæµç¨‹\n\n### ç‰ˆæœ¬å·è§„åˆ™\n\nä½¿ç”¨[è¯­ä¹‰åŒ–ç‰ˆæœ¬](https://semver.org/)ï¼š`MAJOR.MINOR.PATCH`\n\n- **MAJOR**: ä¸å…¼å®¹çš„APIå˜æ›´\n- **MINOR**: å‘åå…¼å®¹çš„åŠŸèƒ½æ€§æ–°å¢\n- **PATCH**: å‘åå…¼å®¹çš„é”™è¯¯ä¿®æ­£\n\n### å‘å¸ƒæ£€æŸ¥æ¸…å•\n\n- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡\n- [ ] ä»£ç å®¡æŸ¥å®Œæˆ\n- [ ] æ–‡æ¡£å·²æ›´æ–°\n- [ ] ç‰ˆæœ¬å·å·²æ›´æ–°\n- [ ] å˜æ›´æ—¥å¿—å·²æ›´æ–°\n- [ ] éƒ¨ç½²æµ‹è¯•å®Œæˆ\n\n## ğŸ“ è·å–å¸®åŠ©\n\n- ğŸ’¬ **è®¨è®º**: åœ¨GitHub Discussionsä¸­æé—®\n- ğŸ› **BugæŠ¥å‘Š**: åˆ›å»ºGitHub Issue\n- ğŸ“§ **ç§äººå’¨è¯¢**: è”ç³»é¡¹ç›®ç»´æŠ¤è€…\n\n---\n\næ„Ÿè°¢æ‚¨çš„è´¡çŒ®ï¼ğŸ‰"
  },
  {
    "path": "TROUBLESHOOTING.md",
    "content": "# ğŸ” æ•…éšœæ’é™¤æŒ‡å— - AI PPT Assistant\n\næœ¬æ–‡æ¡£åŒ…å«å¸¸è§é—®é¢˜çš„è¯Šæ–­å’Œè§£å†³æ–¹æ¡ˆã€‚\n\n## ğŸ“‹ ç›®å½•\n\n- [éƒ¨ç½²ç›¸å…³é—®é¢˜](#éƒ¨ç½²ç›¸å…³é—®é¢˜)\n- [API Gatewayé—®é¢˜](#api-gatewayé—®é¢˜)\n- [Lambdaå‡½æ•°é—®é¢˜](#lambdaå‡½æ•°é—®é¢˜)\n- [é…ç½®å’Œç¯å¢ƒé—®é¢˜](#é…ç½®å’Œç¯å¢ƒé—®é¢˜)\n- [BedrockæœåŠ¡é—®é¢˜](#bedrockæœåŠ¡é—®é¢˜)\n- [æ€§èƒ½é—®é¢˜](#æ€§èƒ½é—®é¢˜)\n- [è°ƒè¯•å·¥å…·](#è°ƒè¯•å·¥å…·)\n\n## ğŸš€ éƒ¨ç½²ç›¸å…³é—®é¢˜\n\n### Terraforméƒ¨ç½²å¤±è´¥\n\n#### é—®é¢˜: `Error: Cycle in module dependencies`\n\n**ç—‡çŠ¶**:\n```bash\nError: Cycle in module dependencies\nModule [A] depends on [B], which depends on [A]\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. æ£€æŸ¥å¾ªç¯ä¾èµ–\nterraform graph > dependency_graph.dot\ndot -Tpng dependency_graph.dot -o dependency_graph.png\n\n# 2. ä½¿ç”¨é‡æ„åçš„é…ç½®\ncp infrastructure/main_refactored.tf infrastructure/main.tf\n\n# 3. é‡æ–°åˆå§‹åŒ–\nterraform init -reconfigure\nterraform plan\n```\n\n#### é—®é¢˜: `Resource already exists`\n\n**ç—‡çŠ¶**:\n```bash\nError: Resource \"aws_s3_bucket.presentations\" already exists\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. å¯¼å…¥å·²å­˜åœ¨çš„èµ„æº\nterraform import aws_s3_bucket.presentations bucket-name\n\n# 2. æˆ–åˆ é™¤å†²çªèµ„æºå¹¶é‡æ–°åˆ›å»º\naws s3 rm s3://bucket-name --recursive\naws s3api delete-bucket --bucket bucket-name\nterraform apply\n```\n\n### Lambdaéƒ¨ç½²å¤±è´¥\n\n#### é—®é¢˜: `Invalid handler specified`\n\n**ç—‡çŠ¶**:\n```bash\nError: Invalid handler specified: handler.lambda_handler\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. æ£€æŸ¥handleræ–‡ä»¶ç»“æ„\nls -la lambdas/session_manager/\n# åº”è¯¥åŒ…å«: handler.py, requirements.txt\n\n# 2. éªŒè¯handlerå‡½æ•°\ngrep -n \"lambda_handler\" lambdas/session_manager/handler.py\n\n# 3. ä½¿ç”¨è‡ªåŠ¨éƒ¨ç½²è„šæœ¬\npython deploy_lambda_functions.py\n```\n\n#### é—®é¢˜: `Package too large`\n\n**ç—‡çŠ¶**:\n```bash\nError: Unzipped size must be smaller than 262144000 bytes\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. æ£€æŸ¥åŒ…å¤§å°\ncd lambdas/session_manager\ndu -sh .\n\n# 2. æ’é™¤ä¸å¿…è¦æ–‡ä»¶\necho \"__pycache__/\" >> .lambdaignore\necho \"*.pyc\" >> .lambdaignore\necho \"tests/\" >> .lambdaignore\n\n# 3. ä½¿ç”¨Lambdaå±‚\npython deploy_lambda_functions.py --use-layers\n```\n\n## ğŸŒ API Gatewayé—®é¢˜\n\n### CORSé”™è¯¯\n\n#### é—®é¢˜: `Access-Control-Allow-Origin header is missing`\n\n**ç—‡çŠ¶**:\næµè§ˆå™¨æ§åˆ¶å°æ˜¾ç¤ºCORSé”™è¯¯\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. é‡æ–°é…ç½®API Gateway CORS\npython configure_api_gateway.py --enable-cors\n\n# 2. æ‰‹åŠ¨éªŒè¯CORSé…ç½®\ncurl -H \"Origin: http://localhost:3000\" \\\n     -H \"Access-Control-Request-Method: POST\" \\\n     -X OPTIONS \\\n     https://your-api-id.execute-api.us-east-1.amazonaws.com/dev/sessions\n```\n\n### APIè·¯ç”±é”™è¯¯\n\n#### é—®é¢˜: `Missing Authentication Token`\n\n**ç—‡çŠ¶**:\n```json\n{\n  \"message\": \"Missing Authentication Token\"\n}\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. æ£€æŸ¥APIé…ç½®\naws apigateway get-rest-apis\n\n# 2. éªŒè¯è·¯ç”±é…ç½®\npython -c \"\nimport json\nwith open('api_gateway_configuration.json', 'r') as f:\n    config = json.load(f)\n    print('Configured endpoints:')\n    for endpoint in config.get('endpoints', []):\n        print(f'  {endpoint[\\\"method\\\"]} {endpoint[\\\"resource_path\\\"]}')\n\"\n\n# 3. é‡æ–°éƒ¨ç½²API\npython configure_api_gateway.py --redeploy\n```\n\n## ğŸ”§ Lambdaå‡½æ•°é—®é¢˜\n\n### è¿è¡Œæ—¶é”™è¯¯\n\n#### é—®é¢˜: `Module not found`\n\n**ç—‡çŠ¶**:\n```\n[ERROR] Runtime.ImportModuleError: Unable to import module 'handler': No module named 'enhanced_config_manager'\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. éªŒè¯Lambdaå±‚\naws lambda list-layers\n\n# 2. æ£€æŸ¥ä¾èµ–æ‰“åŒ…\ncd lambdas/layers/shared/python\npython -c \"import enhanced_config_manager; print('Import successful')\"\n\n# 3. é‡æ–°éƒ¨ç½²å±‚\npython deploy_lambda_functions.py --update-layers\n```\n\n#### é—®é¢˜: `Task timed out`\n\n**ç—‡çŠ¶**:\n```\n[ERROR] Task timed out after 30.00 seconds\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. å¢åŠ è¶…æ—¶æ—¶é—´\naws lambda update-function-configuration \\\n    --function-name session_manager \\\n    --timeout 60\n\n# 2. æ£€æŸ¥å‡½æ•°æ€§èƒ½\npython -c \"\nimport boto3\nclient = boto3.client('cloudwatch')\nresponse = client.get_metric_statistics(\n    Namespace='AWS/Lambda',\n    MetricName='Duration',\n    Dimensions=[{'Name': 'FunctionName', 'Value': 'session_manager'}],\n    StartTime='2025-09-05T00:00:00Z',\n    EndTime='2025-09-05T23:59:59Z',\n    Period=300,\n    Statistics=['Average', 'Maximum']\n)\nfor point in response['Datapoints']:\n    print(f'{point[\\\"Timestamp\\\"]}: {point[\\\"Average\\\"]:.2f}ms')\n\"\n\n# 3. ä¼˜åŒ–ä»£ç æ€§èƒ½\n# å‚è€ƒperformance_optimization.md\n```\n\n### æƒé™é—®é¢˜\n\n#### é—®é¢˜: `Access denied`\n\n**ç—‡çŠ¶**:\n```\n[ERROR] botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the PutItem operation\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. æ£€æŸ¥IAMè§’è‰²\naws iam get-role --role-name lambda-execution-role\n\n# 2. æ·»åŠ å¿…è¦æƒé™\naws iam attach-role-policy \\\n    --role-name lambda-execution-role \\\n    --policy-arn arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess\n\n# 3. éªŒè¯èµ„æºç­–ç•¥\naws dynamodb describe-table --table-name ai-ppt-assistant-dev-sessions\n```\n\n## âš™ï¸ é…ç½®å’Œç¯å¢ƒé—®é¢˜\n\n### é…ç½®åŠ è½½å¤±è´¥\n\n#### é—®é¢˜: `Configuration key not found`\n\n**ç—‡çŠ¶**:\n```\n[ERROR] KeyError: 'BUCKET_NAME'\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. éªŒè¯é…ç½®æ–‡ä»¶\npython -c \"\nfrom lambdas.layers.shared.python.enhanced_config_manager import EnhancedConfigManager\nconfig = EnhancedConfigManager('dev')\nprint('Available configs:')\nvalidation = config.validate_config()\nfor key, status in validation.items():\n    print(f'  {key}: {\\\"âœ…\\\" if status else \\\"âŒ\\\"}')\n\"\n\n# 2. æ£€æŸ¥ç¯å¢ƒå˜é‡\nenv | grep -E \"(BUCKET_NAME|TABLE_NAME|REGION)\"\n\n# 3. æ›´æ–°é…ç½®\npython -c \"\nimport yaml\nwith open('config/environments/dev.yaml', 'r') as f:\n    config = yaml.safe_load(f)\nprint('Current config:', config)\n\"\n```\n\n### ç¯å¢ƒå˜é‡é—®é¢˜\n\n#### é—®é¢˜: `AWS region not configured`\n\n**ç—‡çŠ¶**:\n```\n[ERROR] You must specify a region\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. è®¾ç½®AWSåŒºåŸŸ\nexport AWS_DEFAULT_REGION=us-east-1\nexport BEDROCK_REGION=us-east-1\n\n# 2. éªŒè¯AWSé…ç½®\naws configure list\n\n# 3. æ›´æ–°Lambdaç¯å¢ƒå˜é‡\naws lambda update-function-configuration \\\n    --function-name session_manager \\\n    --environment Variables='{\\\"BEDROCK_REGION\\\":\\\"us-east-1\\\"}'\n```\n\n## ğŸ¤– BedrockæœåŠ¡é—®é¢˜\n\n### æ¨¡å‹è®¿é—®é—®é¢˜\n\n#### é—®é¢˜: `Model access denied`\n\n**ç—‡çŠ¶**:\n```\n[ERROR] botocore.exceptions.ClientError: An error occurred (AccessDeniedException) when calling the InvokeModel operation: Your account is not authorized to invoke this model.\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. æ£€æŸ¥æ¨¡å‹è®¿é—®æƒé™\naws bedrock list-foundation-models --region us-east-1\n\n# 2. ç”³è¯·æ¨¡å‹è®¿é—®æƒé™\n# ç™»å½•AWSæ§åˆ¶å° â†’ Bedrock â†’ Model access â†’ Request access\n\n# 3. éªŒè¯æƒé™çŠ¶æ€\npython -c \"\nimport boto3\nclient = boto3.client('bedrock', region_name='us-east-1')\ntry:\n    response = client.list_foundation_models()\n    accessible_models = [m['modelId'] for m in response['modelSummaries']]\n    print('Accessible models:')\n    for model in accessible_models:\n        print(f'  {model}')\nexcept Exception as e:\n    print(f'Error: {e}')\n\"\n```\n\n### è°ƒç”¨é™åˆ¶é—®é¢˜\n\n#### é—®é¢˜: `Throttling exception`\n\n**ç—‡çŠ¶**:\n```\n[ERROR] ThrottlingException: Request was throttled due to request rate\n```\n\n**è§£å†³æ–¹æ¡ˆ**:\n```python\n# åœ¨Lambdaå‡½æ•°ä¸­æ·»åŠ é‡è¯•é€»è¾‘\nimport time\nimport boto3\nfrom botocore.exceptions import ClientError\n\ndef invoke_bedrock_with_retry(client, **kwargs):\n    max_retries = 3\n    base_delay = 1\n    \n    for attempt in range(max_retries):\n        try:\n            return client.invoke_model(**kwargs)\n        except ClientError as e:\n            if e.response['Error']['Code'] == 'ThrottlingException':\n                if attempt < max_retries - 1:\n                    delay = base_delay * (2 ** attempt)\n                    time.sleep(delay)\n                    continue\n            raise e\n```\n\n## ğŸ“ˆ æ€§èƒ½é—®é¢˜\n\n### Lambdaå†·å¯åŠ¨\n\n#### é—®é¢˜: å‡½æ•°å†·å¯åŠ¨æ—¶é—´è¿‡é•¿\n\n**è§£å†³æ–¹æ¡ˆ**:\n```python\n# 1. é¢„çƒ­å‡½æ•°\nimport boto3\n\ndef warm_up_functions():\n    \"\"\"é¢„çƒ­æ‰€æœ‰Lambdaå‡½æ•°\"\"\"\n    lambda_client = boto3.client('lambda')\n    functions = [\n        'session_manager',\n        'ppt_generator',\n        'content_enhancer'\n    ]\n    \n    for func in functions:\n        try:\n            lambda_client.invoke(\n                FunctionName=func,\n                InvocationType='RequestResponse',\n                Payload='{\"warmup\": true}'\n            )\n        except Exception as e:\n            print(f\"é¢„çƒ­{func}å¤±è´¥: {e}\")\n```\n\n### DynamoDBæ€§èƒ½\n\n#### é—®é¢˜: è¯»å†™æ“ä½œå»¶è¿Ÿè¿‡é«˜\n\n**è§£å†³æ–¹æ¡ˆ**:\n```bash\n# 1. æ£€æŸ¥DynamoDBæŒ‡æ ‡\naws cloudwatch get-metric-statistics \\\n    --namespace AWS/DynamoDB \\\n    --metric-name SuccessfulRequestLatency \\\n    --dimensions Name=TableName,Value=ai-ppt-assistant-dev-sessions \\\n    --start-time 2025-09-05T00:00:00Z \\\n    --end-time 2025-09-05T23:59:59Z \\\n    --period 300 \\\n    --statistics Average\n\n# 2. ä¼˜åŒ–DynamoDBé…ç½®\naws dynamodb update-table \\\n    --table-name ai-ppt-assistant-dev-sessions \\\n    --provisioned-throughput ReadCapacityUnits=10,WriteCapacityUnits=10\n\n# 3. æ·»åŠ DAXç¼“å­˜(å¯é€‰)\n# å‚è€ƒdeploymentæŒ‡å—ä¸­çš„DAXé…ç½®\n```\n\n## ğŸ”§ è°ƒè¯•å·¥å…·\n\n### æ—¥å¿—æŸ¥çœ‹\n\n```bash\n# æŸ¥çœ‹Lambdaå‡½æ•°æ—¥å¿—\naws logs describe-log-groups --log-group-name-prefix \"/aws/lambda/\"\n\n# å®æ—¶æŸ¥çœ‹æ—¥å¿—\naws logs tail /aws/lambda/session_manager --follow\n\n# è¿‡æ»¤é”™è¯¯æ—¥å¿—\naws logs filter-log-events \\\n    --log-group-name \"/aws/lambda/session_manager\" \\\n    --filter-pattern \"ERROR\"\n```\n\n### æ€§èƒ½ç›‘æ§\n\n```python\n# CloudWatchè‡ªå®šä¹‰æŒ‡æ ‡\nimport boto3\nfrom datetime import datetime\n\ndef put_custom_metric(metric_name, value, unit='Count'):\n    \"\"\"å‘é€è‡ªå®šä¹‰æŒ‡æ ‡åˆ°CloudWatch\"\"\"\n    cloudwatch = boto3.client('cloudwatch')\n    \n    cloudwatch.put_metric_data(\n        Namespace='AI-PPT-Assistant',\n        MetricData=[\n            {\n                'MetricName': metric_name,\n                'Value': value,\n                'Unit': unit,\n                'Timestamp': datetime.utcnow()\n            }\n        ]\n    )\n\n# ä½¿ç”¨ç¤ºä¾‹\nput_custom_metric('SessionCreated', 1)\nput_custom_metric('ResponseTime', 150, 'Milliseconds')\n```\n\n### æœ¬åœ°æµ‹è¯•\n\n```bash\n# 1. è®¾ç½®æœ¬åœ°ç¯å¢ƒ\nexport AWS_PROFILE=your-profile\nexport ENVIRONMENT=dev\n\n# 2. æœ¬åœ°æµ‹è¯•Lambdaå‡½æ•°\ncd lambdas/session_manager\npython -c \"\nimport json\nfrom handler import lambda_handler\n\nevent = {\n    'httpMethod': 'POST',\n    'body': json.dumps({\n        'user_id': 'test_user',\n        'project_name': 'test_project'\n    })\n}\n\nresult = lambda_handler(event, {})\nprint(json.dumps(result, indent=2))\n\"\n\n# 3. APIæµ‹è¯•\ncurl -X POST https://your-api-id.execute-api.us-east-1.amazonaws.com/dev/sessions \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"user_id\": \"test_user\", \"project_name\": \"test_project\"}'\n```\n\n## ğŸš¨ ç´§æ€¥é—®é¢˜å¤„ç†\n\n### æœåŠ¡å®Œå…¨æ— å“åº”\n\n```bash\n# 1. å¿«é€Ÿå¥åº·æ£€æŸ¥\npython -c \"\nimport boto3\nimport json\n\n# æ£€æŸ¥å…³é”®æœåŠ¡çŠ¶æ€\nservices = {\n    'lambda': boto3.client('lambda'),\n    'apigateway': boto3.client('apigateway'),\n    'dynamodb': boto3.client('dynamodb')\n}\n\nfor service, client in services.items():\n    try:\n        if service == 'lambda':\n            response = client.list_functions(MaxItems=1)\n        elif service == 'apigateway':\n            response = client.get_rest_apis(limit=1)\n        elif service == 'dynamodb':\n            response = client.list_tables(Limit=1)\n        print(f'âœ… {service}: æ­£å¸¸')\n    except Exception as e:\n        print(f'âŒ {service}: {e}')\n\"\n\n# 2. å›æ»šåˆ°ç¨³å®šç‰ˆæœ¬\ngit checkout main\npython deploy_lambda_functions.py --force-update\n\n# 3. å¯ç”¨è¯¦ç»†æ—¥å¿—\naws logs put-retention-policy \\\n    --log-group-name \"/aws/lambda/session_manager\" \\\n    --retention-in-days 7\n```\n\n## ğŸ“ è·å–å¸®åŠ©\n\nå¦‚æœä¸Šè¿°è§£å†³æ–¹æ¡ˆæ— æ³•è§£å†³æ‚¨çš„é—®é¢˜ï¼š\n\n1. **æ£€æŸ¥æ—¥å¿—**: è¯¦ç»†æŸ¥çœ‹CloudWatchæ—¥å¿—\n2. **æŸ¥çœ‹ç›‘æ§**: æ£€æŸ¥CloudWatchæŒ‡æ ‡å’ŒæŠ¥è­¦\n3. **æµ‹è¯•éš”ç¦»**: é€ä¸ªç»„ä»¶æµ‹è¯•å®šä½é—®é¢˜\n4. **è”ç³»æ”¯æŒ**: åˆ›å»ºGitHub Issueå¹¶é™„ä¸Šè¯¦ç»†æ—¥å¿—\n\n---\n\nğŸ“… **æœ€åæ›´æ–°**: 2025-09-05 | âœ… **æ–‡æ¡£çŠ¶æ€**: ç”Ÿäº§å°±ç»ª"
  },
  {
    "path": "api/openapi.yaml",
    "content": "openapi: 3.0.3\ninfo:\n  title: AI PPT Assistant API\n  description: RESTful API for AI-powered presentation generation using Amazon Bedrock Agents\n  version: 1.0.0\n  contact:\n    name: API Support\n    email: support@example.com\n  license:\n    name: MIT\n    url: https://opensource.org/licenses/MIT\n\nservers:\n  - url: https://api.example.com/v1\n    description: Production server\n  - url: https://staging-api.example.com/v1\n    description: Staging server\n  - url: http://localhost:3000/v1\n    description: Development server\n\ntags:\n  - name: presentations\n    description: Presentation creation and management\n  - name: tasks\n    description: Async task management\n  - name: templates\n    description: Template management\n  - name: health\n    description: Health and status endpoints\n\npaths:\n  /presentations:\n    post:\n      tags:\n        - presentations\n      summary: Create a new presentation\n      description: Initiates an asynchronous presentation creation task\n      operationId: createPresentation\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/CreatePresentationRequest'\n            examples:\n              basic:\n                value:\n                  title: \"Q4 2024 Business Review\"\n                  topic: \"Quarterly business performance and strategic outlook\"\n                  language: \"en\"\n                  slide_count: 15\n                  style: \"corporate\"\n                  template: \"executive_summary\"\n              detailed:\n                value:\n                  title: \"AI Technology Trends 2025\"\n                  topic: \"Emerging AI technologies and their business impact\"\n                  language: \"en\"\n                  slide_count: 20\n                  style: \"modern\"\n                  template: \"technology_showcase\"\n                  audience_type: \"technical\"\n                  tone: \"informative\"\n                  include_speaker_notes: true\n                  color_scheme: \"blue_gradient\"\n      responses:\n        '202':\n          description: Presentation creation task accepted\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/TaskResponse'\n        '400':\n          $ref: '#/components/responses/BadRequest'\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '429':\n          $ref: '#/components/responses/TooManyRequests'\n        '500':\n          $ref: '#/components/responses/InternalServerError'\n\n    get:\n      tags:\n        - presentations\n      summary: List presentations\n      description: Retrieves a list of created presentations\n      operationId: listPresentations\n      parameters:\n        - $ref: '#/components/parameters/PageSize'\n        - $ref: '#/components/parameters/PageToken'\n        - $ref: '#/components/parameters/SortBy'\n        - $ref: '#/components/parameters/SortOrder'\n        - name: status\n          in: query\n          schema:\n            type: string\n            enum: [completed, processing, failed]\n          description: Filter by presentation status\n        - name: created_after\n          in: query\n          schema:\n            type: string\n            format: date-time\n          description: Filter presentations created after this date\n      responses:\n        '200':\n          description: List of presentations\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/PresentationListResponse'\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '500':\n          $ref: '#/components/responses/InternalServerError'\n\n  /presentations/{presentationId}:\n    parameters:\n      - $ref: '#/components/parameters/PresentationId'\n    \n    get:\n      tags:\n        - presentations\n      summary: Get presentation details\n      description: Retrieves details of a specific presentation\n      operationId: getPresentation\n      responses:\n        '200':\n          description: Presentation details\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/PresentationResponse'\n        '404':\n          $ref: '#/components/responses/NotFound'\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '500':\n          $ref: '#/components/responses/InternalServerError'\n\n    put:\n      tags:\n        - presentations\n      summary: Update presentation\n      description: Updates an existing presentation\n      operationId: updatePresentation\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/UpdatePresentationRequest'\n      responses:\n        '200':\n          description: Presentation updated successfully\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/PresentationResponse'\n        '404':\n          $ref: '#/components/responses/NotFound'\n        '400':\n          $ref: '#/components/responses/BadRequest'\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '500':\n          $ref: '#/components/responses/InternalServerError'\n\n    delete:\n      tags:\n        - presentations\n      summary: Delete presentation\n      description: Deletes a presentation and its associated files\n      operationId: deletePresentation\n      responses:\n        '204':\n          description: Presentation deleted successfully\n        '404':\n          $ref: '#/components/responses/NotFound'\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '500':\n          $ref: '#/components/responses/InternalServerError'\n\n  /presentations/{presentationId}/download:\n    parameters:\n      - $ref: '#/components/parameters/PresentationId'\n    \n    get:\n      tags:\n        - presentations\n      summary: Download presentation file\n      description: Downloads the presentation file in specified format\n      operationId: downloadPresentation\n      parameters:\n        - name: format\n          in: query\n          required: false\n          schema:\n            type: string\n            enum: [pptx, pdf, html, images]\n            default: pptx\n          description: Output format for the presentation\n      responses:\n        '200':\n          description: Presentation file\n          content:\n            application/vnd.openxmlformats-officedocument.presentationml.presentation:\n              schema:\n                type: string\n                format: binary\n            application/pdf:\n              schema:\n                type: string\n                format: binary\n            text/html:\n              schema:\n                type: string\n            application/zip:\n              schema:\n                type: string\n                format: binary\n        '404':\n          $ref: '#/components/responses/NotFound'\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '500':\n          $ref: '#/components/responses/InternalServerError'\n\n  /presentations/{presentationId}/slides:\n    parameters:\n      - $ref: '#/components/parameters/PresentationId'\n    \n    post:\n      tags:\n        - presentations\n      summary: Add slide to presentation\n      description: Adds a new slide to an existing presentation\n      operationId: addSlide\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/AddSlideRequest'\n      responses:\n        '201':\n          description: Slide added successfully\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/SlideResponse'\n        '404':\n          $ref: '#/components/responses/NotFound'\n        '400':\n          $ref: '#/components/responses/BadRequest'\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '500':\n          $ref: '#/components/responses/InternalServerError'\n\n  /tasks/{taskId}:\n    parameters:\n      - $ref: '#/components/parameters/TaskId'\n    \n    get:\n      tags:\n        - tasks\n      summary: Get task status\n      description: Retrieves the status of an asynchronous task\n      operationId: getTaskStatus\n      responses:\n        '200':\n          description: Task status information\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/TaskStatusResponse'\n        '404':\n          $ref: '#/components/responses/NotFound'\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '500':\n          $ref: '#/components/responses/InternalServerError'\n\n    delete:\n      tags:\n        - tasks\n      summary: Cancel task\n      description: Cancels an ongoing task\n      operationId: cancelTask\n      responses:\n        '204':\n          description: Task cancelled successfully\n        '404':\n          $ref: '#/components/responses/NotFound'\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '500':\n          $ref: '#/components/responses/InternalServerError'\n\n  /templates:\n    get:\n      tags:\n        - templates\n      summary: List available templates\n      description: Retrieves a list of available presentation templates\n      operationId: listTemplates\n      parameters:\n        - name: category\n          in: query\n          schema:\n            type: string\n            enum: [business, education, creative, technical]\n          description: Filter templates by category\n      responses:\n        '200':\n          description: List of templates\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/TemplateListResponse'\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '500':\n          $ref: '#/components/responses/InternalServerError'\n\n  /templates/{templateId}:\n    parameters:\n      - $ref: '#/components/parameters/TemplateId'\n    \n    get:\n      tags:\n        - templates\n      summary: Get template details\n      description: Retrieves details of a specific template\n      operationId: getTemplate\n      responses:\n        '200':\n          description: Template details\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/TemplateResponse'\n        '404':\n          $ref: '#/components/responses/NotFound'\n        '401':\n          $ref: '#/components/responses/Unauthorized'\n        '500':\n          $ref: '#/components/responses/InternalServerError'\n\n  /health:\n    get:\n      tags:\n        - health\n      summary: Health check\n      description: Returns the health status of the API\n      operationId: healthCheck\n      security: []\n      responses:\n        '200':\n          description: Service is healthy\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/HealthResponse'\n        '503':\n          description: Service is unhealthy\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/HealthResponse'\n\n  /health/ready:\n    get:\n      tags:\n        - health\n      summary: Readiness check\n      description: Checks if the service is ready to accept requests\n      operationId: readinessCheck\n      security: []\n      responses:\n        '200':\n          description: Service is ready\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ReadinessResponse'\n        '503':\n          description: Service is not ready\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ReadinessResponse'\n\ncomponents:\n  parameters:\n    PresentationId:\n      name: presentationId\n      in: path\n      required: true\n      description: Unique identifier of the presentation\n      schema:\n        type: string\n        format: uuid\n\n    TaskId:\n      name: taskId\n      in: path\n      required: true\n      description: Unique identifier of the task\n      schema:\n        type: string\n        format: uuid\n\n    TemplateId:\n      name: templateId\n      in: path\n      required: true\n      description: Unique identifier of the template\n      schema:\n        type: string\n\n    PageSize:\n      name: page_size\n      in: query\n      description: Number of items per page\n      schema:\n        type: integer\n        minimum: 1\n        maximum: 100\n        default: 20\n\n    PageToken:\n      name: page_token\n      in: query\n      description: Token for pagination\n      schema:\n        type: string\n\n    SortBy:\n      name: sort_by\n      in: query\n      description: Field to sort by\n      schema:\n        type: string\n        enum: [created_at, updated_at, title]\n        default: created_at\n\n    SortOrder:\n      name: sort_order\n      in: query\n      description: Sort order\n      schema:\n        type: string\n        enum: [asc, desc]\n        default: desc\n\n  schemas:\n    CreatePresentationRequest:\n      type: object\n      required:\n        - title\n        - topic\n      properties:\n        title:\n          type: string\n          description: Presentation title\n          minLength: 1\n          maxLength: 200\n        topic:\n          type: string\n          description: Main topic or content description\n          minLength: 10\n          maxLength: 2000\n        language:\n          type: string\n          description: Language code\n          enum: [en, ja, zh, es, fr, de, pt, ko]\n          default: en\n        slide_count:\n          type: integer\n          description: Number of slides to generate\n          minimum: 5\n          maximum: 50\n          default: 10\n        style:\n          type: string\n          description: Presentation style\n          enum: [corporate, creative, minimal, academic, modern]\n          default: corporate\n        template:\n          type: string\n          description: Template identifier\n        audience_type:\n          type: string\n          description: Target audience type\n          enum: [executive, technical, general, academic, sales]\n        tone:\n          type: string\n          description: Presentation tone\n          enum: [formal, informal, persuasive, informative, inspiring]\n        include_speaker_notes:\n          type: boolean\n          description: Whether to generate speaker notes\n          default: true\n        color_scheme:\n          type: string\n          description: Color scheme preference\n        custom_requirements:\n          type: string\n          description: Additional custom requirements\n          maxLength: 1000\n        metadata:\n          type: object\n          description: Additional metadata\n          additionalProperties: true\n\n    UpdatePresentationRequest:\n      type: object\n      properties:\n        title:\n          type: string\n          description: Updated presentation title\n        metadata:\n          type: object\n          description: Updated metadata\n          additionalProperties: true\n\n    AddSlideRequest:\n      type: object\n      required:\n        - content\n        - position\n      properties:\n        content:\n          type: string\n          description: Slide content\n        position:\n          type: integer\n          description: Position to insert the slide\n        layout:\n          type: string\n          description: Slide layout type\n          enum: [title, content, two_column, image, comparison, blank]\n        notes:\n          type: string\n          description: Speaker notes for the slide\n\n    TaskResponse:\n      type: object\n      properties:\n        task_id:\n          type: string\n          format: uuid\n          description: Unique task identifier\n        status:\n          type: string\n          enum: [pending, processing, completed, failed, cancelled]\n          description: Current task status\n        created_at:\n          type: string\n          format: date-time\n          description: Task creation timestamp\n        estimated_completion:\n          type: string\n          format: date-time\n          description: Estimated completion time\n        _links:\n          type: object\n          properties:\n            self:\n              type: string\n              description: Link to task status endpoint\n            result:\n              type: string\n              description: Link to result when completed\n\n    TaskStatusResponse:\n      type: object\n      properties:\n        task_id:\n          type: string\n          format: uuid\n        status:\n          type: string\n          enum: [pending, processing, completed, failed, cancelled]\n        progress:\n          type: integer\n          minimum: 0\n          maximum: 100\n          description: Progress percentage\n        message:\n          type: string\n          description: Current status message\n        created_at:\n          type: string\n          format: date-time\n        updated_at:\n          type: string\n          format: date-time\n        completed_at:\n          type: string\n          format: date-time\n        result:\n          type: object\n          description: Task result when completed\n          properties:\n            presentation_id:\n              type: string\n              format: uuid\n            download_url:\n              type: string\n              format: uri\n        error:\n          type: object\n          description: Error information if failed\n          properties:\n            code:\n              type: string\n            message:\n              type: string\n            details:\n              type: object\n\n    PresentationResponse:\n      type: object\n      properties:\n        id:\n          type: string\n          format: uuid\n        title:\n          type: string\n        topic:\n          type: string\n        language:\n          type: string\n        slide_count:\n          type: integer\n        style:\n          type: string\n        template:\n          type: string\n        status:\n          type: string\n          enum: [draft, processing, completed, failed]\n        created_at:\n          type: string\n          format: date-time\n        updated_at:\n          type: string\n          format: date-time\n        metadata:\n          type: object\n        download_urls:\n          type: object\n          properties:\n            pptx:\n              type: string\n              format: uri\n            pdf:\n              type: string\n              format: uri\n            html:\n              type: string\n              format: uri\n        _links:\n          type: object\n          properties:\n            self:\n              type: string\n            download:\n              type: string\n            slides:\n              type: string\n\n    PresentationListResponse:\n      type: object\n      properties:\n        items:\n          type: array\n          items:\n            $ref: '#/components/schemas/PresentationSummary'\n        pagination:\n          $ref: '#/components/schemas/PaginationInfo'\n\n    PresentationSummary:\n      type: object\n      properties:\n        id:\n          type: string\n          format: uuid\n        title:\n          type: string\n        slide_count:\n          type: integer\n        status:\n          type: string\n        created_at:\n          type: string\n          format: date-time\n        _links:\n          type: object\n          properties:\n            self:\n              type: string\n\n    SlideResponse:\n      type: object\n      properties:\n        id:\n          type: string\n          format: uuid\n        position:\n          type: integer\n        content:\n          type: string\n        layout:\n          type: string\n        notes:\n          type: string\n        created_at:\n          type: string\n          format: date-time\n\n    TemplateResponse:\n      type: object\n      properties:\n        id:\n          type: string\n        name:\n          type: string\n        description:\n          type: string\n        category:\n          type: string\n        preview_url:\n          type: string\n          format: uri\n        supported_languages:\n          type: array\n          items:\n            type: string\n\n    TemplateListResponse:\n      type: object\n      properties:\n        items:\n          type: array\n          items:\n            $ref: '#/components/schemas/TemplateSummary'\n        total:\n          type: integer\n\n    TemplateSummary:\n      type: object\n      properties:\n        id:\n          type: string\n        name:\n          type: string\n        category:\n          type: string\n        preview_url:\n          type: string\n          format: uri\n\n    HealthResponse:\n      type: object\n      properties:\n        status:\n          type: string\n          enum: [healthy, degraded, unhealthy]\n        timestamp:\n          type: string\n          format: date-time\n        version:\n          type: string\n        checks:\n          type: object\n          additionalProperties:\n            type: object\n            properties:\n              status:\n                type: string\n              message:\n                type: string\n\n    ReadinessResponse:\n      type: object\n      properties:\n        ready:\n          type: boolean\n        timestamp:\n          type: string\n          format: date-time\n        dependencies:\n          type: object\n          additionalProperties:\n            type: boolean\n\n    PaginationInfo:\n      type: object\n      properties:\n        total:\n          type: integer\n        page_size:\n          type: integer\n        next_token:\n          type: string\n        previous_token:\n          type: string\n\n    ErrorResponse:\n      type: object\n      required:\n        - error\n      properties:\n        error:\n          type: object\n          required:\n            - code\n            - message\n          properties:\n            code:\n              type: string\n            message:\n              type: string\n            details:\n              type: object\n            request_id:\n              type: string\n            timestamp:\n              type: string\n              format: date-time\n\n  responses:\n    BadRequest:\n      description: Bad request\n      content:\n        application/json:\n          schema:\n            $ref: '#/components/schemas/ErrorResponse'\n\n    Unauthorized:\n      description: Unauthorized\n      content:\n        application/json:\n          schema:\n            $ref: '#/components/schemas/ErrorResponse'\n\n    NotFound:\n      description: Resource not found\n      content:\n        application/json:\n          schema:\n            $ref: '#/components/schemas/ErrorResponse'\n\n    TooManyRequests:\n      description: Too many requests\n      content:\n        application/json:\n          schema:\n            $ref: '#/components/schemas/ErrorResponse'\n\n    InternalServerError:\n      description: Internal server error\n      content:\n        application/json:\n          schema:\n            $ref: '#/components/schemas/ErrorResponse'\n\n  securitySchemes:\n    ApiKeyAuth:\n      type: apiKey\n      in: header\n      name: X-API-Key\n      description: API key for authentication\n\n    BearerAuth:\n      type: http\n      scheme: bearer\n      bearerFormat: JWT\n      description: JWT token for authentication\n\n    OAuth2:\n      type: oauth2\n      flows:\n        authorizationCode:\n          authorizationUrl: https://auth.example.com/oauth/authorize\n          tokenUrl: https://auth.example.com/oauth/token\n          scopes:\n            read: Read access to presentations\n            write: Write access to presentations\n            admin: Administrative access\n\nsecurity:\n  - ApiKeyAuth: []\n  - BearerAuth: []\n  - OAuth2: [read, write]"
  },
  {
    "path": "frontend/package.json",
    "content": "{\n  \"name\": \"frontend\",\n  \"private\": true,\n  \"version\": \"0.0.0\",\n  \"type\": \"module\",\n  \"scripts\": {\n    \"dev\": \"vite\",\n    \"build\": \"tsc -b && vite build\",\n    \"build:prod\": \"npm run clean && npm run type-check && npm run lint && npm run build\",\n    \"build:analyze\": \"vite build --mode analyze\",\n    \"clean\": \"rm -rf dist\",\n    \"lint\": \"eslint .\",\n    \"lint:fix\": \"eslint . --fix\",\n    \"format\": \"prettier --write \\\"src/**/*.{js,jsx,ts,tsx,json,css,md}\\\"\",\n    \"preview\": \"vite preview\",\n    \"serve\": \"vite preview --port 5000\",\n    \"type-check\": \"tsc --noEmit\",\n    \"test\": \"jest\",\n    \"test:watch\": \"jest --watch\",\n    \"test:coverage\": \"jest --coverage\",\n    \"test:ci\": \"jest --ci --coverage --watchAll=false\",\n    \"test:e2e\": \"playwright test\",\n    \"test:e2e:ui\": \"playwright test --ui\",\n    \"test:e2e:headed\": \"playwright test --headed\",\n    \"test:e2e:debug\": \"playwright test --debug\",\n    \"test:e2e:report\": \"playwright show-report\",\n    \"test:e2e:install\": \"playwright install\",\n    \"test:e2e:chromium\": \"playwright test --project=chromium\",\n    \"test:e2e:firefox\": \"playwright test --project=firefox\",\n    \"test:e2e:webkit\": \"playwright test --project=webkit\",\n    \"test:e2e:mobile\": \"playwright test --project='Mobile Chrome' --project='Mobile Safari'\",\n    \"test:all\": \"npm run test && npm run test:e2e\",\n    \"deploy:s3\": \"npm run build:prod && aws s3 sync dist/ s3://your-bucket-name --delete\",\n    \"deploy:cf\": \"npm run deploy:s3 && aws cloudfront create-invalidation --distribution-id YOUR_DIST_ID --paths '/*'\",\n    \"deploy:vercel\": \"npm run build:prod && vercel\",\n    \"deploy:netlify\": \"npm run build:prod && netlify deploy --prod\",\n    \"docker:build\": \"docker build -t ppt-assistant-frontend .\",\n    \"docker:run\": \"docker run -p 80:80 ppt-assistant-frontend\",\n    \"analyze\": \"npm run build:analyze && npx source-map-explorer 'dist/**/*.js'\",\n    \"preinstall\": \"npx only-allow npm\"\n  },\n  \"dependencies\": {\n    \"@dnd-kit/core\": \"^6.3.1\",\n    \"@dnd-kit/sortable\": \"^10.0.0\",\n    \"@dnd-kit/utilities\": \"^3.2.2\",\n    \"@heroicons/react\": \"^2.2.0\",\n    \"@tailwindcss/postcss\": \"^4.1.13\",\n    \"@types/uuid\": \"^10.0.0\",\n    \"axios\": \"^1.11.0\",\n    \"immer\": \"^10.1.3\",\n    \"localforage\": \"^1.10.0\",\n    \"lucide-react\": \"^0.542.0\",\n    \"react\": \"^19.1.1\",\n    \"react-dom\": \"^19.1.1\",\n    \"react-router-dom\": \"^7.8.2\",\n    \"uuid\": \"^11.1.0\",\n    \"zustand\": \"^5.0.8\"\n  },\n  \"devDependencies\": {\n    \"@eslint/js\": \"^9.33.0\",\n    \"@playwright/test\": \"^1.55.0\",\n    \"@testing-library/jest-dom\": \"^6.8.0\",\n    \"@testing-library/react\": \"^16.3.0\",\n    \"@testing-library/user-event\": \"^14.6.1\",\n    \"@types/jest\": \"^30.0.0\",\n    \"@types/react\": \"^19.1.10\",\n    \"@types/react-dom\": \"^19.1.7\",\n    \"@vitejs/plugin-react\": \"^5.0.0\",\n    \"autoprefixer\": \"^10.4.21\",\n    \"eslint\": \"^9.33.0\",\n    \"eslint-plugin-react-hooks\": \"^5.2.0\",\n    \"eslint-plugin-react-refresh\": \"^0.4.20\",\n    \"globals\": \"^16.3.0\",\n    \"jest\": \"^30.1.3\",\n    \"jest-environment-jsdom\": \"^30.1.2\",\n    \"postcss\": \"^8.5.6\",\n    \"tailwindcss\": \"^4.1.13\",\n    \"ts-jest\": \"^29.4.1\",\n    \"typescript\": \"~5.8.3\",\n    \"typescript-eslint\": \"^8.39.1\",\n    \"vite\": \"^7.1.2\"\n  }\n}\n"
  },
  {
    "path": "infrastructure/variables.tf",
    "content": "# AI PPT Assistant Infrastructure Variables\n# This file defines all input variables for the Terraform configuration\n\n# General Configuration\nvariable \"project_name\" {\n  description = \"Name of the project\"\n  type        = string\n  default     = \"ai-ppt-assistant\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name (dev, staging, prod)\"\n  type        = string\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be one of: dev, staging, prod\"\n  }\n}\n\nvariable \"aws_region\" {\n  description = \"AWS region for resources\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"owner\" {\n  description = \"Owner of the resources\"\n  type        = string\n}\n\nvariable \"cost_center\" {\n  description = \"Cost center for billing purposes\"\n  type        = string\n}\n\n# State Management (for remote backend)\nvariable \"state_bucket\" {\n  description = \"S3 bucket for Terraform state storage\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"state_lock_table\" {\n  description = \"DynamoDB table for state locking\"\n  type        = string\n  default     = \"\"\n}\n\n# S3 Configuration\nvariable \"s3_lifecycle_rules\" {\n  description = \"S3 lifecycle rules configuration\"\n  type = list(object({\n    id                 = string\n    status             = string\n    days_to_ia         = number\n    days_to_glacier    = number\n    days_to_expiration = number\n  }))\n  default = [\n    {\n      id                 = \"presentation-lifecycle\"\n      status             = \"Enabled\"\n      days_to_ia         = 30\n      days_to_glacier    = 90\n      days_to_expiration = 365\n    }\n  ]\n}\n\nvariable \"s3_cors_configuration\" {\n  description = \"CORS configuration for S3 bucket\"\n  type = list(object({\n    allowed_headers = list(string)\n    allowed_methods = list(string)\n    allowed_origins = list(string)\n    expose_headers  = list(string)\n    max_age_seconds = number\n  }))\n  default = [\n    {\n      allowed_headers = [\"*\"]\n      allowed_methods = [\"GET\", \"HEAD\", \"PUT\", \"POST\", \"DELETE\"]\n      allowed_origins = [\"*\"] # Update with specific domains in production\n      expose_headers  = [\"ETag\", \"x-amz-server-side-encryption\"]\n      max_age_seconds = 3000\n    }\n  ]\n}\n\n# DynamoDB Configuration\nvariable \"dynamodb_billing_mode\" {\n  description = \"DynamoDB billing mode (PAY_PER_REQUEST or PROVISIONED)\"\n  type        = string\n  default     = \"PAY_PER_REQUEST\"\n  validation {\n    condition     = contains([\"PAY_PER_REQUEST\", \"PROVISIONED\"], var.dynamodb_billing_mode)\n    error_message = \"Billing mode must be PAY_PER_REQUEST or PROVISIONED\"\n  }\n}\n\nvariable \"dynamodb_read_capacity\" {\n  description = \"Read capacity units (only used if billing mode is PROVISIONED)\"\n  type        = number\n  default     = 5\n}\n\nvariable \"dynamodb_write_capacity\" {\n  description = \"Write capacity units (only used if billing mode is PROVISIONED)\"\n  type        = number\n  default     = 5\n}\n\n# API Gateway Configuration\nvariable \"stage_name\" {\n  description = \"API Gateway stage name\"\n  type        = string\n  default     = \"v1\"\n}\n\nvariable \"api_throttle_rate_limit\" {\n  description = \"API Gateway throttle rate limit (requests per second)\"\n  type        = number\n  default     = 100\n}\n\nvariable \"api_throttle_burst_limit\" {\n  description = \"API Gateway throttle burst limit\"\n  type        = number\n  default     = 200\n}\n\nvariable \"api_quota_limit\" {\n  description = \"API Gateway quota limit (requests per period)\"\n  type        = number\n  default     = 10000\n}\n\nvariable \"api_quota_period\" {\n  description = \"API Gateway quota period (DAY, WEEK, or MONTH)\"\n  type        = string\n  default     = \"DAY\"\n}\n\nvariable \"api_keys\" {\n  description = \"List of API keys to create\"\n  type = list(object({\n    name        = string\n    description = string\n  }))\n  default = []\n}\n\n# Lambda Configuration\nvariable \"lambda_architecture\" {\n  description = \"Lambda function architecture (x86_64 or arm64)\"\n  type        = string\n  default     = \"arm64\" # Graviton2 for cost optimization\n  validation {\n    condition     = contains([\"x86_64\", \"arm64\"], var.lambda_architecture)\n    error_message = \"Architecture must be x86_64 or arm64\"\n  }\n}\n\nvariable \"lambda_functions\" {\n  description = \"Map of Lambda function configurations\"\n  type = map(object({\n    handler             = string\n    memory_size         = number\n    timeout             = number\n    reserved_concurrent = number\n    description         = string\n  }))\n  default = {\n    create_outline = {\n      handler             = \"create_outline.handler\"\n      memory_size         = 1024\n      timeout             = 30\n      reserved_concurrent = 2\n      description         = \"Generate presentation outline from topic\"\n    }\n    generate_content = {\n      handler             = \"generate_content.handler\"\n      memory_size         = 1024\n      timeout             = 60\n      reserved_concurrent = 5\n      description         = \"Generate detailed slide content\"\n    }\n    generate_image = {\n      handler             = \"generate_image.handler\"\n      memory_size         = 2048\n      timeout             = 120\n      reserved_concurrent = 3\n      description         = \"Generate images using Amazon Nova\"\n    }\n    find_image = {\n      handler             = \"find_image.handler\"\n      memory_size         = 512\n      timeout             = 30\n      reserved_concurrent = 2\n      description         = \"Find relevant images from library\"\n    }\n    generate_speaker_notes = {\n      handler             = \"generate_speaker_notes.handler\"\n      memory_size         = 1024\n      timeout             = 30\n      reserved_concurrent = 2\n      description         = \"Generate speaker notes for slides\"\n    }\n    compile_pptx = {\n      handler             = \"compile_pptx.handler\"\n      memory_size         = 2048\n      timeout             = 300\n      reserved_concurrent = 2\n      description         = \"Compile final PowerPoint file\"\n    }\n    generate_presentation = {\n      handler             = \"generate_presentation.handler\"\n      memory_size         = 512\n      timeout             = 30\n      reserved_concurrent = 5\n      description         = \"API endpoint for presentation generation\"\n    }\n    presentation_status = {\n      handler             = \"presentation_status.handler\"\n      memory_size         = 256\n      timeout             = 10\n      reserved_concurrent = 5\n      description         = \"API endpoint for status checking\"\n    }\n    presentation_download = {\n      handler             = \"presentation_download.handler\"\n      memory_size         = 256\n      timeout             = 10\n      reserved_concurrent = 5\n      description         = \"API endpoint for file download\"\n    }\n    modify_slide = {\n      handler             = \"modify_slide.handler\"\n      memory_size         = 1024\n      timeout             = 60\n      reserved_concurrent = 2\n      description         = \"API endpoint for slide modification\"\n    }\n  }\n}\n\n# Bedrock Configuration\nvariable \"bedrock_region\" {\n  description = \"AWS region for Bedrock services\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"bedrock_model_id\" {\n  description = \"Bedrock model ID\"\n  type        = string\n  default     = \"anthropic.claude-4-0\"\n}\n\nvariable \"bedrock_model_version\" {\n  description = \"Bedrock model version\"\n  type        = string\n  default     = \"1.0\"\n}\n\nvariable \"bedrock_agents\" {\n  description = \"Map of Bedrock agent configurations\"\n  type = map(object({\n    name         = string\n    description  = string\n    instructions = string\n    action_groups = list(object({\n      name        = string\n      description = string\n      actions     = list(string)\n    }))\n  }))\n  default = {\n    orchestrator = {\n      name          = \"orchestrator-agent\"\n      description   = \"Main workflow orchestration agent\"\n      instructions  = \"Coordinate the overall presentation generation workflow\"\n      action_groups = []\n    }\n    content = {\n      name         = \"content-agent\"\n      description  = \"Content generation agent\"\n      instructions = \"Generate text content for presentations\"\n      action_groups = [\n        {\n          name        = \"content-generation\"\n          description = \"Actions for content generation\"\n          actions     = [\"create_outline\", \"generate_content\", \"generate_speaker_notes\"]\n        }\n      ]\n    }\n    visual = {\n      name         = \"visual-agent\"\n      description  = \"Visual content generation agent\"\n      instructions = \"Generate and find images for presentations\"\n      action_groups = [\n        {\n          name        = \"visual-generation\"\n          description = \"Actions for visual content\"\n          actions     = [\"generate_image\", \"find_image\"]\n        }\n      ]\n    }\n    compiler = {\n      name         = \"compiler-agent\"\n      description  = \"File compilation agent\"\n      instructions = \"Compile final presentation files\"\n      action_groups = [\n        {\n          name        = \"file-compilation\"\n          description = \"Actions for file compilation\"\n          actions     = [\"compile_pptx\"]\n        }\n      ]\n    }\n  }\n}\n\n# Logging Configuration\nvariable \"log_level\" {\n  description = \"Log level for Lambda functions\"\n  type        = string\n  default     = \"INFO\"\n  validation {\n    condition     = contains([\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"], var.log_level)\n    error_message = \"Log level must be one of: DEBUG, INFO, WARNING, ERROR, CRITICAL\"\n  }\n}\n\nvariable \"log_retention_days\" {\n  description = \"CloudWatch log retention in days\"\n  type        = number\n  default     = 30\n}\n\n# Monitoring and Alerting\nvariable \"enable_monitoring\" {\n  description = \"Enable CloudWatch monitoring and alarms\"\n  type        = bool\n  default     = true\n}\n\nvariable \"alert_email\" {\n  description = \"Email address for CloudWatch alarms\"\n  type        = string\n  default     = \"\"\n}\n\n# Cost Optimization\nvariable \"enable_cost_optimization\" {\n  description = \"Enable cost optimization features\"\n  type        = bool\n  default     = true\n}\n\n# VPC Configuration\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for the VPC\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"availability_zones\" {\n  description = \"List of availability zones to use\"\n  type        = list(string)\n  default     = [\"us-west-2a\", \"us-west-2b\"]\n}\n\nvariable \"enable_vpc_endpoints\" {\n  description = \"Enable VPC endpoints for AWS services\"\n  type        = bool\n  default     = true\n}\n\nvariable \"enable_sqs_endpoint\" {\n  description = \"Enable SQS VPC endpoint\"\n  type        = bool\n  default     = false\n}\n\nvariable \"enable_nat_gateway\" {\n  description = \"Enable NAT Gateway for private subnet internet access\"\n  type        = bool\n  default     = true\n}\n\nvariable \"enable_lambda_vpc_config\" {\n  description = \"Enable VPC configuration for Lambda functions\"\n  type        = bool\n  default     = true\n}\n\nvariable \"enable_vpc_flow_logs\" {\n  description = \"Enable VPC Flow Logs for network monitoring\"\n  type        = bool\n  default     = true\n}\n\nvariable \"vpc_flow_log_retention_days\" {\n  description = \"Retention period for VPC flow logs\"\n  type        = number\n  default     = 30\n}\n\n# Tags\nvariable \"tags\" {\n  description = \"Common tags to apply to all resources\"\n  type        = map(string)\n  default     = {}\n}\n\nvariable \"additional_tags\" {\n  description = \"Additional tags to apply to all resources\"\n  type        = map(string)\n  default     = {}\n}"
  },
  {
    "path": "config/default.yaml",
    "content": "aws:\n  region: us-east-1\nservices:\n  s3:\n    bucket: ai-ppt-assistant-presentations\n    templates_bucket: ai-ppt-assistant-templates\n  dynamodb:\n    table: ai-ppt-assistant-sessions\n    checkpoints_table: ai-ppt-assistant-checkpoints\n  bedrock:\n    model_id: anthropic.claude-4-0\n    nova_model_id: stability.stable-diffusion-xl-v1\nperformance:\n  max_concurrent_downloads: 3\n  max_concurrent_images: 3\n  max_concurrent_slides: 5\n  image_download_timeout: 10\n  cache_ttl_seconds: 3600\n  max_slides: 20\n  max_image_size_mb: 10\n  batch_size: 3\n  checkpoint_ttl_hours: 24\n  max_checkpoints_per_task: 50\n  default_seconds_per_slide: 60\n  max_search_results: 10\n  max_template_size_mb: 50\n  default_image_size: 1024x768\nsecurity:\n  vpc_enabled: true\n  enable_rekognition: false\n  encryption_enabled: true\nmonitoring:\n  log_level: DEBUG\n  download_expiry_seconds: 3600\n  enable_xray: true\n  enable_monitoring: true\nmetadata:\n  environment: default\n  last_updated: '2025-01-15'\nunmapped_environment_variables:\n  use_config_files: true\n  config_migration_mode: auto\n"
  }
]